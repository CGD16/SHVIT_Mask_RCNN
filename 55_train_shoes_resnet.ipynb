{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # https://github.com/maxw1489/Mask_RCNN (tensorflow 2.9.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.15.0\n",
      "Num GPUs Available:  1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[name: \"/device:CPU:0\"\n",
       " device_type: \"CPU\"\n",
       " memory_limit: 268435456\n",
       " locality {\n",
       " }\n",
       " incarnation: 4625473458240118117\n",
       " xla_global_id: -1,\n",
       " name: \"/device:GPU:0\"\n",
       " device_type: \"GPU\"\n",
       " memory_limit: 10180624384\n",
       " locality {\n",
       "   bus_id: 1\n",
       "   links {\n",
       "   }\n",
       " }\n",
       " incarnation: 2180333366412471862\n",
       " physical_device_desc: \"device: 0, name: NVIDIA GeForce RTX 4090, pci bus id: 0000:01:00.0, compute capability: 8.9\"\n",
       " xla_global_id: 416903419]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\" # https://stackoverflow.com/questions/35911252/disable-tensorflow-debugging-information\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.client import device_lib\n",
    "\n",
    "print(tf.__version__)\n",
    "print(\"Num GPUs Available: \",\n",
    "len(tf.config.list_physical_devices('GPU')))\n",
    "device_lib.list_local_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import os\n",
    "import json\n",
    "import cv2\n",
    "import sys\n",
    "import math\n",
    "import random\n",
    "import warnings\n",
    "\n",
    "import cv2\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "dir_root = os.path.abspath(\"./\")\n",
    "\n",
    "# sys.path.append(os.path.join(dir_root, \"maskrcnn/Mask_RCNN-master/\"))  # To find local version\n",
    "# sys.path.append(os.path.join(dir_root, \"maskrcnn/Mask_RCNN-master_tf2p9/\"))  # To find local version\n",
    "# sys.path.append(os.path.join(dir_root, \"maskrcnn/mask-rcnn-tf2-us-main/\"))  # To find local version\n",
    "\n",
    "# sys.path.append(os.path.join(dir_root, \"maskrcnn/mask-rcnn-tf2-us-main/samples/coco/\"))  # To find local version\n",
    "\n",
    "\n",
    "from mrcnn import utils\n",
    "from mrcnn import visualize\n",
    "from mrcnn.visualize import display_images\n",
    "import mrcnn.model as modellib\n",
    "from mrcnn.model import log\n",
    "from mrcnn.config import Config\n",
    "\n",
    "import imgaug as ia\n",
    "import imgaug.augmenters as iaa\n",
    "\n",
    "\n",
    "\n",
    "logging.disable(logging.WARNING)\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' \n",
    "    # 0 = all messages are logged (default behavior)\n",
    "    # 1 = INFO messages are not printed\n",
    "    # 2 = INFO and WARNING messages are not printed\n",
    "    # 3 = INFO, WARNING, and ERROR messages are not printed\n",
    "\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.tensorflow.org/api_docs/python/tf/config/experimental/set_memory_growth\n",
    "physical_devices = tf.config.list_physical_devices(\"GPU\") \n",
    "for device in physical_devices:\n",
    "    tf.config.experimental.set_memory_growth(device=device, enable=True)\n",
    "\n",
    "tf.config.threading.set_intra_op_parallelism_threads(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_OF_IMAGES = 1000#0\n",
    "NUM_OF_VAL_IMAGES = int(NUM_OF_IMAGES*0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Configurations:\n",
      "BACKBONE                       resnet101\n",
      "BACKBONE_STRIDES               [4, 8, 16, 32, 64]\n",
      "BATCH_SIZE                     4\n",
      "BBOX_STD_DEV                   [0.1 0.1 0.2 0.2]\n",
      "COMPUTE_BACKBONE_SHAPE         None\n",
      "DETECTION_MAX_INSTANCES        100\n",
      "DETECTION_MIN_CONFIDENCE       0.7\n",
      "DETECTION_NMS_THRESHOLD        0.3\n",
      "FPN_CLASSIF_FC_LAYERS_SIZE     1024\n",
      "GPU_COUNT                      1\n",
      "GRADIENT_CLIP_NORM             5.0\n",
      "IMAGES_PER_GPU                 4\n",
      "IMAGE_CHANNEL_COUNT            3\n",
      "IMAGE_MAX_DIM                  512\n",
      "IMAGE_META_SIZE                16\n",
      "IMAGE_MIN_DIM                  512\n",
      "IMAGE_MIN_SCALE                0\n",
      "IMAGE_RESIZE_MODE              square\n",
      "IMAGE_SHAPE                    [512 512   3]\n",
      "LEARNING_MOMENTUM              0.9\n",
      "LEARNING_RATE                  0.001\n",
      "LOSS_WEIGHTS                   {'rpn_class_loss': 1.0, 'rpn_bbox_loss': 1.0, 'mrcnn_class_loss': 1.0, 'mrcnn_bbox_loss': 1.0, 'mrcnn_mask_loss': 1.0}\n",
      "MASK_POOL_SIZE                 14\n",
      "MASK_SHAPE                     [28, 28]\n",
      "MAX_GT_INSTANCES               100\n",
      "MEAN_PIXEL                     [123.7 116.8 103.9]\n",
      "MINI_MASK_SHAPE                (56, 56)\n",
      "NAME                           55_shapes_resnet\n",
      "NUM_CLASSES                    4\n",
      "POOL_SIZE                      7\n",
      "POST_NMS_ROIS_INFERENCE        1000\n",
      "POST_NMS_ROIS_TRAINING         2000\n",
      "PRE_NMS_LIMIT                  6000\n",
      "ROI_POSITIVE_RATIO             0.33\n",
      "RPN_ANCHOR_RATIOS              [0.5, 1, 2]\n",
      "RPN_ANCHOR_SCALES              (8, 16, 32, 64, 128)\n",
      "RPN_ANCHOR_STRIDE              1\n",
      "RPN_BBOX_STD_DEV               [0.1 0.1 0.2 0.2]\n",
      "RPN_NMS_THRESHOLD              0.7\n",
      "RPN_TRAIN_ANCHORS_PER_IMAGE    256\n",
      "RUN_EAGERLY                    False\n",
      "STEPS_PER_EPOCH                250\n",
      "TOP_DOWN_PYRAMID_SIZE          256\n",
      "TRAIN_BN                       False\n",
      "TRAIN_ROIS_PER_IMAGE           128\n",
      "USE_MINI_MASK                  False\n",
      "USE_RPN_ROIS                   True\n",
      "VALIDATION_STEPS               50\n",
      "WEIGHT_DECAY                   0.0001\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "class ShapesConfig(Config):\n",
    "    \"\"\"Configuration for training on the toy shapes dataset.\n",
    "    Derives from the base Config class and overrides values specific\n",
    "    to the toy shapes dataset.\n",
    "    \"\"\"\n",
    "    # Give the configuration a recognizable name\n",
    "    NAME = \"55_shapes_resnet\"\n",
    "\n",
    "    BACKBONE = \"resnet101\" # \"shvit\"\n",
    "\n",
    "    # The strides of each layer of the FPN Pyramid. These values\n",
    "    # are based on a SHViT  backbone.\n",
    "    # BACKBONE_STRIDES = [8, 16, 32, 64, 128] # 128 added as they add 64 in the paper (original strides were [4,8,16,32] -> [4,8,16,32,64], maybe because P5 was upsampled by factor 2??)\n",
    "    BACKBONE_STRIDES= [4, 8, 16, 32, 64] # resnet\n",
    "\n",
    "\n",
    "    # Train on 1 GPU and 8 images per GPU. We can put multiple images on each\n",
    "    # GPU because the images are small. Batch size is 8 (GPUs * images/GPU).\n",
    "    GPU_COUNT = 1\n",
    "    IMAGES_PER_GPU = 4\n",
    "\n",
    "    # Number of classes (including background)\n",
    "    NUM_CLASSES = 1 + 3  # background + 3 shapes\n",
    "\n",
    "    # Use small images for faster training. Set the limits of the small side\n",
    "    # the large side, and that determines the image shape.\n",
    "    IMAGE_MIN_DIM = 512 # 128\n",
    "    IMAGE_MAX_DIM = 512 # 128\n",
    "\n",
    "    # Use smaller anchors because our image and objects are small\n",
    "    RPN_ANCHOR_SCALES = (8, 16, 32, 64, 128)  # anchor side in pixels resnet\n",
    "    # RPN_ANCHOR_SCALES = (16, 32, 64, 128, 256)\n",
    "\n",
    "    # Reduce training ROIs per image because the images are small and have\n",
    "    # few objects. Aim to allow ROI sampling to pick 33% positive ROIs.\n",
    "    TRAIN_ROIS_PER_IMAGE = 128 # 32\n",
    "\n",
    "    # Use a small epoch since the data is simple\n",
    "    STEPS_PER_EPOCH = int(NUM_OF_IMAGES / IMAGES_PER_GPU)\n",
    "\n",
    "    # use small validation steps since the epoch is small\n",
    "    VALIDATION_STEPS = int(NUM_OF_VAL_IMAGES / IMAGES_PER_GPU)\n",
    "\n",
    "    RUN_EAGERLY = False    \n",
    "\n",
    "\n",
    "\n",
    "config = ShapesConfig()\n",
    "config.display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ShapesDataset(utils.Dataset):\n",
    "    \"\"\"Generates the shapes synthetic dataset. The dataset consists of simple\n",
    "    shapes (triangles, squares, circles) placed randomly on a blank surface.\n",
    "    The images are generated on the fly. No file access required.\n",
    "    \"\"\"\n",
    "\n",
    "    def load_shapes(self, count, height, width):\n",
    "        \"\"\"Generate the requested number of synthetic images.\n",
    "        count: number of images to generate.\n",
    "        height, width: the size of the generated images.\n",
    "        \"\"\"\n",
    "        # Add classes\n",
    "        self.add_class(\"shapes\", 1, \"square\")\n",
    "        self.add_class(\"shapes\", 2, \"circle\")\n",
    "        self.add_class(\"shapes\", 3, \"triangle\")\n",
    "\n",
    "        # Add images\n",
    "        # Generate random specifications of images (i.e. color and\n",
    "        # list of shapes sizes and locations). This is more compact than\n",
    "        # actual images. Images are generated on the fly in load_image().\n",
    "        for i in range(count):\n",
    "            bg_color, shapes = self.random_image(height, width)\n",
    "            #print(\"bg_color\", bg_color)\n",
    "            #print(\"shapes\", shapes)\n",
    "            self.add_image(\"shapes\", image_id=i, path=None,\n",
    "                           width=width, height=height,\n",
    "                           bg_color=bg_color, shapes=shapes)\n",
    "\n",
    "    def load_image(self, image_id):\n",
    "        \"\"\"Generate an image from the specs of the given image ID.\n",
    "        Typically this function loads the image from a file, but\n",
    "        in this case it generates the image on the fly from the\n",
    "        specs in image_info.\n",
    "        \"\"\"\n",
    "        info = self.image_info[image_id]\n",
    "        bg_color = np.array(info['bg_color']).reshape([1, 1, 3])\n",
    "        image = np.ones([info['height'], info['width'], 3], dtype=np.uint8)\n",
    "        image = image * bg_color.astype(np.uint8)\n",
    "        for shape, color, dims in info['shapes']:\n",
    "            image = self.draw_shape(image, shape, dims, color)\n",
    "        return image\n",
    "\n",
    "    def image_reference(self, image_id):\n",
    "        \"\"\"Return the shapes data of the image.\"\"\"\n",
    "        info = self.image_info[image_id]\n",
    "        if info[\"source\"] == \"shapes\":\n",
    "            return info[\"shapes\"]\n",
    "        else:\n",
    "            super(self.__class__).image_reference(self, image_id)\n",
    "\n",
    "    def load_mask(self, image_id):\n",
    "        \"\"\"Generate instance masks for shapes of the given image ID.\n",
    "        \"\"\"\n",
    "        info = self.image_info[image_id]\n",
    "        shapes = info['shapes']\n",
    "        count = len(shapes)\n",
    "        mask = np.zeros([info['height'], info['width'], count], dtype=np.uint8)\n",
    "        for i, (shape, _, dims) in enumerate(info['shapes']):\n",
    "            mask[:, :, i:i + 1] = self.draw_shape(mask[:, :, i:i + 1].copy(),\n",
    "                                                  shape, dims, 1)\n",
    "        # Handle occlusions\n",
    "        occlusion = np.logical_not(mask[:, :, -1]).astype(np.uint8)\n",
    "        for i in range(count - 2, -1, -1):\n",
    "            mask[:, :, i] = mask[:, :, i] * occlusion\n",
    "            occlusion = np.logical_and(\n",
    "                occlusion, np.logical_not(mask[:, :, i]))\n",
    "        # Map class names to class IDs.\n",
    "        class_ids = np.array([self.class_names.index(s[0]) for s in shapes])\n",
    "        return mask, class_ids.astype(np.int32)\n",
    "\n",
    "    def draw_shape(self, image, shape, dims, color):\n",
    "        \"\"\"Draws a shape from the given specs.\"\"\"\n",
    "        # Get the center x, y and the size s\n",
    "        x, y, s = dims\n",
    "        if shape == 'square':\n",
    "            image = cv2.rectangle(image, (x - s, y - s),\n",
    "                                  (x + s, y + s), color, -1)\n",
    "        elif shape == \"circle\":\n",
    "            image = cv2.circle(image, (x, y), s, color, -1)\n",
    "        elif shape == \"triangle\":\n",
    "            points = np.array([[(x, y - s),\n",
    "                                (x - s / math.sin(math.radians(60)), y + s),\n",
    "                                (x + s / math.sin(math.radians(60)), y + s),\n",
    "                                ]], dtype=np.int32)\n",
    "            image = cv2.fillPoly(image, points, color)\n",
    "        return image\n",
    "\n",
    "    def random_shape(self, height, width):\n",
    "        \"\"\"Generates specifications of a random shape that lies within\n",
    "        the given height and width boundaries.\n",
    "        Returns a tuple of three valus:\n",
    "        * The shape name (square, circle, ...)\n",
    "        * Shape color: a tuple of 3 values, RGB.\n",
    "        * Shape dimensions: A tuple of values that define the shape size\n",
    "                            and location. Differs per shape type.\n",
    "        \"\"\"\n",
    "        # Shape\n",
    "        shape = random.choice([\"square\", \"circle\", \"triangle\"])\n",
    "        # Color\n",
    "        color = tuple([random.randint(0, 255) for _ in range(3)])\n",
    "        # Center x, y\n",
    "        buffer = 20\n",
    "        y = random.randint(buffer, height - buffer - 1)\n",
    "        x = random.randint(buffer, width - buffer - 1)\n",
    "        # Size\n",
    "        s = random.randint(buffer, height // 4)\n",
    "        return shape, color, (x, y, s)\n",
    "\n",
    "    def random_image(self, height, width):\n",
    "        \"\"\"Creates random specifications of an image with multiple shapes.\n",
    "        Returns the background color of the image and a list of shape\n",
    "        specifications that can be used to draw the image.\n",
    "        \"\"\"\n",
    "        # Pick random background color\n",
    "        bg_color = np.array([random.randint(0, 255) for _ in range(3)])\n",
    "        # Generate a few random shapes and record their\n",
    "        # bounding boxes\n",
    "        shapes = []\n",
    "        boxes = []\n",
    "        N = random.randint(1, 4)\n",
    "        for _ in range(N):\n",
    "            shape, color, dims = self.random_shape(height, width)\n",
    "            shapes.append((shape, color, dims))\n",
    "            x, y, s = dims\n",
    "            boxes.append([y - s, x - s, y + s, x + s])\n",
    "        # Apply non-max suppression wit 0.3 threshold to avoid\n",
    "        # shapes covering each other\n",
    "        keep_ixs = utils.non_max_suppression(\n",
    "            np.array(boxes), np.arange(N), 0.3)\n",
    "        shapes = [s for i, s in enumerate(shapes) if i in keep_ixs]\n",
    "        return bg_color, shapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training dataset\n",
    "dataset_train = ShapesDataset()\n",
    "dataset_train.load_shapes(NUM_OF_IMAGES, config.IMAGE_SHAPE[0], config.IMAGE_SHAPE[1])\n",
    "dataset_train.prepare()\n",
    "\n",
    "# Validation dataset\n",
    "dataset_val = ShapesDataset()\n",
    "dataset_val.load_shapes(NUM_OF_VAL_IMAGES, config.IMAGE_SHAPE[0], config.IMAGE_SHAPE[1])\n",
    "dataset_val.prepare()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask, idx = dataset_val.load_mask(2)\n",
    "np.max(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1400x700 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1400x700 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABFEAAAESCAYAAAA17UrCAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/TGe4hAAAACXBIWXMAAA9hAAAPYQGoP6dpAAA12klEQVR4nO3deXTcdb3/8dfnO3symUzWyb43SZs0S0OTJm2hZSu1IJsUW4rg0qLSyqKopfq7CCheEY9H0QviH3i5oHAvVz3H5ajnAhe916vXlcWfCnSlOy1tmrZp02R+f5TmR+g2SWbymeX5OKd/NPOd7/eVHDrMvPL+fj4mGo1GBQAAAAAAgDNybAcAAAAAAABIBZQoAAAAAAAAMaBEAQAAAAAAiAElCgAAAAAAQAwoUQAAAAAAAGJAiQIAAAAAABADShQAAAAAAIAYUKIAAAAAAADEgBIFAAAAAAAgBpQoAICYtbS06Ec/+tGUXGvBggX66le/OiXXAgAAAGJBiTIBp3tjb4zRn/70p0mf/9JLL9XatWvHfK2iokILFy4c87Wrr75aH/vYx8Z9/pqaGgUCAQWDQQWDQYXD4TGPr1q1Sk1NTXIc56Tv8+9//7uuvPJKlZSUKBwOa+7cufqv//qvmK991113ye12j147GAzqySefHH38qaeeUl9fn7KystTR0XHS8++44w41NTUpJydHtbW1uu+++8bzrQM4g5qaGv3gBz844zEvv/yyLr300qkJBAAAACQZSpQktHDhQj377LOjf3/llVfk8Xj05z//WYODg5KkaDSq559//qRiJVbf/e53NTAwoIGBAe3bt2/MY+3t7frmN7+p7u7uk563b98+LV68WC+++KL27NmjG2+8Ue9617v0xhtvxHztSy+9dPTaAwMDuvbaa0cfy8/P16233qp169ad8rl+v19PP/209u3bp5/+9Kd6+OGH9a1vfSvmawOYmOHhYUWjUdsxACDujh07ZjsCACCFUKJMkWuuuUYrVqwY/fv999+vlpYWHT58+KRjFy5cqN///vc6cOCAJOm5557TBRdcoM7OTv3617+WJL300kvau3evzjvvvLhnvfnmm3XBBRfI7/ef9Fh3d7dWrVqloqIiuVwurVy5Ui6XSy+88IIk6Uc/+pEikYi2b98uSVq/fr3y8vLGlEJncuGFF2rp0qUqLy8/5eP33HOPWltb5XK51NzcrKuuukq/+tWvJvidAjjhmmuu0ebNm7Vs2TIFg0F9+MMfljFGDz74oFpbW5WVlaWBgYEx0yqbN2/WRRddpKKiIuXl5WnJkiXauHHj6DlvvPFGrVy5Uu9973uVk5OjpqYmPffcc6OP79u3T9dcc43C4bCam5v19a9/XcaY02b8wx/+oIULFyo/P18NDQ165JFHEvTTADBVvvKVr6iqqko5OTmqqanRt7/9bUnSgw8+qMrKShUUFGjdunXq6OjQo48+Kun4VOsVV1wx5jzhcHj09eWPf/yj5s2bp/z8fBUVFWnZsmXas2fP6LELFizQJz/5SV188cXKzs7WT3/6Uw0MDGj16tWqqqpScXGx3ve+92n//v1T8SMAAKQYSpQp8sgjj+iXv/yl/vmf/1m/+93vdO+99+p73/ueAoHAScd2dHQoJydntBx47rnntGDBAp133nmjbxCee+45tbe3Kz8/X5L0xS9+UeFw+LR/nnjiiTHXuOmmm1RYWKje3l795Cc/mfD39eKLL+rAgQOaMWOGpONTJtdee63e97736ciRI1q2bJk++tGPjpmYeeaZZ1RQUKDGxkatW7dudLpmvE5M47S1tU04P4Dj/vVf/1VVVVWjU2oPPfSQJOmJJ57Qz3/+c/X39ys7O3vMc0ZGRnT77bdry5Yt2rRpk7KysrRy5coxx3zve9/TqlWrtG/fPl1//fW68cYbRx9bs2aNDh48qE2bNunZZ5/VY489dtp8O3bs0EUXXaSPfOQj2r17t37wgx/oH/7hH/Qf//Ef8fshAJhSf//73/WZz3xGP//5z3XgwAH95je/UXd3t5555hmtW7dOTz311OgvZV566aWYz+s4jr74xS9q586deumll7R161Z9+tOfHnPMo48+qnvvvVcDAwO68MIL9YEPfEB79+7VCy+8oA0bNmhoaEirV6+O6/cLAEgPlCgTtHbt2pOKijMJh8N6/PHHdcstt2jp0qX6whe+oJkzZ57yWMdxdO65545Ob/znf/6nzjvvPJ133nmjX3vuuefGFBOf/vSntW/fvtP+Wb58+eixjz32mDZs2KCtW7dqzZo1uvrqq/W///u/4/4ZvPnmm3rve9+rO++8UyUlJaNfv//++7Vr1y51d3fLcRx97nOfG33smmuu0V/+8hft3r1b//7v/64f//jH+tSnPjXua0vSunXrdOjQIX3kIx+Z0PMBnN0nP/lJlZWVyefzyXHG/i+jpqZGixcvlt/vVygU0rp16/T8889rZGRk9JglS5bo/PPPl8vl0vvf/35t2rRJe/bs0fDwsJ588kndfffdys3NVWlpqe64447T5njsscd07rnnaunSpXK5XGptbdX73//+kwpiAKnD5XIpGo3q5Zdf1uHDhxWJRNTW1qbHH39c1113nXp7e+X1enXXXXedVOKeSXt7u+bNmyePx6NIJKLbb799zBScJC1fvlzd3d0yxmhgYEBPP/20HnzwQYXDYWVnZ+vuu+/Wk08+qeHh4Th/1wCAVEeJMkH33XffSUXF2cydO1d1dXXq7+/Xhz70oTMee2JdlFdeeUU+n0+VlZXq6enRn//8Zx08eHBS66HMnz9fWVlZ8vl8Wr58uS677DI9/fTT4zrH/v37dckll2jevHm66667xjzm8/n0gQ98QC+88II+8YlPyO12jz7W0tKiiooKOY6j1tZWfeELXxizsGys7rvvPj355JP6+c9/Pq43VgDGp6qq6rSP7d69W8uXL1dlZaVCoZDOPfdcHT16dPRWREljCtYT/1YPHDigN954Q0NDQ6qsrIzpWhs3btRPfvKTMcX11772tdHfUgNIPfX19frOd76jBx98UJFIRBdffLH+9Kc/adu2baqurh49zuPxqLS0NObzvvrqq7r88stVVlamUCikFStWnLR229tfbzZu3KiRkRHV1dWNvr7Mnj1bjuNox44dk/9GAaSNxx9/fHRzjJaWFttxYAklyhR64IEHdOTIEU2fPl133nnnGY9duHCh/vjHP+qHP/zh6Lonfr9fHR0deuSRR/Tmm2/q3HPPHT3+C1/4wpgdb9755/HHHz/ttd752+Wz6e/v16JFi9TS0qKHHnropDUMNmzYoM997nNauXKl7rjjDvX398ft2tLxW5cefvhhPfPMM6qoqBj38wGc2qn+PZ7p3+jatWt16NAh/eEPf1B/f7+ef/55SYppAdrCwkJ5PB5t2bJl9GubN28+7fGVlZW68sorxxTXBw4cmNTtiADsW7p0qZ599lnt3LlT7e3tuv7661VWVqZNmzaNHjM0NDSmMA0Ggzp06NDo3w8dOjTmvcaHP/xhlZeX6y9/+Yv6+/v1L//yLye9Lr39ta2yslKO42jbtm1jXmMGBwdPu0YbgMx03XXXjW6O8fLLL9uOA0soUabI73//e91zzz367ne/qyeeeELf+c539LOf/ey0x8+cOVN5eXl64IEHtGDBgtGvn3feefrHf/xHdXV1KRQKjX79zjvvHLPjzTv/XHfddZKOf0h5/vnndeTIEQ0NDempp57SD3/4wzELtB09elSDg4MaGRnRsWPHNDg4OLpy/YkCpbGxUd/+9rdPKlCOHTs2ug7Kt771LXV1denDH/7w6OPf//73Rxd3+9vf/qY777xTV1999ejjw8PDGhwc1NDQkKLRqAYHB3XkyJHRx7/0pS/pG9/4hp555pkxv6UCMHmRSESvvfZazMf39/crKytL4XBYe/bsGXPr3tm4XC4tXbpUd911l/r7+7Vjxw498MADpz3++uuv1zPPPKOnn35aQ0NDGhoa0p/+9KcJ3YoIIDn87W9/0y9+8QsdPnxYXq9XwWBQbrdby5Yt0+OPP67f/OY3Onr0qO6++24dPHhw9HmzZs3Sr3/9a/31r3/V4OCg1q5dO+b9SH9/v3JychQKhbRlyxbdf//9Z8xRUlKiK664QqtXrx6dWNmxY4e+//3vJ+YbBwCkNEqUKTAwMKBly5bp85//vGbOnKnKykp961vf0g033KBdu3ad8jnGGJ133nnasWPHmB14TnxtorfyDAwM6GMf+5gKCgpUVFSkL3/5y3rqqac0Z86c0WMuvvhiBQIB/fKXv9Qdd9yhQCCge++9V9LxEuR//ud/9PTTTysUCp006fLZz35WkkZv8XnkkUf03//93/rOd74j6fjilU1NTcrOztbixYu1aNEiffnLXx699mOPPaZAIKBVq1bphRdeUCAQUFNT0+jjn/rUp7Rz5061tbWNXnvx4sUT+lkAGOvOO+/Ugw8+qLy8PH30ox896/Gf+9zn9OqrryovL09z584d97/Fr3/966O3Ky5YsEBLly6V1+s95bHl5eX62c9+pocfflilpaWKRCK6+eabzzjpBiC5HT16VJ/97GcViURUUFCgZ555Ro8++qguvPBC3XPPPbr66qtVWlqqkZERtba2jj7v/PPP10033aS+vj41NDRo5syZysnJGX38K1/5in70ox8pFArp8ssvH/PLmtN59NFHR2/jCYVCmj9/vn7/+98n5PsGAKQ2E41l7hoAgAR74okn9H/+z//Rq6++ajsKgCTT0dGhW2+9dcwOXwAA2MAkCgDAildeeUW/+93vFI1G9corr+jzn/+8rrnmGtuxAAAAgNNyn/0QAADi7+DBg1qxYoW2bNmi3NxcXXHFFfrMZz5jOxYAAABwWtzOAwAAAAAAEANu5wEAAAAAAIgBJQoAAAAAAEAMKFEAAAAAAABiQIkCAAAAAAAQg5h357mx4NlE5gDGbY7vqLp8Q7ZjJKXZGy61HWHCjDG2IwCIUSqvTc9rDZLNfffdp09/+tO2YyDOeK0BUkes72uYRAEAAAAAAIgBJQoAAAAAAEAMKFEAAAAAAABiQImSYMaMSErde8YBpAbH4eUcAAAASDTedSeQx3VUs6v/rGzvIdtRAKQxv9+vyy+/XHl5ebajAAAAAGmNEiWBynN3qjJvm+oKN4tpFACJ0tzcrJkzZ6qrq8t2FAAAACCtUaIkiNsZUkPxBjkmquqC15lGAZAQPp9P3d3dchxH7e3tCofDtiMBAAAAaYsSJQGMomoo2qTcwAFJkt99RM0lr8plhi0nA5BOjDGaPXu2IpGIJCkYDOrcc8+V2+22nAwAAABIT5QoCRD0D6gx8pocc/wWHmOkmoLXVZTzhuVkANJJYWGh+vr65HK5JB0vVdrb21VTU2M3GAAAAJCmKFHizDEjaijaKJ976B1fj2pa8Qa5nGOWkgFIJy6XS93d3crKyjrp6729vfJ4PJaSAQAAAOmLEiWuoirL3fHWQrInKwruVWlol1hkFsBkNTU1adasWad8rLq6WtOmTZviRAAAAED6o0SJI5cZUWNk/ehtPCc97oyoveIv8nuOTHEyAOnE7XaPuY3nVI8vWrRIOTk5U5wMAAAASG+UKHFUmrtT+Vn7znhMwDOo2gK2PAYwcY2NjSovLz/jMaFQSJ2dnVOUCAAAAMgMlChxku09qM7Kl2TMmY8zRqor3KyAZ1AUKQDGKy8vT+9617tkzvJiY4xRV1cX0ygAAABAHFGixEX0rcVkj8Z0dMAzqFlVLyY4E4B0NHv2bGVnZ8d0bCgU0qWXXnrWwgUAAABAbChR4iDbe0jV+VvPOoVygjFSJOcNFQX3JDYYgLSSl5en9vb2mEsRY4zq6upUXV2d4GQAAABAZqBEmSSXc0wdFS/LG+MUyv9/3luLzLoHE5QMQDrxeDy65JJLTtrSOJbnLVq0SMFgMEHJAAAAgMxBiTJJkZw3FAm9EfMUytuFA/2qLng9/qEApJ26ujrV19dP6NackpIStbe3JyAVAAAAkFkoUSbB7xlUU+Q1uZyRCT3/xCKzTKMAOJNgMKi+vj653e4JPf/EIrNMowAAAACTQ4kyYVHVF25SQfabkzpLtveQmiKvyTETK2IApL/Zs2erqqpqUufIy8tTX1+fXC5XnFIBAAAAmYcSZYKyPIdVU7BlQrfxvJ0xUl3RZuVl7YtLLgDpJTc3Vx0dHZPeYefENEpZWVmckgEAAACZhxJlAoxGVFe0WVne+NyG43aGNa14gwzTKADexhijWbNmKTc3Ny7n8/l86unpkePw0g8AAABMBO+kJ6AoZ4+ail+L6zlLQrtUHNwjKRrX8wJIXbW1tZo3b15czzlt2jTV1tbG9ZwAAABApqBEGSfHDKsp8pqMiW/Z4XENq6PyJXlcQ3E9L4DU5HK51NfXF/epEZ/Pp8WLF8vv98f1vAAAAEAmoEQZp6LgXhXn7Jn0WiinkuM7qKq8bWIaBUB1dbVqa2snvRbKqRQUFKi1tTXu5wUAAADSHSXKOPjdg+qqekEmQSWHMVJD8QZ5mUYBMlowGNRll12WsLVLjDGaM2eOAoFAQs4PAAAApCtKlJhFVVOwRVnewwmZQjkhx3dQHRUvi2kUIHN1dHQoHA4nZArlhIKCAl1yySUJOz8AAACQjihRYlSQ/aYaijcmtECRjk+jlId3KBzoT+yFACSlqqoq9fT0JLRAkY5PozQ3N6ukpCSh1wEAAADSCSVKDIwZUWPxegU8R6bkei5nWI3F62XElsdAJnEcR3PmzFFOTs6UXM/r9aq3tzfhhQ0AAACQLihRYlCQ/aYiod1Tdj1jpIq87aoueH3KrgnAvsrKStXX10/Z9YwxamlpUXt7+5RdEwAAAEhllChn4XUd1fTIq/K4hqf0ui5nRNOKNrLlMZAhAoGA5s2bJ5/PN6XXdbvdmjNnzpRfFwAAAEhFlChnFFV1/utTOoXydqHAAZWHt4tFZoH019bWpoaGBivXLioq0vTp061cGwAAAEgllChn4HMfVX3RpoQvJns6jomqOfKaQv4BOwEATImsrCx1d3dbW5vE5XJp3rx5KioqsnJ9AAAAIFVQopzW8SmUoO+g1RQ5/oNqKNogplGA9GSMUUdHh/Lz863mKCwstFrkAAAAAKmAEuU08rL2qaXsb9amUN6uIm+7cv0HbMcAkAClpaVauHBhUpQXLS0tTKMAAAAAZ0CJcgpGI2os3iCXSY4thn3uITVGXpPLOWY7CoA4chxHfX19crvdtqNIOn5b0dy5c+XxeGxHAQAAAJISJcpJosrL2q+y8I6kmEI5oTp/q8pyd9qOASCOSktL1dTUlBRTKCe0tbWpqanJdgwAAAAgKVGivIPHdUznVL+QNFMoJxgjNRavl9thy2MgHfj9fr373e9OmimUE4wx6u3tZctjAAAA4BQoUcaIqjJvm3L8A0k1hXJCXtZ+tZb9TSwyC6S+E+uPJNMUygllZWVauHCh7RgAAABA0qFEeZvcQL+aI6/KMclZUhgjVeVvtb5jEIDJiUQimj9/vhwnOV+CjTFqa2uzvmMQAAAAkGyS8x28FVFNK9qobN9h20HOyOsaUkPRRjGNAqQmY4x6enoUDodtRzmjQCDAlscAAADAO1CivCUc6Fd5eIftGGdljFRbsEXlucmfFcDJIpGIpk+fbjvGWRlj1NnZySKzAAAAwNtQokhyO8fUXPKqvO7UWLTV7RrWtOINcsyw7SgAxsHr9Wr+/PkKBAK2o8TE5/Opt7c36Ra/BQAAAGyhRJFUHt6hivB22zHGJT97n0pCu8RtPUDqaG5u1owZM2zHGJfy8nI1NDTYjgEAAAAkhYwvUTyuIU0r3pCUu/GcicsZUUvpK8ryJvcaLgCO8/v9mjNnTsqtMeJ2u7VgwYKkX8MFAAAAmAoZXqJEVRHepnBgv+0gExLO6ldd4WYxjQIkN2OMZsyYoZKSEttRJqSkpERdXV22YwAAAADWZXSJkuMbUFv5/025KZS3q8nfomzvIdsxAJxBQUGBLrrooqTd0jgWbW1tTKMAAAAg46XuO/pJMoqqoXijPK5jtqNMit9zRI0sMgskLWOMZs+eLb/fbzvKpIRCIRaZBQAAQMbL0BIlqvLwdtUWbEnpKRTp+JbHdUWbVJyzx3YUAKcwffp0zZo1K+XWQnmnE2VQTU2N7SgAAACANRlZojhmRNOKN8jljNiOEhdGUTUWr5eLaRQgqbjdbvX29srj8diOEhfGGKZRAAAAkNEysESJqix3p/Kz9tkOEjfGSEXBPSoO7RaLzALJo7GxUWVlZbZjxI0xRjU1Naqrq7MdBQAAALAi40qUbN8htZT9TY6TXmWD40Q1q/Il+T1HbEcBICkvL0/nn3++XC6X7Shx5XK5tGTJEuXk5NiOAgAAAEy5DCtRoqov3KSQ/6DtIAkR8AyqtoAtj4FkcM4556iwsNB2jIQIhULq7Oy0HQMAAACYchlVogR9h1Sdv9V2jIQxRqor3Mw0CmBZfn6+2tvbbcdIGGOMurq6mEYBAABAxsmYEsVlhtUceVU+d3oXDAHPoGZVvijDNApghcfj0bx585SdnW07SkKFQiEtWbIk5XcdAgAAAMYjY0qU4tBuVafBlsZnY4wUCe1WYXCvuK0HmHq1tbXq6OhI+3LBGKPa2lpVVVXZjgIAAABMmYwoUTyuITUWb5CT3p9pRrmdETVGXlOGfLtA0vD5fOrt7ZXjZMRLq3w+n/r6+tK+MAIAAABOyIB3+lE1Fq9XUXCP7SBTKpLzhuqLNtqOAWSUvr4+1dTU2I4xperr6zV79mzbMQAAAIApkfYlyokdazLtF6UuZ0QNRRvkdw/ajgJkhFAolBG38byT2+1WT0+PgsGg7SgAAABAwqV5iRLN6N1qgr5Dqi5I392IgGQya9YshUIh2zGsyM/PV1tbm+0YAAAAQMKlcYkSVXHOG2osXp9xUygnGCPVF25UOLDfdhQgrdXV1am3tzfjplBOMMZo9uzZKikpsR0FAAAASKi0LVHMW2uhuF3DtqNYleU9rOaSV+WYEdtRgLRkjFFvb698Pp/tKFaFw2HNmzdPLpfLdhQAAAAgYdK0RImqKGePinMyazHZUzFGKg3tUkH2m2LLYyD+qqurM24x2VMxxmjatGmqqKiwHQUAAABImLQsUfyeI2ov/79yOUxfSJLbNaxZVS/K4zpmOwqQVnJycnTJJZfI4/HYjpIUfD6fLr30Uvn9fttRAAAAgIRIyxKlJn+LcgP9tmMklRzfgKrytoppFCB+2tvbFYlEbMdIKgUFBWptbbUdAwAAAEiItCtRcgP7VVeYeVsan40xUkPxBnlcQ7ajAGkhEomoq6srYxeTPR3HcdTT08M0CgAAANJSWpUojhlWS+kryvIeth0lKeX4Dqqj4i9iGgWYHJfLpQULFigcDtuOkpQKCwt1ySWX2I4BAAAAxF1alSj52ftUEtrFFMppGCOVh3cozK1OwKSUl5eroaGBKZTTMMZo+vTpbHkMAACAtOO2HSBeXM4xTSvewGKyZ+F2jmla8Xr976YOSan9AXDXsKOXj6bNf8JxNdt2gDTm8XjU29vLYrJn4fV61dvbqx/84AeKRpl+A4Cz+e1vf6tHHnnEdoyktHLlStsRAGCUicb47vbGgmcTnWUSomoo2qiOipeZQonBsWGX/rBlpjbtZSvSdPXonoW2I0xYsk939PT0aNGiRXKctBrkS4gjR47oJz/5if785z/bjoIESeWCLNlfawD8f7zWAJgKsb7WpMWnAK9rSA1FGylQYuR2DWta8Xp5XEdtRwFSSiAQUHd3NwVKjHw+n+bMmcMiswAAAEgbafBJIKqq/K0K+g7aDpJScgMHVBHeYTsGkFLa2tqUn59vO0ZKiUQiam5uth0DAAAAiIuUL1HysvartexvTKGMk2Oimla8XkHfgO0oQEooKyvTwoULGcsdJ8dx1Nvbq4KCAttRAAAAgElL8RIlqsbi9fK4jtkOkpJC/gE1Fm+QYctj4Kx6e3u5LWWCiouLNWfOHAooAAAApLyULlGq87eqLHen7RgpyxipIm+bcvwHbEcBklpbW5saGxttx0hZxhi1tLSoqKjIdhQAAABgUlK2RPG6jqox8prcrmHbUVKazz2kacUb5Bh+jsCpBAIBzZ07Vz6fz3aUlJaVlaWenh653WxLDgAAgNSVsiVKRd525TJBERe1BVtUHt4hcVsPcBImKOKns7OTRWYBAACQ0lKyRAn6BtRQtIHFZOPEGKmxeL1cDtMowNsVFBRo9uzZbGkcJycWmfV4PLajAAAAABOScp8MjEbUHHlNIT+7ysRTXtb+t9aXYRoFkI5/4J87d66Ki4ttR0krZWVlampqsh0DAAAAmJCUK1FCgQMqD29nCiXOjJE6K19S0HfIdhQgKRQVFWnGjBnsKBNnxhgtXrxY+fn5tqMAAAAA45ZSJYpjhjWtaKO8brY0TgSva0j1RRvFNAoyncvlUk9PD1saJ0hWVpa6u7ttxwAAAADGLYVKlKgq8raruuB120HSljFSdf7rTKMg47W0tKijo8N2jLRljFFbWxvTKAAAAEg5KVOiuJxhNRavl2OYkkgkr2tInZUvyuUw7YPM5PV61dvby2KyCRYIBLRkyRIWmQUAAEBKSZFPCVHNLPurwoF+20HSnjFSUXCvSnJ2244CWHHBBReopKTEdoy0Z4xRdXW16uvrbUcBAAAAYpYSJUqO76Cq8reymOwUcTkjai55VQHPYdtRgClVUFCgmTNnspjsFHG73Zo/f75CoZDtKAAAAEBMUqBEiaqheIO8riHbQTJKfvZ+1RduEovMIpN0d3crEAjYjpFRysvL1dXVZTsGAAAAEJOkL1HKcncyhWJJdcHryvIyjYLM0NzcrPb2dqZQLOjo6FA4HLYdAwAAADirpC5R3M4xNUVek9fFIqc2ZHkH1VC0UcaM2I4CJNSJxWTZ0tiO3NxcdXd3s5gvAAAAkl5Sv2MtCe1SftY+2zEy2rTiDSoOvmE7BpBQ06ZNU0VFhe0YGa2np0e1tbW2YwAAAABnlLQlSsBzWE2R1+Q4rMlhk1FUTZH1csyw7ShAQoRCIfX19cnlctmOktEcx1FfX5/cbrftKAAAAMBpJWmJElVD0UblZe23HSTjGSMV5exRcc4escgs0lF3d7fKyspsx8h4xhjV1NSopqbGdhQAAADgtJKyRMn2HlJ1wessJpskHBNVV9UL8nuO2I4CxFVeXh6LySYRl8ulyy67TDk5ObajAAAAAKeUdCWK0YjqizYpwAf2pBLwDKq2YLOYRkG6cBxHs2fP5gN7kgmFQurs7LQdAwAAADilpCtRIqHdmla8wXYMvIMxUl3hZqZRkDbq6urU09NjOwbewRijrq4uBYNB21EAAACAkyRVieKY4bcWMWXaIRkFPIPqrHhJRmx5jNTmdrs1d+5cFpNNUqFQSIsXL2bLYwAAACSdJHqHGlVzyasqCu6xHQSnYYxUEtqtwuBe21GASZk3b56qq6ttx8BpGGPU0NCgqqoq21EAAACAMZKmRDm+5sYWFpNNcm7XsBqLN4i1UZCqTqy5wZRDcvP5fOrt7WXRXwAAACSVJPkUEVVd4WYFPIO2gyAGxaHdLDKLlNXV1aVQKGQ7BmJQV1fHIrMAAABIKklRohQF96iucBNTKCnC7YyoKfKa/G4WmUVqqamp0TnnnMN0Q4rweDyaO3cui8wCAAAgaVgvURwzrMbIevk9R21HwTgEfYdUlb/VdgwgZi6XS729vcrOzrYdBeOQn5+vtrY22zEAAAAASUlQohQF96qYxWRTjjFSfdEmhfwHbEcBYlJdXa2amhrbMTBOxhidc845Kioqsh0FAAAAsFui+NxH1FzyqtyuYZsxMEHZ3kOaUfp3OYYtj5HcsrKyNH/+fPl8PttRMAF5eXlasGABW1IDAADAOoslSlQ1BVvY0jiFGSOV5u5UXtZ+21GAM+rs7GQKJYUZY9TY2KjS0lLbUQAAAJDhrJUoAc+g6go3s5hsinM7I5pWtF4uwzQRklMoFGIx2TTg8Xg0Z84cud1u21EAAACQwayUKEYj6qx8WdneQzYujzgrz9uumoItYstjJBtjjBYvXqxwOGw7CuJgxowZ6ujosB0DAAAAGcxKiZKfvU8loV1MoaQJx0gNRRvlcR2zHQUYo6KiQtOmTWMKJU04jqOenh75/X7bUQAAAJChprxEccyImiLrWYw0zeT4B9Re/hcxjYJk4XK51NfXx2KkaaawsFAXX3yx7RgAAADIUFNcokRVV7hRpbk7mUJJM8ZI5eHtCgf6bUcBJEnnnHOOmpqamEJJM8YYzZgxQyUlJbajAAAAIANNaYnidQ2poWiTHMO0Qjryuo9pWvEGMY0C2wKBgGbPni3HsbqLOxLE7/drzpw5tmMAAAAgA03hJ4yoqvK3Kug7OHWXxJQrD29XZd522zGQ4dra2pSfn287BhJo+vTpamlpsR0DAAAAGWbKSpS8rP1qirzGbTxpzuMaVlPkVXlcR21HQYYqKytTX18fUyhpzufzad68eSwyCwAAgCk1JZ8yjKKaVrxBWd7BqbgcLAsH+lUe3mE7BjKQMUY9PT3Kzc21HQVTIBKJqLm52XYMAAAAZJApKFGiioR2qTS0M/GXQlIwRppWtEHZXm7dwtSqr69XU1OT7RiYIo7jaM6cOcrLy7MdBQAAABki4SWKx3VMbeV/ldd9LNGXQhLJDRxQU2S9jNjKGlPD7/froosu4vaODBOJRNTX18cuTAAAAJgSCS9RKsLbFfIfSPRlkGSMkSrztinHzzQKpsaMGTNUXFxsOwammDFGra2tKiwstB0FAAAAGcCdyJN7XEOqLdis4RFXIi+DJOWYEdUUbNELW6dL4rfESBy/36/Ozk4dPcqCxpnIcRx1dnbqF7/4haJRtlgHAABA4iS0RDk24tL/bJjF5+cMNhJlhxQk3tGjR/Vv//ZvtmPAopGREQoUAAAAJFxCS5Ro1NGhoaxEXgIANDIyov3799uOAQAAACDNMSYAAAAAAAAQA0oUAAAAAACAGFCiAAAAAAAAxIASBQAAAAAAIAaUKAAAAAAAADGgRAEAAAAAAIgBJQoAAAAAAEAMKFEAAAAAAABiQIkCAAAAAAAQA0oUAAAAAACAGFCiAAAAAAAAxIASBQAAAAAAIAaUKAAAAAAAADGgRAEAAAAAAIgBJQoAAAAAAEAMKFEAAAAAAABiEPcSxWVGZBSN92kBYAy/3y/HoQcGAAAAMHXi+gnE4zqm8+tfU0PBnnieFgDGyMnJ0UMPPaT3vOc9tqMAAAAAyCBxLFGiaip8Q81Fu9VRul1uZzh+pwaAt1m2bJne97736dZbb1V2drbtOAAAAAAyRNxKFJ9rWO2l22WMVBwcUG3emxK39QCIs7y8PN1yyy0yxqirq0tLliyxHQkAAABAhohTiRLVtMI3lB84LElyOVHNrnhdId+R+JweACQZY3TttddqxowZkiSv16t169aprq7OcjIAAAAAmSAuJUph1iHNq94kY972texDmlmyQ0yjAIiXmTNn6ktf+tKYr7W1tekjH/mIzNtfgAAAAAAgASZdohhF1VG2TR7XyWugNBftVq5/cLKXAAC5XC7ddtttysnJOemxFStWqL6+3kIqAAAAAJlk0iVKQdYhNRTs0al+CZztHVJn2Ta5zMhkLwMgw7W2tp52N56SkhLdfvvt8vv9U5wKAAAAQCaZVIliFFVH6XZ5nNOXJK2RnaoK75vMZQBkOLfbrVtuuUXBYPC0x9x000266KKLpjAVAAAAgEwziRIlqqai3Woq2n3KKZQTjKTOsm1seQxgwpYvX64VK1ac8RjHcfTxj39cWVlZU5QKAAAAQKaZcInicUbUUbpdLufMC8caI5WF+t+aRmGRWQDjk52drVtuuUUej+esx86bN0+LFi2aglQAAAAAMtEES5So6gv2qDD7YGwXMdKCuvUKeo9O7HIAMtZVV12ltra2mI51uVz6xje+ocrKygSnAgAAAJCJJlSi5AcOa07lFjnj2FE02zOk1shOMY0CIFbNzc26++675Xa7Y35OSUmJVq1axZbHAAAAAOJuAiVKVG0lOxTyHxnXs4yRZkR2Mo0CIGZr1qxRTU3NuJ5jjNEHP/hBVVRUJCYUAAAAgIw17hIlL3BY0wrfmNDFsj1DWli3Xg5bHgM4i+bmZl177bUTem5paam++c1vxrSOCgAAAADEapwlSlTtJTvkdx+b0MWMkSpy96s81C9u6wFwJmvWrFFBQcGEn3/BBRdowYIF8QsEAAAAIOONq0SpzXtTjWfZ0vhsPK4R9VZtVpZnaOInAZDWLr30Ui1fvnxS5wgEArrnnntUWloap1QAAAAAMl3MJYrHdUxd5Vvldw9P+qIlOQOaUbxLTKMAeKecnBytXbtW4XB40ufq6enRjTfeOOnzAAAAAIA0jhKlJrxPkeBA3C7cEtmpbBaZBfAO73rXu9Td3R23861cuVLl5eVxOx8AAACAzBVziXJOxetyOfGbHAn5jqi9ZAeLzAIYY+3atePa0vhsamtrtXr1anm93ridEwAAAEBmirlEKco+FNcLGyN1lm1TSc6BuJ4XQGprb2+P+zlvv/12zZkzJ+7nBQAAAJBZxr3FcVwvbqLqLN0uF9MoABLI6/Xqtttuk8/nsx0FAAAAQAqzWqIYI1WH96k054BYZBZAIi1atEh9fX22YwAAAABIYVZLFElyu0Z0fv1r8ruP2Y4CII0FAgE9/PDDKigosB0FAAAAQIqyXqJIUq5/UM1Fu8U0CoBEqq+v14oVK2zHAAAAAJCikqJEMUZqK9nBNAqAhHIcR6tXr2YaBQAAAMCEJEWJIh2fRjmvdoOYRgGQSA0NDfra174mY4ztKAAAAABSTNKUKMZItfl7VRwcsB0FQJp797vfra6uLtsxAAAAAKSYpClRJMnrGtGssm1iGgVAIgWDQX384x9nGgUAAADAuCRViSJJtXlvanrxLtsxAKS5yy+/XDfeeKPtGAAAAABSSNKVKB7XiDpLt8vvHrIdBUAaCwQCuv3221lkFgAAAEDMkq5EkaT8rEOaVrDHdgwAaW7GjBlaunSp7RgAAAAAUkRSliiOkdpLtysvcMh2FABpzHEcfexjH1Nzc7PtKAAAAABSQFKWKJKUFzisWWXbZFhkFkACNTc364477pDb7bYdBQAAAECSS9oSxRipvmCPCrKYRgGQWFdddZVaW1ttxwAAAACQ5JK2RJEkv3tYHWXb5HKGbUcBkMbC4bBuueUW+f1+21EAAAAAJLGkLlEkqblo91uLzHJbD4DEuf7663XNNdfYjgEAAAAgiSV9ieIYqaN0uzzOiO0oANKYy+XSbbfdpmAwaDsKAAAAgCSV9CWKJBVlH1Q90ygAEqyzs1NXXnml7RgAAAAAklRKlCjGSOfWbFRe4LDtKADS3Fe/+lW2PAYAAABwSilRokiSz31M7SU7xDQKgETKz8/XmjVrZIyxHQUAAABAkkmZEsUYqalot+rz99qOAiDNrVixQldccYXtGAAAAACSTMqUKJLkcw+rs2ybPGx5DCCBQqGQPvGJT7DILAAAAIAxUqpEkaRIcEA1eW/ajgEgzZ1zzjlasmSJ7RgAAAAAkkjKlSguJ6pZ5VuV4xu0HQVAGvN6vbrjjjtUXV1tOwoAAACAJJFyJYokFWcfVBuLzAJIsK6uLt18880sMgsAAABAUoqWKMZIzUW7letnGgVAYl1//fWqq6uzHQMAAABAEkjJEkWSsr1DaivZIceM2I4CII2VlJRo9erV8ng8tqMAAAAAsCxlSxRJai/drqrwPtsxAKS5NWvWaNGiRbZjAAAAALAspUsUI2lW2Ta52PIYQAK5XC594hOfUCAQsB0FAAAAgEWpXaIYqSzUr6rc/WKRWQCJNH/+fF144YW2YwAAAACwKKVLFElyjLSwbr2C3qO2owBIY47j6KGHHlJlZaXtKAAAAAAsSfkSRZKyvUfVGtkpplEAJFJpaalWrlzJlscAAABAhkqLEsUYaUZkJ9MoABLKGKMPfvCDKi8vtx0FAAAAgAVpUaJIUrZnSOfVbpCLLY8BJFBpaam+9rWvyefz2Y4CAAAAYIqlTYlijFQV3qeyUL/tKADSmDFGixYt0rnnnms7CgAAAIApljYliiR5XCPqLNsmw9ooABIoKytLt912m1wul+0oAAAAAKZQWpUoklQR6lcLi8wCSLCFCxfqQx/6kO0YAAAAAKZQ2pUobteIusq3KtszZDsKgDTm9/v1qU99SmVlZbajAAAAAJgiaVeiSFLId0TTi3fZjgEgzdXW1uqGG26wHQMAAADAFEnLEsUYqSWyU/mBQ7ajAEhzK1euVEtLi+0YAAAAAKZAWpYo0vFplN6qzXLY8hhAAtXW1uree++V1+u1HQUAAABAgqVtiWKMVJ33pkqCA7ajAEhzixcvVnd3t+0YAAAAABIsbUsUSXI7UXWUbZPbGbYdBUAa8/l8uv322xUIBGxHAQAAAJBAaV2iSFJd/l62PAaQcJdffrlWrVplOwYAAACABEr7EsUxUlvJDvndx2xHAZDGHMfRzTffrPz8fNtRAAAAACRI2pcokhT2D2pezUYZplEAJFBDQ4MeeOABOU5GvLQCAAAAGcdtO8BUMEaqz9+rF4MD2jmQYztOWolGjQaHShSVK67ndcyg/J434npOINGMMbrqqqv0T//0T/rtb39rOw4AYJzcbrcWLVoU9zWuduzYoV/96ldxPScAwI6MKFEkyeceVkfpdv3slaAkYztOGjEaGg4pKk9cz+p2DkiiREHqCYVCuvXWW7V8+XLbUQAA4+Q4jhobG5WbmxvX8/p8PkoUAEgTGTVzXpu/V42FfDAHkFiXXXaZli1bZjsGAAAAgDjLqBLF6xrROeVb5XcP2Y4CII0Fg0GtXbtWBQUFtqMAAAAAiKOMKlEkqSDrkBoK9tiOASDNtba26j3veY/tGAAAAADiKONKFGOk9tLtyvUfth0FQBozxmj16tWqr6+3HQUAAABAnGRciSJJ+YHDOqd8K1seA0io1tZW3XnnnXK7M2YNbwAAACCtZWSJYozUULBHBVmHbEcBkObe8573qKWlxXYMAAAAAHGQkSWKdHzL4/bS7XLMiO0oANJYKBTSmjVr5PV6bUcBAAAAMEkZW6JI0vTiXZpWsEfith4ACXTDDTdo6dKltmMAAAAAmKSMLlEcI3WWbZPbYRoFQOK43W7ddtttys7Oth0FAAAAwCRkdIkiSYXZB1Wfv1dMowBIpI6ODl155ZW2YwAAAACYhIwvURwjza/ZqLwAWx4DSBzHcfTAAw+oubnZdhQAAAAAE5TxJYokBTxDaivZIaZRACRScXGxbr75ZtsxAAAAAEwQJYqOb3ncVPgG0ygAEu66665TU1OT7RgAAAAAJoAS5S0+9zHNq94kj+uY7SgA0lheXp6+/OUvKycnx3YUAAAAAONEifIWY6Sq8D7VhPfZjgIgzS1atEiLFy+2HQMAAADAOFGivI3Liaq9dLvczrDtKADSmMfj0Zo1a9jyGAAAAEgxlCjvEAkOaEbxLrHILIBE6u7u1gc+8AE5Di/DAAAAQKrg3fs7uJyoZle8rpDviO0oANKY1+vVunXrVFNTYzsKAAAAgBhRopxCtndIrWx5DCDBIpGIbrrpJhljbEcBAAAAEAO37QDJanrRbv11d5H2HsqSxAecMzFmWIrG+2c0EufzAcnp+uuv12OPPaaXXnrJdhQAgKTBwUF5PJ64nvPo0aNxPR8AwB4TjUZjGrf4w2WfT3SWpPP6/pB++JcZGo4ysHM60agUlSvu5zWKyhiKlIl6dM9C2xEwDs8995wWLVrEm2yknBjfQiQlJsBwOoFAIO7/fQwPD+vIEW4VnyheawBMhVhfa5hEOYOyUL8qw/u08c1821GSljGSEbsZAZMxf/58XXTRRfrxj39sOwoAZLzDhw/bjgAASGKMWJyBkbSwbr2CXn5zACBxXC6XvvnNb6qystJ2FAAAAABnQIlyBsZIQe9RtUZ2ikVmASRSZWWlVq5caTsGAAAAgDOgRDkLY6QZxbsU9LJWAYDEMcbogx/8oCoqKmxHAQAAAHAalCgxyPYe1dzqTXKx0CmABCotLdX9998vv99vOwoAAACAU6BEiYExUl3+XpWF+m1HAZDGjDG6/PLLNX/+fNtRAAAAAJwCJUqMPK4RdZRtk8M0CoAECgQCuvXWW+XxeGxHAQAAAPAOlCjjUBHqV2PhG2KRWQCJtGDBAi1btsx2DAAAAADvQIkyDh7XiHoqtyjLM2Q7CoA0lpWVpbvuukslJSW2owAAAAB4G0qUccr1H9H04l1iGgVAItXW1uqGG26wHQMAAADA21CiTEBrZKeymUYBkGCrVq1SWVmZ7RgAAAAA3mKi0SgjFQAAAAAAAGfBJAoAAAAAAEAMKFEAAAAAAABiQIkCAAAAAAAQA0oUAAAAAACAGFCiAAAAAAAAxIASBQAAAAAAIAaUKAAAAAAAADGgRAEAAAAAAIgBJQoAAAAAAEAM/h9Lw7cQ7VCU0gAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 1400x700 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load and display random samples\n",
    "image_ids = np.random.choice(dataset_val.image_ids, 3)\n",
    "for image_id in image_ids:\n",
    "    image = dataset_val.load_image(image_id)\n",
    "    cv2.imwrite(f\"./shape_test_images/shape_test_image_{image_id}.png\", image)\n",
    "    mask, class_ids = dataset_val.load_mask(image_id)\n",
    "    visualize.display_top_masks(image, mask, class_ids, dataset_val.class_names, limit=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Model and Load Trained Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "sometimes = lambda aug: iaa.Sometimes(0.5, aug)\n",
    "\n",
    "augmentation = iaa.Sequential([\n",
    "                                iaa.Fliplr(0.5), \n",
    "                                iaa.Flipud(0.5),\n",
    "                                #sometimes(iaa.Crop(percent=(0, 0.1))),\n",
    "                                sometimes(iaa.Affine(\n",
    "                                            #scale={\"x\": (0.8, 1.2), \"y\": (0.8, 1.2)},\n",
    "                                            #translate_percent={\"x\": (-0.2, 0.2), \"y\": (-0.2, 0.2)},\n",
    "                                            rotate=(-45, 45),\n",
    "                                            #shear=(-16, 16),\n",
    "                                            #order=[0, 1],\n",
    "                                            #cval=(0, 255),\n",
    "                                            #mode=ia.ALL\n",
    "                                            )\n",
    "                                        ),\n",
    "                            ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "dir_model = os.path.join(dir_root, \"logs/\")\n",
    "\n",
    "#COCO_MODEL_PATH = os.path.join(dir_root, \"shoes/mask_rcnn_coco.h5\")    \n",
    "#if not os.path.exists(COCO_MODEL_PATH):\n",
    "#    utils.download_trained_weights(COCO_MODEL_PATH)\n",
    "    \n",
    "# Create model object in inference mode.\n",
    "model = modellib.MaskRCNN(mode=\"training\", config=config, model_dir=dir_model)\n",
    "\n",
    "# Load weights trained on MS-COCO\n",
    "#model.load_weights(COCO_MODEL_PATH, by_name=True, exclude=[\"mrcnn_class_logits\", \"mrcnn_bbox_fc\", \"mrcnn_bbox\", \"mrcnn_mask\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "EPOCHS = [1,500]\n",
    "\n",
    "stop_early = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=50)\n",
    "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor=\"val_loss\", factor=0.1, patience=10, min_lr=1e-8)\n",
    "csv_logger_head = tf.keras.callbacks.CSVLogger(filename=config.NAME + \"_training.log\", append=False)\n",
    "csv_logger_all = tf.keras.callbacks.CSVLogger(filename=config.NAME + \"_training.log\", append=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'55_shapes_resnet_training.log'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename=config.NAME + \"_training.log\"\n",
    "filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selecting layers to train\n",
      "Model: \"mask_rcnn\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_image (InputLayer)    [(None, None, None, 3)]      0         []                            \n",
      "                                                                                                  \n",
      " zero_padding2d (ZeroPaddin  (None, None, None, 3)        0         ['input_image[0][0]']         \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv1 (Conv2D)              (None, None, None, 64)       9472      ['zero_padding2d[0][0]']      \n",
      "                                                                                                  \n",
      " bn_conv1 (BatchNorm)        (None, None, None, 64)       256       ['conv1[0][0]']               \n",
      "                                                                                                  \n",
      " activation (Activation)     (None, None, None, 64)       0         ['bn_conv1[0][0]']            \n",
      "                                                                                                  \n",
      " max_pooling2d (MaxPooling2  (None, None, None, 64)       0         ['activation[0][0]']          \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " res2a_branch2a (Conv2D)     (None, None, None, 64)       4160      ['max_pooling2d[0][0]']       \n",
      "                                                                                                  \n",
      " bn2a_branch2a (BatchNorm)   (None, None, None, 64)       256       ['res2a_branch2a[0][0]']      \n",
      "                                                                                                  \n",
      " activation_1 (Activation)   (None, None, None, 64)       0         ['bn2a_branch2a[0][0]']       \n",
      "                                                                                                  \n",
      " res2a_branch2b (Conv2D)     (None, None, None, 64)       36928     ['activation_1[0][0]']        \n",
      "                                                                                                  \n",
      " bn2a_branch2b (BatchNorm)   (None, None, None, 64)       256       ['res2a_branch2b[0][0]']      \n",
      "                                                                                                  \n",
      " activation_2 (Activation)   (None, None, None, 64)       0         ['bn2a_branch2b[0][0]']       \n",
      "                                                                                                  \n",
      " res2a_branch2c (Conv2D)     (None, None, None, 256)      16640     ['activation_2[0][0]']        \n",
      "                                                                                                  \n",
      " res2a_branch1 (Conv2D)      (None, None, None, 256)      16640     ['max_pooling2d[0][0]']       \n",
      "                                                                                                  \n",
      " bn2a_branch2c (BatchNorm)   (None, None, None, 256)      1024      ['res2a_branch2c[0][0]']      \n",
      "                                                                                                  \n",
      " bn2a_branch1 (BatchNorm)    (None, None, None, 256)      1024      ['res2a_branch1[0][0]']       \n",
      "                                                                                                  \n",
      " add (Add)                   (None, None, None, 256)      0         ['bn2a_branch2c[0][0]',       \n",
      "                                                                     'bn2a_branch1[0][0]']        \n",
      "                                                                                                  \n",
      " res2a_out (Activation)      (None, None, None, 256)      0         ['add[0][0]']                 \n",
      "                                                                                                  \n",
      " res2b_branch2a (Conv2D)     (None, None, None, 64)       16448     ['res2a_out[0][0]']           \n",
      "                                                                                                  \n",
      " bn2b_branch2a (BatchNorm)   (None, None, None, 64)       256       ['res2b_branch2a[0][0]']      \n",
      "                                                                                                  \n",
      " activation_3 (Activation)   (None, None, None, 64)       0         ['bn2b_branch2a[0][0]']       \n",
      "                                                                                                  \n",
      " res2b_branch2b (Conv2D)     (None, None, None, 64)       36928     ['activation_3[0][0]']        \n",
      "                                                                                                  \n",
      " bn2b_branch2b (BatchNorm)   (None, None, None, 64)       256       ['res2b_branch2b[0][0]']      \n",
      "                                                                                                  \n",
      " activation_4 (Activation)   (None, None, None, 64)       0         ['bn2b_branch2b[0][0]']       \n",
      "                                                                                                  \n",
      " res2b_branch2c (Conv2D)     (None, None, None, 256)      16640     ['activation_4[0][0]']        \n",
      "                                                                                                  \n",
      " bn2b_branch2c (BatchNorm)   (None, None, None, 256)      1024      ['res2b_branch2c[0][0]']      \n",
      "                                                                                                  \n",
      " add_1 (Add)                 (None, None, None, 256)      0         ['bn2b_branch2c[0][0]',       \n",
      "                                                                     'res2a_out[0][0]']           \n",
      "                                                                                                  \n",
      " res2b_out (Activation)      (None, None, None, 256)      0         ['add_1[0][0]']               \n",
      "                                                                                                  \n",
      " res2c_branch2a (Conv2D)     (None, None, None, 64)       16448     ['res2b_out[0][0]']           \n",
      "                                                                                                  \n",
      " bn2c_branch2a (BatchNorm)   (None, None, None, 64)       256       ['res2c_branch2a[0][0]']      \n",
      "                                                                                                  \n",
      " activation_5 (Activation)   (None, None, None, 64)       0         ['bn2c_branch2a[0][0]']       \n",
      "                                                                                                  \n",
      " res2c_branch2b (Conv2D)     (None, None, None, 64)       36928     ['activation_5[0][0]']        \n",
      "                                                                                                  \n",
      " bn2c_branch2b (BatchNorm)   (None, None, None, 64)       256       ['res2c_branch2b[0][0]']      \n",
      "                                                                                                  \n",
      " activation_6 (Activation)   (None, None, None, 64)       0         ['bn2c_branch2b[0][0]']       \n",
      "                                                                                                  \n",
      " res2c_branch2c (Conv2D)     (None, None, None, 256)      16640     ['activation_6[0][0]']        \n",
      "                                                                                                  \n",
      " bn2c_branch2c (BatchNorm)   (None, None, None, 256)      1024      ['res2c_branch2c[0][0]']      \n",
      "                                                                                                  \n",
      " add_2 (Add)                 (None, None, None, 256)      0         ['bn2c_branch2c[0][0]',       \n",
      "                                                                     'res2b_out[0][0]']           \n",
      "                                                                                                  \n",
      " res2c_out (Activation)      (None, None, None, 256)      0         ['add_2[0][0]']               \n",
      "                                                                                                  \n",
      " res3a_branch2a (Conv2D)     (None, None, None, 128)      32896     ['res2c_out[0][0]']           \n",
      "                                                                                                  \n",
      " bn3a_branch2a (BatchNorm)   (None, None, None, 128)      512       ['res3a_branch2a[0][0]']      \n",
      "                                                                                                  \n",
      " activation_7 (Activation)   (None, None, None, 128)      0         ['bn3a_branch2a[0][0]']       \n",
      "                                                                                                  \n",
      " res3a_branch2b (Conv2D)     (None, None, None, 128)      147584    ['activation_7[0][0]']        \n",
      "                                                                                                  \n",
      " bn3a_branch2b (BatchNorm)   (None, None, None, 128)      512       ['res3a_branch2b[0][0]']      \n",
      "                                                                                                  \n",
      " activation_8 (Activation)   (None, None, None, 128)      0         ['bn3a_branch2b[0][0]']       \n",
      "                                                                                                  \n",
      " res3a_branch2c (Conv2D)     (None, None, None, 512)      66048     ['activation_8[0][0]']        \n",
      "                                                                                                  \n",
      " res3a_branch1 (Conv2D)      (None, None, None, 512)      131584    ['res2c_out[0][0]']           \n",
      "                                                                                                  \n",
      " bn3a_branch2c (BatchNorm)   (None, None, None, 512)      2048      ['res3a_branch2c[0][0]']      \n",
      "                                                                                                  \n",
      " bn3a_branch1 (BatchNorm)    (None, None, None, 512)      2048      ['res3a_branch1[0][0]']       \n",
      "                                                                                                  \n",
      " add_3 (Add)                 (None, None, None, 512)      0         ['bn3a_branch2c[0][0]',       \n",
      "                                                                     'bn3a_branch1[0][0]']        \n",
      "                                                                                                  \n",
      " res3a_out (Activation)      (None, None, None, 512)      0         ['add_3[0][0]']               \n",
      "                                                                                                  \n",
      " res3b_branch2a (Conv2D)     (None, None, None, 128)      65664     ['res3a_out[0][0]']           \n",
      "                                                                                                  \n",
      " bn3b_branch2a (BatchNorm)   (None, None, None, 128)      512       ['res3b_branch2a[0][0]']      \n",
      "                                                                                                  \n",
      " activation_9 (Activation)   (None, None, None, 128)      0         ['bn3b_branch2a[0][0]']       \n",
      "                                                                                                  \n",
      " res3b_branch2b (Conv2D)     (None, None, None, 128)      147584    ['activation_9[0][0]']        \n",
      "                                                                                                  \n",
      " bn3b_branch2b (BatchNorm)   (None, None, None, 128)      512       ['res3b_branch2b[0][0]']      \n",
      "                                                                                                  \n",
      " activation_10 (Activation)  (None, None, None, 128)      0         ['bn3b_branch2b[0][0]']       \n",
      "                                                                                                  \n",
      " res3b_branch2c (Conv2D)     (None, None, None, 512)      66048     ['activation_10[0][0]']       \n",
      "                                                                                                  \n",
      " bn3b_branch2c (BatchNorm)   (None, None, None, 512)      2048      ['res3b_branch2c[0][0]']      \n",
      "                                                                                                  \n",
      " add_4 (Add)                 (None, None, None, 512)      0         ['bn3b_branch2c[0][0]',       \n",
      "                                                                     'res3a_out[0][0]']           \n",
      "                                                                                                  \n",
      " res3b_out (Activation)      (None, None, None, 512)      0         ['add_4[0][0]']               \n",
      "                                                                                                  \n",
      " res3c_branch2a (Conv2D)     (None, None, None, 128)      65664     ['res3b_out[0][0]']           \n",
      "                                                                                                  \n",
      " bn3c_branch2a (BatchNorm)   (None, None, None, 128)      512       ['res3c_branch2a[0][0]']      \n",
      "                                                                                                  \n",
      " activation_11 (Activation)  (None, None, None, 128)      0         ['bn3c_branch2a[0][0]']       \n",
      "                                                                                                  \n",
      " res3c_branch2b (Conv2D)     (None, None, None, 128)      147584    ['activation_11[0][0]']       \n",
      "                                                                                                  \n",
      " bn3c_branch2b (BatchNorm)   (None, None, None, 128)      512       ['res3c_branch2b[0][0]']      \n",
      "                                                                                                  \n",
      " activation_12 (Activation)  (None, None, None, 128)      0         ['bn3c_branch2b[0][0]']       \n",
      "                                                                                                  \n",
      " res3c_branch2c (Conv2D)     (None, None, None, 512)      66048     ['activation_12[0][0]']       \n",
      "                                                                                                  \n",
      " bn3c_branch2c (BatchNorm)   (None, None, None, 512)      2048      ['res3c_branch2c[0][0]']      \n",
      "                                                                                                  \n",
      " add_5 (Add)                 (None, None, None, 512)      0         ['bn3c_branch2c[0][0]',       \n",
      "                                                                     'res3b_out[0][0]']           \n",
      "                                                                                                  \n",
      " res3c_out (Activation)      (None, None, None, 512)      0         ['add_5[0][0]']               \n",
      "                                                                                                  \n",
      " res3d_branch2a (Conv2D)     (None, None, None, 128)      65664     ['res3c_out[0][0]']           \n",
      "                                                                                                  \n",
      " bn3d_branch2a (BatchNorm)   (None, None, None, 128)      512       ['res3d_branch2a[0][0]']      \n",
      "                                                                                                  \n",
      " activation_13 (Activation)  (None, None, None, 128)      0         ['bn3d_branch2a[0][0]']       \n",
      "                                                                                                  \n",
      " res3d_branch2b (Conv2D)     (None, None, None, 128)      147584    ['activation_13[0][0]']       \n",
      "                                                                                                  \n",
      " bn3d_branch2b (BatchNorm)   (None, None, None, 128)      512       ['res3d_branch2b[0][0]']      \n",
      "                                                                                                  \n",
      " activation_14 (Activation)  (None, None, None, 128)      0         ['bn3d_branch2b[0][0]']       \n",
      "                                                                                                  \n",
      " res3d_branch2c (Conv2D)     (None, None, None, 512)      66048     ['activation_14[0][0]']       \n",
      "                                                                                                  \n",
      " bn3d_branch2c (BatchNorm)   (None, None, None, 512)      2048      ['res3d_branch2c[0][0]']      \n",
      "                                                                                                  \n",
      " add_6 (Add)                 (None, None, None, 512)      0         ['bn3d_branch2c[0][0]',       \n",
      "                                                                     'res3c_out[0][0]']           \n",
      "                                                                                                  \n",
      " res3d_out (Activation)      (None, None, None, 512)      0         ['add_6[0][0]']               \n",
      "                                                                                                  \n",
      " res4a_branch2a (Conv2D)     (None, None, None, 256)      131328    ['res3d_out[0][0]']           \n",
      "                                                                                                  \n",
      " bn4a_branch2a (BatchNorm)   (None, None, None, 256)      1024      ['res4a_branch2a[0][0]']      \n",
      "                                                                                                  \n",
      " activation_15 (Activation)  (None, None, None, 256)      0         ['bn4a_branch2a[0][0]']       \n",
      "                                                                                                  \n",
      " res4a_branch2b (Conv2D)     (None, None, None, 256)      590080    ['activation_15[0][0]']       \n",
      "                                                                                                  \n",
      " bn4a_branch2b (BatchNorm)   (None, None, None, 256)      1024      ['res4a_branch2b[0][0]']      \n",
      "                                                                                                  \n",
      " activation_16 (Activation)  (None, None, None, 256)      0         ['bn4a_branch2b[0][0]']       \n",
      "                                                                                                  \n",
      " res4a_branch2c (Conv2D)     (None, None, None, 1024)     263168    ['activation_16[0][0]']       \n",
      "                                                                                                  \n",
      " res4a_branch1 (Conv2D)      (None, None, None, 1024)     525312    ['res3d_out[0][0]']           \n",
      "                                                                                                  \n",
      " bn4a_branch2c (BatchNorm)   (None, None, None, 1024)     4096      ['res4a_branch2c[0][0]']      \n",
      "                                                                                                  \n",
      " bn4a_branch1 (BatchNorm)    (None, None, None, 1024)     4096      ['res4a_branch1[0][0]']       \n",
      "                                                                                                  \n",
      " add_7 (Add)                 (None, None, None, 1024)     0         ['bn4a_branch2c[0][0]',       \n",
      "                                                                     'bn4a_branch1[0][0]']        \n",
      "                                                                                                  \n",
      " res4a_out (Activation)      (None, None, None, 1024)     0         ['add_7[0][0]']               \n",
      "                                                                                                  \n",
      " res4b_branch2a (Conv2D)     (None, None, None, 256)      262400    ['res4a_out[0][0]']           \n",
      "                                                                                                  \n",
      " bn4b_branch2a (BatchNorm)   (None, None, None, 256)      1024      ['res4b_branch2a[0][0]']      \n",
      "                                                                                                  \n",
      " activation_17 (Activation)  (None, None, None, 256)      0         ['bn4b_branch2a[0][0]']       \n",
      "                                                                                                  \n",
      " res4b_branch2b (Conv2D)     (None, None, None, 256)      590080    ['activation_17[0][0]']       \n",
      "                                                                                                  \n",
      " bn4b_branch2b (BatchNorm)   (None, None, None, 256)      1024      ['res4b_branch2b[0][0]']      \n",
      "                                                                                                  \n",
      " activation_18 (Activation)  (None, None, None, 256)      0         ['bn4b_branch2b[0][0]']       \n",
      "                                                                                                  \n",
      " res4b_branch2c (Conv2D)     (None, None, None, 1024)     263168    ['activation_18[0][0]']       \n",
      "                                                                                                  \n",
      " bn4b_branch2c (BatchNorm)   (None, None, None, 1024)     4096      ['res4b_branch2c[0][0]']      \n",
      "                                                                                                  \n",
      " add_8 (Add)                 (None, None, None, 1024)     0         ['bn4b_branch2c[0][0]',       \n",
      "                                                                     'res4a_out[0][0]']           \n",
      "                                                                                                  \n",
      " res4b_out (Activation)      (None, None, None, 1024)     0         ['add_8[0][0]']               \n",
      "                                                                                                  \n",
      " res4c_branch2a (Conv2D)     (None, None, None, 256)      262400    ['res4b_out[0][0]']           \n",
      "                                                                                                  \n",
      " bn4c_branch2a (BatchNorm)   (None, None, None, 256)      1024      ['res4c_branch2a[0][0]']      \n",
      "                                                                                                  \n",
      " activation_19 (Activation)  (None, None, None, 256)      0         ['bn4c_branch2a[0][0]']       \n",
      "                                                                                                  \n",
      " res4c_branch2b (Conv2D)     (None, None, None, 256)      590080    ['activation_19[0][0]']       \n",
      "                                                                                                  \n",
      " bn4c_branch2b (BatchNorm)   (None, None, None, 256)      1024      ['res4c_branch2b[0][0]']      \n",
      "                                                                                                  \n",
      " activation_20 (Activation)  (None, None, None, 256)      0         ['bn4c_branch2b[0][0]']       \n",
      "                                                                                                  \n",
      " res4c_branch2c (Conv2D)     (None, None, None, 1024)     263168    ['activation_20[0][0]']       \n",
      "                                                                                                  \n",
      " bn4c_branch2c (BatchNorm)   (None, None, None, 1024)     4096      ['res4c_branch2c[0][0]']      \n",
      "                                                                                                  \n",
      " add_9 (Add)                 (None, None, None, 1024)     0         ['bn4c_branch2c[0][0]',       \n",
      "                                                                     'res4b_out[0][0]']           \n",
      "                                                                                                  \n",
      " res4c_out (Activation)      (None, None, None, 1024)     0         ['add_9[0][0]']               \n",
      "                                                                                                  \n",
      " res4d_branch2a (Conv2D)     (None, None, None, 256)      262400    ['res4c_out[0][0]']           \n",
      "                                                                                                  \n",
      " bn4d_branch2a (BatchNorm)   (None, None, None, 256)      1024      ['res4d_branch2a[0][0]']      \n",
      "                                                                                                  \n",
      " activation_21 (Activation)  (None, None, None, 256)      0         ['bn4d_branch2a[0][0]']       \n",
      "                                                                                                  \n",
      " res4d_branch2b (Conv2D)     (None, None, None, 256)      590080    ['activation_21[0][0]']       \n",
      "                                                                                                  \n",
      " bn4d_branch2b (BatchNorm)   (None, None, None, 256)      1024      ['res4d_branch2b[0][0]']      \n",
      "                                                                                                  \n",
      " activation_22 (Activation)  (None, None, None, 256)      0         ['bn4d_branch2b[0][0]']       \n",
      "                                                                                                  \n",
      " res4d_branch2c (Conv2D)     (None, None, None, 1024)     263168    ['activation_22[0][0]']       \n",
      "                                                                                                  \n",
      " bn4d_branch2c (BatchNorm)   (None, None, None, 1024)     4096      ['res4d_branch2c[0][0]']      \n",
      "                                                                                                  \n",
      " add_10 (Add)                (None, None, None, 1024)     0         ['bn4d_branch2c[0][0]',       \n",
      "                                                                     'res4c_out[0][0]']           \n",
      "                                                                                                  \n",
      " res4d_out (Activation)      (None, None, None, 1024)     0         ['add_10[0][0]']              \n",
      "                                                                                                  \n",
      " res4e_branch2a (Conv2D)     (None, None, None, 256)      262400    ['res4d_out[0][0]']           \n",
      "                                                                                                  \n",
      " bn4e_branch2a (BatchNorm)   (None, None, None, 256)      1024      ['res4e_branch2a[0][0]']      \n",
      "                                                                                                  \n",
      " activation_23 (Activation)  (None, None, None, 256)      0         ['bn4e_branch2a[0][0]']       \n",
      "                                                                                                  \n",
      " res4e_branch2b (Conv2D)     (None, None, None, 256)      590080    ['activation_23[0][0]']       \n",
      "                                                                                                  \n",
      " bn4e_branch2b (BatchNorm)   (None, None, None, 256)      1024      ['res4e_branch2b[0][0]']      \n",
      "                                                                                                  \n",
      " activation_24 (Activation)  (None, None, None, 256)      0         ['bn4e_branch2b[0][0]']       \n",
      "                                                                                                  \n",
      " res4e_branch2c (Conv2D)     (None, None, None, 1024)     263168    ['activation_24[0][0]']       \n",
      "                                                                                                  \n",
      " bn4e_branch2c (BatchNorm)   (None, None, None, 1024)     4096      ['res4e_branch2c[0][0]']      \n",
      "                                                                                                  \n",
      " add_11 (Add)                (None, None, None, 1024)     0         ['bn4e_branch2c[0][0]',       \n",
      "                                                                     'res4d_out[0][0]']           \n",
      "                                                                                                  \n",
      " res4e_out (Activation)      (None, None, None, 1024)     0         ['add_11[0][0]']              \n",
      "                                                                                                  \n",
      " res4f_branch2a (Conv2D)     (None, None, None, 256)      262400    ['res4e_out[0][0]']           \n",
      "                                                                                                  \n",
      " bn4f_branch2a (BatchNorm)   (None, None, None, 256)      1024      ['res4f_branch2a[0][0]']      \n",
      "                                                                                                  \n",
      " activation_25 (Activation)  (None, None, None, 256)      0         ['bn4f_branch2a[0][0]']       \n",
      "                                                                                                  \n",
      " res4f_branch2b (Conv2D)     (None, None, None, 256)      590080    ['activation_25[0][0]']       \n",
      "                                                                                                  \n",
      " bn4f_branch2b (BatchNorm)   (None, None, None, 256)      1024      ['res4f_branch2b[0][0]']      \n",
      "                                                                                                  \n",
      " activation_26 (Activation)  (None, None, None, 256)      0         ['bn4f_branch2b[0][0]']       \n",
      "                                                                                                  \n",
      " res4f_branch2c (Conv2D)     (None, None, None, 1024)     263168    ['activation_26[0][0]']       \n",
      "                                                                                                  \n",
      " bn4f_branch2c (BatchNorm)   (None, None, None, 1024)     4096      ['res4f_branch2c[0][0]']      \n",
      "                                                                                                  \n",
      " add_12 (Add)                (None, None, None, 1024)     0         ['bn4f_branch2c[0][0]',       \n",
      "                                                                     'res4e_out[0][0]']           \n",
      "                                                                                                  \n",
      " res4f_out (Activation)      (None, None, None, 1024)     0         ['add_12[0][0]']              \n",
      "                                                                                                  \n",
      " res4g_branch2a (Conv2D)     (None, None, None, 256)      262400    ['res4f_out[0][0]']           \n",
      "                                                                                                  \n",
      " bn4g_branch2a (BatchNorm)   (None, None, None, 256)      1024      ['res4g_branch2a[0][0]']      \n",
      "                                                                                                  \n",
      " activation_27 (Activation)  (None, None, None, 256)      0         ['bn4g_branch2a[0][0]']       \n",
      "                                                                                                  \n",
      " res4g_branch2b (Conv2D)     (None, None, None, 256)      590080    ['activation_27[0][0]']       \n",
      "                                                                                                  \n",
      " bn4g_branch2b (BatchNorm)   (None, None, None, 256)      1024      ['res4g_branch2b[0][0]']      \n",
      "                                                                                                  \n",
      " activation_28 (Activation)  (None, None, None, 256)      0         ['bn4g_branch2b[0][0]']       \n",
      "                                                                                                  \n",
      " res4g_branch2c (Conv2D)     (None, None, None, 1024)     263168    ['activation_28[0][0]']       \n",
      "                                                                                                  \n",
      " bn4g_branch2c (BatchNorm)   (None, None, None, 1024)     4096      ['res4g_branch2c[0][0]']      \n",
      "                                                                                                  \n",
      " add_13 (Add)                (None, None, None, 1024)     0         ['bn4g_branch2c[0][0]',       \n",
      "                                                                     'res4f_out[0][0]']           \n",
      "                                                                                                  \n",
      " res4g_out (Activation)      (None, None, None, 1024)     0         ['add_13[0][0]']              \n",
      "                                                                                                  \n",
      " res4h_branch2a (Conv2D)     (None, None, None, 256)      262400    ['res4g_out[0][0]']           \n",
      "                                                                                                  \n",
      " bn4h_branch2a (BatchNorm)   (None, None, None, 256)      1024      ['res4h_branch2a[0][0]']      \n",
      "                                                                                                  \n",
      " activation_29 (Activation)  (None, None, None, 256)      0         ['bn4h_branch2a[0][0]']       \n",
      "                                                                                                  \n",
      " res4h_branch2b (Conv2D)     (None, None, None, 256)      590080    ['activation_29[0][0]']       \n",
      "                                                                                                  \n",
      " bn4h_branch2b (BatchNorm)   (None, None, None, 256)      1024      ['res4h_branch2b[0][0]']      \n",
      "                                                                                                  \n",
      " activation_30 (Activation)  (None, None, None, 256)      0         ['bn4h_branch2b[0][0]']       \n",
      "                                                                                                  \n",
      " res4h_branch2c (Conv2D)     (None, None, None, 1024)     263168    ['activation_30[0][0]']       \n",
      "                                                                                                  \n",
      " bn4h_branch2c (BatchNorm)   (None, None, None, 1024)     4096      ['res4h_branch2c[0][0]']      \n",
      "                                                                                                  \n",
      " add_14 (Add)                (None, None, None, 1024)     0         ['bn4h_branch2c[0][0]',       \n",
      "                                                                     'res4g_out[0][0]']           \n",
      "                                                                                                  \n",
      " res4h_out (Activation)      (None, None, None, 1024)     0         ['add_14[0][0]']              \n",
      "                                                                                                  \n",
      " res4i_branch2a (Conv2D)     (None, None, None, 256)      262400    ['res4h_out[0][0]']           \n",
      "                                                                                                  \n",
      " bn4i_branch2a (BatchNorm)   (None, None, None, 256)      1024      ['res4i_branch2a[0][0]']      \n",
      "                                                                                                  \n",
      " activation_31 (Activation)  (None, None, None, 256)      0         ['bn4i_branch2a[0][0]']       \n",
      "                                                                                                  \n",
      " res4i_branch2b (Conv2D)     (None, None, None, 256)      590080    ['activation_31[0][0]']       \n",
      "                                                                                                  \n",
      " bn4i_branch2b (BatchNorm)   (None, None, None, 256)      1024      ['res4i_branch2b[0][0]']      \n",
      "                                                                                                  \n",
      " activation_32 (Activation)  (None, None, None, 256)      0         ['bn4i_branch2b[0][0]']       \n",
      "                                                                                                  \n",
      " res4i_branch2c (Conv2D)     (None, None, None, 1024)     263168    ['activation_32[0][0]']       \n",
      "                                                                                                  \n",
      " bn4i_branch2c (BatchNorm)   (None, None, None, 1024)     4096      ['res4i_branch2c[0][0]']      \n",
      "                                                                                                  \n",
      " add_15 (Add)                (None, None, None, 1024)     0         ['bn4i_branch2c[0][0]',       \n",
      "                                                                     'res4h_out[0][0]']           \n",
      "                                                                                                  \n",
      " res4i_out (Activation)      (None, None, None, 1024)     0         ['add_15[0][0]']              \n",
      "                                                                                                  \n",
      " res4j_branch2a (Conv2D)     (None, None, None, 256)      262400    ['res4i_out[0][0]']           \n",
      "                                                                                                  \n",
      " bn4j_branch2a (BatchNorm)   (None, None, None, 256)      1024      ['res4j_branch2a[0][0]']      \n",
      "                                                                                                  \n",
      " activation_33 (Activation)  (None, None, None, 256)      0         ['bn4j_branch2a[0][0]']       \n",
      "                                                                                                  \n",
      " res4j_branch2b (Conv2D)     (None, None, None, 256)      590080    ['activation_33[0][0]']       \n",
      "                                                                                                  \n",
      " bn4j_branch2b (BatchNorm)   (None, None, None, 256)      1024      ['res4j_branch2b[0][0]']      \n",
      "                                                                                                  \n",
      " activation_34 (Activation)  (None, None, None, 256)      0         ['bn4j_branch2b[0][0]']       \n",
      "                                                                                                  \n",
      " res4j_branch2c (Conv2D)     (None, None, None, 1024)     263168    ['activation_34[0][0]']       \n",
      "                                                                                                  \n",
      " bn4j_branch2c (BatchNorm)   (None, None, None, 1024)     4096      ['res4j_branch2c[0][0]']      \n",
      "                                                                                                  \n",
      " add_16 (Add)                (None, None, None, 1024)     0         ['bn4j_branch2c[0][0]',       \n",
      "                                                                     'res4i_out[0][0]']           \n",
      "                                                                                                  \n",
      " res4j_out (Activation)      (None, None, None, 1024)     0         ['add_16[0][0]']              \n",
      "                                                                                                  \n",
      " res4k_branch2a (Conv2D)     (None, None, None, 256)      262400    ['res4j_out[0][0]']           \n",
      "                                                                                                  \n",
      " bn4k_branch2a (BatchNorm)   (None, None, None, 256)      1024      ['res4k_branch2a[0][0]']      \n",
      "                                                                                                  \n",
      " activation_35 (Activation)  (None, None, None, 256)      0         ['bn4k_branch2a[0][0]']       \n",
      "                                                                                                  \n",
      " res4k_branch2b (Conv2D)     (None, None, None, 256)      590080    ['activation_35[0][0]']       \n",
      "                                                                                                  \n",
      " bn4k_branch2b (BatchNorm)   (None, None, None, 256)      1024      ['res4k_branch2b[0][0]']      \n",
      "                                                                                                  \n",
      " activation_36 (Activation)  (None, None, None, 256)      0         ['bn4k_branch2b[0][0]']       \n",
      "                                                                                                  \n",
      " res4k_branch2c (Conv2D)     (None, None, None, 1024)     263168    ['activation_36[0][0]']       \n",
      "                                                                                                  \n",
      " bn4k_branch2c (BatchNorm)   (None, None, None, 1024)     4096      ['res4k_branch2c[0][0]']      \n",
      "                                                                                                  \n",
      " add_17 (Add)                (None, None, None, 1024)     0         ['bn4k_branch2c[0][0]',       \n",
      "                                                                     'res4j_out[0][0]']           \n",
      "                                                                                                  \n",
      " res4k_out (Activation)      (None, None, None, 1024)     0         ['add_17[0][0]']              \n",
      "                                                                                                  \n",
      " res4l_branch2a (Conv2D)     (None, None, None, 256)      262400    ['res4k_out[0][0]']           \n",
      "                                                                                                  \n",
      " bn4l_branch2a (BatchNorm)   (None, None, None, 256)      1024      ['res4l_branch2a[0][0]']      \n",
      "                                                                                                  \n",
      " activation_37 (Activation)  (None, None, None, 256)      0         ['bn4l_branch2a[0][0]']       \n",
      "                                                                                                  \n",
      " res4l_branch2b (Conv2D)     (None, None, None, 256)      590080    ['activation_37[0][0]']       \n",
      "                                                                                                  \n",
      " bn4l_branch2b (BatchNorm)   (None, None, None, 256)      1024      ['res4l_branch2b[0][0]']      \n",
      "                                                                                                  \n",
      " activation_38 (Activation)  (None, None, None, 256)      0         ['bn4l_branch2b[0][0]']       \n",
      "                                                                                                  \n",
      " res4l_branch2c (Conv2D)     (None, None, None, 1024)     263168    ['activation_38[0][0]']       \n",
      "                                                                                                  \n",
      " bn4l_branch2c (BatchNorm)   (None, None, None, 1024)     4096      ['res4l_branch2c[0][0]']      \n",
      "                                                                                                  \n",
      " add_18 (Add)                (None, None, None, 1024)     0         ['bn4l_branch2c[0][0]',       \n",
      "                                                                     'res4k_out[0][0]']           \n",
      "                                                                                                  \n",
      " res4l_out (Activation)      (None, None, None, 1024)     0         ['add_18[0][0]']              \n",
      "                                                                                                  \n",
      " res4m_branch2a (Conv2D)     (None, None, None, 256)      262400    ['res4l_out[0][0]']           \n",
      "                                                                                                  \n",
      " bn4m_branch2a (BatchNorm)   (None, None, None, 256)      1024      ['res4m_branch2a[0][0]']      \n",
      "                                                                                                  \n",
      " activation_39 (Activation)  (None, None, None, 256)      0         ['bn4m_branch2a[0][0]']       \n",
      "                                                                                                  \n",
      " res4m_branch2b (Conv2D)     (None, None, None, 256)      590080    ['activation_39[0][0]']       \n",
      "                                                                                                  \n",
      " bn4m_branch2b (BatchNorm)   (None, None, None, 256)      1024      ['res4m_branch2b[0][0]']      \n",
      "                                                                                                  \n",
      " activation_40 (Activation)  (None, None, None, 256)      0         ['bn4m_branch2b[0][0]']       \n",
      "                                                                                                  \n",
      " res4m_branch2c (Conv2D)     (None, None, None, 1024)     263168    ['activation_40[0][0]']       \n",
      "                                                                                                  \n",
      " bn4m_branch2c (BatchNorm)   (None, None, None, 1024)     4096      ['res4m_branch2c[0][0]']      \n",
      "                                                                                                  \n",
      " add_19 (Add)                (None, None, None, 1024)     0         ['bn4m_branch2c[0][0]',       \n",
      "                                                                     'res4l_out[0][0]']           \n",
      "                                                                                                  \n",
      " res4m_out (Activation)      (None, None, None, 1024)     0         ['add_19[0][0]']              \n",
      "                                                                                                  \n",
      " res4n_branch2a (Conv2D)     (None, None, None, 256)      262400    ['res4m_out[0][0]']           \n",
      "                                                                                                  \n",
      " bn4n_branch2a (BatchNorm)   (None, None, None, 256)      1024      ['res4n_branch2a[0][0]']      \n",
      "                                                                                                  \n",
      " activation_41 (Activation)  (None, None, None, 256)      0         ['bn4n_branch2a[0][0]']       \n",
      "                                                                                                  \n",
      " res4n_branch2b (Conv2D)     (None, None, None, 256)      590080    ['activation_41[0][0]']       \n",
      "                                                                                                  \n",
      " bn4n_branch2b (BatchNorm)   (None, None, None, 256)      1024      ['res4n_branch2b[0][0]']      \n",
      "                                                                                                  \n",
      " activation_42 (Activation)  (None, None, None, 256)      0         ['bn4n_branch2b[0][0]']       \n",
      "                                                                                                  \n",
      " res4n_branch2c (Conv2D)     (None, None, None, 1024)     263168    ['activation_42[0][0]']       \n",
      "                                                                                                  \n",
      " bn4n_branch2c (BatchNorm)   (None, None, None, 1024)     4096      ['res4n_branch2c[0][0]']      \n",
      "                                                                                                  \n",
      " add_20 (Add)                (None, None, None, 1024)     0         ['bn4n_branch2c[0][0]',       \n",
      "                                                                     'res4m_out[0][0]']           \n",
      "                                                                                                  \n",
      " res4n_out (Activation)      (None, None, None, 1024)     0         ['add_20[0][0]']              \n",
      "                                                                                                  \n",
      " res4o_branch2a (Conv2D)     (None, None, None, 256)      262400    ['res4n_out[0][0]']           \n",
      "                                                                                                  \n",
      " bn4o_branch2a (BatchNorm)   (None, None, None, 256)      1024      ['res4o_branch2a[0][0]']      \n",
      "                                                                                                  \n",
      " activation_43 (Activation)  (None, None, None, 256)      0         ['bn4o_branch2a[0][0]']       \n",
      "                                                                                                  \n",
      " res4o_branch2b (Conv2D)     (None, None, None, 256)      590080    ['activation_43[0][0]']       \n",
      "                                                                                                  \n",
      " bn4o_branch2b (BatchNorm)   (None, None, None, 256)      1024      ['res4o_branch2b[0][0]']      \n",
      "                                                                                                  \n",
      " activation_44 (Activation)  (None, None, None, 256)      0         ['bn4o_branch2b[0][0]']       \n",
      "                                                                                                  \n",
      " res4o_branch2c (Conv2D)     (None, None, None, 1024)     263168    ['activation_44[0][0]']       \n",
      "                                                                                                  \n",
      " bn4o_branch2c (BatchNorm)   (None, None, None, 1024)     4096      ['res4o_branch2c[0][0]']      \n",
      "                                                                                                  \n",
      " add_21 (Add)                (None, None, None, 1024)     0         ['bn4o_branch2c[0][0]',       \n",
      "                                                                     'res4n_out[0][0]']           \n",
      "                                                                                                  \n",
      " res4o_out (Activation)      (None, None, None, 1024)     0         ['add_21[0][0]']              \n",
      "                                                                                                  \n",
      " res4p_branch2a (Conv2D)     (None, None, None, 256)      262400    ['res4o_out[0][0]']           \n",
      "                                                                                                  \n",
      " bn4p_branch2a (BatchNorm)   (None, None, None, 256)      1024      ['res4p_branch2a[0][0]']      \n",
      "                                                                                                  \n",
      " activation_45 (Activation)  (None, None, None, 256)      0         ['bn4p_branch2a[0][0]']       \n",
      "                                                                                                  \n",
      " res4p_branch2b (Conv2D)     (None, None, None, 256)      590080    ['activation_45[0][0]']       \n",
      "                                                                                                  \n",
      " bn4p_branch2b (BatchNorm)   (None, None, None, 256)      1024      ['res4p_branch2b[0][0]']      \n",
      "                                                                                                  \n",
      " activation_46 (Activation)  (None, None, None, 256)      0         ['bn4p_branch2b[0][0]']       \n",
      "                                                                                                  \n",
      " res4p_branch2c (Conv2D)     (None, None, None, 1024)     263168    ['activation_46[0][0]']       \n",
      "                                                                                                  \n",
      " bn4p_branch2c (BatchNorm)   (None, None, None, 1024)     4096      ['res4p_branch2c[0][0]']      \n",
      "                                                                                                  \n",
      " add_22 (Add)                (None, None, None, 1024)     0         ['bn4p_branch2c[0][0]',       \n",
      "                                                                     'res4o_out[0][0]']           \n",
      "                                                                                                  \n",
      " res4p_out (Activation)      (None, None, None, 1024)     0         ['add_22[0][0]']              \n",
      "                                                                                                  \n",
      " res4q_branch2a (Conv2D)     (None, None, None, 256)      262400    ['res4p_out[0][0]']           \n",
      "                                                                                                  \n",
      " bn4q_branch2a (BatchNorm)   (None, None, None, 256)      1024      ['res4q_branch2a[0][0]']      \n",
      "                                                                                                  \n",
      " activation_47 (Activation)  (None, None, None, 256)      0         ['bn4q_branch2a[0][0]']       \n",
      "                                                                                                  \n",
      " res4q_branch2b (Conv2D)     (None, None, None, 256)      590080    ['activation_47[0][0]']       \n",
      "                                                                                                  \n",
      " bn4q_branch2b (BatchNorm)   (None, None, None, 256)      1024      ['res4q_branch2b[0][0]']      \n",
      "                                                                                                  \n",
      " activation_48 (Activation)  (None, None, None, 256)      0         ['bn4q_branch2b[0][0]']       \n",
      "                                                                                                  \n",
      " res4q_branch2c (Conv2D)     (None, None, None, 1024)     263168    ['activation_48[0][0]']       \n",
      "                                                                                                  \n",
      " bn4q_branch2c (BatchNorm)   (None, None, None, 1024)     4096      ['res4q_branch2c[0][0]']      \n",
      "                                                                                                  \n",
      " add_23 (Add)                (None, None, None, 1024)     0         ['bn4q_branch2c[0][0]',       \n",
      "                                                                     'res4p_out[0][0]']           \n",
      "                                                                                                  \n",
      " res4q_out (Activation)      (None, None, None, 1024)     0         ['add_23[0][0]']              \n",
      "                                                                                                  \n",
      " res4r_branch2a (Conv2D)     (None, None, None, 256)      262400    ['res4q_out[0][0]']           \n",
      "                                                                                                  \n",
      " bn4r_branch2a (BatchNorm)   (None, None, None, 256)      1024      ['res4r_branch2a[0][0]']      \n",
      "                                                                                                  \n",
      " activation_49 (Activation)  (None, None, None, 256)      0         ['bn4r_branch2a[0][0]']       \n",
      "                                                                                                  \n",
      " res4r_branch2b (Conv2D)     (None, None, None, 256)      590080    ['activation_49[0][0]']       \n",
      "                                                                                                  \n",
      " bn4r_branch2b (BatchNorm)   (None, None, None, 256)      1024      ['res4r_branch2b[0][0]']      \n",
      "                                                                                                  \n",
      " activation_50 (Activation)  (None, None, None, 256)      0         ['bn4r_branch2b[0][0]']       \n",
      "                                                                                                  \n",
      " res4r_branch2c (Conv2D)     (None, None, None, 1024)     263168    ['activation_50[0][0]']       \n",
      "                                                                                                  \n",
      " bn4r_branch2c (BatchNorm)   (None, None, None, 1024)     4096      ['res4r_branch2c[0][0]']      \n",
      "                                                                                                  \n",
      " add_24 (Add)                (None, None, None, 1024)     0         ['bn4r_branch2c[0][0]',       \n",
      "                                                                     'res4q_out[0][0]']           \n",
      "                                                                                                  \n",
      " res4r_out (Activation)      (None, None, None, 1024)     0         ['add_24[0][0]']              \n",
      "                                                                                                  \n",
      " res4s_branch2a (Conv2D)     (None, None, None, 256)      262400    ['res4r_out[0][0]']           \n",
      "                                                                                                  \n",
      " bn4s_branch2a (BatchNorm)   (None, None, None, 256)      1024      ['res4s_branch2a[0][0]']      \n",
      "                                                                                                  \n",
      " activation_51 (Activation)  (None, None, None, 256)      0         ['bn4s_branch2a[0][0]']       \n",
      "                                                                                                  \n",
      " res4s_branch2b (Conv2D)     (None, None, None, 256)      590080    ['activation_51[0][0]']       \n",
      "                                                                                                  \n",
      " bn4s_branch2b (BatchNorm)   (None, None, None, 256)      1024      ['res4s_branch2b[0][0]']      \n",
      "                                                                                                  \n",
      " activation_52 (Activation)  (None, None, None, 256)      0         ['bn4s_branch2b[0][0]']       \n",
      "                                                                                                  \n",
      " res4s_branch2c (Conv2D)     (None, None, None, 1024)     263168    ['activation_52[0][0]']       \n",
      "                                                                                                  \n",
      " bn4s_branch2c (BatchNorm)   (None, None, None, 1024)     4096      ['res4s_branch2c[0][0]']      \n",
      "                                                                                                  \n",
      " add_25 (Add)                (None, None, None, 1024)     0         ['bn4s_branch2c[0][0]',       \n",
      "                                                                     'res4r_out[0][0]']           \n",
      "                                                                                                  \n",
      " res4s_out (Activation)      (None, None, None, 1024)     0         ['add_25[0][0]']              \n",
      "                                                                                                  \n",
      " res4t_branch2a (Conv2D)     (None, None, None, 256)      262400    ['res4s_out[0][0]']           \n",
      "                                                                                                  \n",
      " bn4t_branch2a (BatchNorm)   (None, None, None, 256)      1024      ['res4t_branch2a[0][0]']      \n",
      "                                                                                                  \n",
      " activation_53 (Activation)  (None, None, None, 256)      0         ['bn4t_branch2a[0][0]']       \n",
      "                                                                                                  \n",
      " res4t_branch2b (Conv2D)     (None, None, None, 256)      590080    ['activation_53[0][0]']       \n",
      "                                                                                                  \n",
      " bn4t_branch2b (BatchNorm)   (None, None, None, 256)      1024      ['res4t_branch2b[0][0]']      \n",
      "                                                                                                  \n",
      " activation_54 (Activation)  (None, None, None, 256)      0         ['bn4t_branch2b[0][0]']       \n",
      "                                                                                                  \n",
      " res4t_branch2c (Conv2D)     (None, None, None, 1024)     263168    ['activation_54[0][0]']       \n",
      "                                                                                                  \n",
      " bn4t_branch2c (BatchNorm)   (None, None, None, 1024)     4096      ['res4t_branch2c[0][0]']      \n",
      "                                                                                                  \n",
      " add_26 (Add)                (None, None, None, 1024)     0         ['bn4t_branch2c[0][0]',       \n",
      "                                                                     'res4s_out[0][0]']           \n",
      "                                                                                                  \n",
      " res4t_out (Activation)      (None, None, None, 1024)     0         ['add_26[0][0]']              \n",
      "                                                                                                  \n",
      " res4u_branch2a (Conv2D)     (None, None, None, 256)      262400    ['res4t_out[0][0]']           \n",
      "                                                                                                  \n",
      " bn4u_branch2a (BatchNorm)   (None, None, None, 256)      1024      ['res4u_branch2a[0][0]']      \n",
      "                                                                                                  \n",
      " activation_55 (Activation)  (None, None, None, 256)      0         ['bn4u_branch2a[0][0]']       \n",
      "                                                                                                  \n",
      " res4u_branch2b (Conv2D)     (None, None, None, 256)      590080    ['activation_55[0][0]']       \n",
      "                                                                                                  \n",
      " bn4u_branch2b (BatchNorm)   (None, None, None, 256)      1024      ['res4u_branch2b[0][0]']      \n",
      "                                                                                                  \n",
      " activation_56 (Activation)  (None, None, None, 256)      0         ['bn4u_branch2b[0][0]']       \n",
      "                                                                                                  \n",
      " res4u_branch2c (Conv2D)     (None, None, None, 1024)     263168    ['activation_56[0][0]']       \n",
      "                                                                                                  \n",
      " bn4u_branch2c (BatchNorm)   (None, None, None, 1024)     4096      ['res4u_branch2c[0][0]']      \n",
      "                                                                                                  \n",
      " add_27 (Add)                (None, None, None, 1024)     0         ['bn4u_branch2c[0][0]',       \n",
      "                                                                     'res4t_out[0][0]']           \n",
      "                                                                                                  \n",
      " res4u_out (Activation)      (None, None, None, 1024)     0         ['add_27[0][0]']              \n",
      "                                                                                                  \n",
      " res4v_branch2a (Conv2D)     (None, None, None, 256)      262400    ['res4u_out[0][0]']           \n",
      "                                                                                                  \n",
      " bn4v_branch2a (BatchNorm)   (None, None, None, 256)      1024      ['res4v_branch2a[0][0]']      \n",
      "                                                                                                  \n",
      " activation_57 (Activation)  (None, None, None, 256)      0         ['bn4v_branch2a[0][0]']       \n",
      "                                                                                                  \n",
      " res4v_branch2b (Conv2D)     (None, None, None, 256)      590080    ['activation_57[0][0]']       \n",
      "                                                                                                  \n",
      " bn4v_branch2b (BatchNorm)   (None, None, None, 256)      1024      ['res4v_branch2b[0][0]']      \n",
      "                                                                                                  \n",
      " activation_58 (Activation)  (None, None, None, 256)      0         ['bn4v_branch2b[0][0]']       \n",
      "                                                                                                  \n",
      " res4v_branch2c (Conv2D)     (None, None, None, 1024)     263168    ['activation_58[0][0]']       \n",
      "                                                                                                  \n",
      " bn4v_branch2c (BatchNorm)   (None, None, None, 1024)     4096      ['res4v_branch2c[0][0]']      \n",
      "                                                                                                  \n",
      " add_28 (Add)                (None, None, None, 1024)     0         ['bn4v_branch2c[0][0]',       \n",
      "                                                                     'res4u_out[0][0]']           \n",
      "                                                                                                  \n",
      " res4v_out (Activation)      (None, None, None, 1024)     0         ['add_28[0][0]']              \n",
      "                                                                                                  \n",
      " res4w_branch2a (Conv2D)     (None, None, None, 256)      262400    ['res4v_out[0][0]']           \n",
      "                                                                                                  \n",
      " bn4w_branch2a (BatchNorm)   (None, None, None, 256)      1024      ['res4w_branch2a[0][0]']      \n",
      "                                                                                                  \n",
      " activation_59 (Activation)  (None, None, None, 256)      0         ['bn4w_branch2a[0][0]']       \n",
      "                                                                                                  \n",
      " res4w_branch2b (Conv2D)     (None, None, None, 256)      590080    ['activation_59[0][0]']       \n",
      "                                                                                                  \n",
      " bn4w_branch2b (BatchNorm)   (None, None, None, 256)      1024      ['res4w_branch2b[0][0]']      \n",
      "                                                                                                  \n",
      " activation_60 (Activation)  (None, None, None, 256)      0         ['bn4w_branch2b[0][0]']       \n",
      "                                                                                                  \n",
      " res4w_branch2c (Conv2D)     (None, None, None, 1024)     263168    ['activation_60[0][0]']       \n",
      "                                                                                                  \n",
      " bn4w_branch2c (BatchNorm)   (None, None, None, 1024)     4096      ['res4w_branch2c[0][0]']      \n",
      "                                                                                                  \n",
      " add_29 (Add)                (None, None, None, 1024)     0         ['bn4w_branch2c[0][0]',       \n",
      "                                                                     'res4v_out[0][0]']           \n",
      "                                                                                                  \n",
      " res4w_out (Activation)      (None, None, None, 1024)     0         ['add_29[0][0]']              \n",
      "                                                                                                  \n",
      " res5a_branch2a (Conv2D)     (None, None, None, 512)      524800    ['res4w_out[0][0]']           \n",
      "                                                                                                  \n",
      " bn5a_branch2a (BatchNorm)   (None, None, None, 512)      2048      ['res5a_branch2a[0][0]']      \n",
      "                                                                                                  \n",
      " activation_61 (Activation)  (None, None, None, 512)      0         ['bn5a_branch2a[0][0]']       \n",
      "                                                                                                  \n",
      " res5a_branch2b (Conv2D)     (None, None, None, 512)      2359808   ['activation_61[0][0]']       \n",
      "                                                                                                  \n",
      " bn5a_branch2b (BatchNorm)   (None, None, None, 512)      2048      ['res5a_branch2b[0][0]']      \n",
      "                                                                                                  \n",
      " activation_62 (Activation)  (None, None, None, 512)      0         ['bn5a_branch2b[0][0]']       \n",
      "                                                                                                  \n",
      " res5a_branch2c (Conv2D)     (None, None, None, 2048)     1050624   ['activation_62[0][0]']       \n",
      "                                                                                                  \n",
      " res5a_branch1 (Conv2D)      (None, None, None, 2048)     2099200   ['res4w_out[0][0]']           \n",
      "                                                                                                  \n",
      " bn5a_branch2c (BatchNorm)   (None, None, None, 2048)     8192      ['res5a_branch2c[0][0]']      \n",
      "                                                                                                  \n",
      " bn5a_branch1 (BatchNorm)    (None, None, None, 2048)     8192      ['res5a_branch1[0][0]']       \n",
      "                                                                                                  \n",
      " add_30 (Add)                (None, None, None, 2048)     0         ['bn5a_branch2c[0][0]',       \n",
      "                                                                     'bn5a_branch1[0][0]']        \n",
      "                                                                                                  \n",
      " res5a_out (Activation)      (None, None, None, 2048)     0         ['add_30[0][0]']              \n",
      "                                                                                                  \n",
      " res5b_branch2a (Conv2D)     (None, None, None, 512)      1049088   ['res5a_out[0][0]']           \n",
      "                                                                                                  \n",
      " bn5b_branch2a (BatchNorm)   (None, None, None, 512)      2048      ['res5b_branch2a[0][0]']      \n",
      "                                                                                                  \n",
      " activation_63 (Activation)  (None, None, None, 512)      0         ['bn5b_branch2a[0][0]']       \n",
      "                                                                                                  \n",
      " res5b_branch2b (Conv2D)     (None, None, None, 512)      2359808   ['activation_63[0][0]']       \n",
      "                                                                                                  \n",
      " bn5b_branch2b (BatchNorm)   (None, None, None, 512)      2048      ['res5b_branch2b[0][0]']      \n",
      "                                                                                                  \n",
      " activation_64 (Activation)  (None, None, None, 512)      0         ['bn5b_branch2b[0][0]']       \n",
      "                                                                                                  \n",
      " res5b_branch2c (Conv2D)     (None, None, None, 2048)     1050624   ['activation_64[0][0]']       \n",
      "                                                                                                  \n",
      " bn5b_branch2c (BatchNorm)   (None, None, None, 2048)     8192      ['res5b_branch2c[0][0]']      \n",
      "                                                                                                  \n",
      " add_31 (Add)                (None, None, None, 2048)     0         ['bn5b_branch2c[0][0]',       \n",
      "                                                                     'res5a_out[0][0]']           \n",
      "                                                                                                  \n",
      " res5b_out (Activation)      (None, None, None, 2048)     0         ['add_31[0][0]']              \n",
      "                                                                                                  \n",
      " res5c_branch2a (Conv2D)     (None, None, None, 512)      1049088   ['res5b_out[0][0]']           \n",
      "                                                                                                  \n",
      " bn5c_branch2a (BatchNorm)   (None, None, None, 512)      2048      ['res5c_branch2a[0][0]']      \n",
      "                                                                                                  \n",
      " activation_65 (Activation)  (None, None, None, 512)      0         ['bn5c_branch2a[0][0]']       \n",
      "                                                                                                  \n",
      " res5c_branch2b (Conv2D)     (None, None, None, 512)      2359808   ['activation_65[0][0]']       \n",
      "                                                                                                  \n",
      " bn5c_branch2b (BatchNorm)   (None, None, None, 512)      2048      ['res5c_branch2b[0][0]']      \n",
      "                                                                                                  \n",
      " activation_66 (Activation)  (None, None, None, 512)      0         ['bn5c_branch2b[0][0]']       \n",
      "                                                                                                  \n",
      " res5c_branch2c (Conv2D)     (None, None, None, 2048)     1050624   ['activation_66[0][0]']       \n",
      "                                                                                                  \n",
      " bn5c_branch2c (BatchNorm)   (None, None, None, 2048)     8192      ['res5c_branch2c[0][0]']      \n",
      "                                                                                                  \n",
      " add_32 (Add)                (None, None, None, 2048)     0         ['bn5c_branch2c[0][0]',       \n",
      "                                                                     'res5b_out[0][0]']           \n",
      "                                                                                                  \n",
      " res5c_out (Activation)      (None, None, None, 2048)     0         ['add_32[0][0]']              \n",
      "                                                                                                  \n",
      " fpn_c5p5 (Conv2D)           (None, None, None, 256)      524544    ['res5c_out[0][0]']           \n",
      "                                                                                                  \n",
      " fpn_p5upsampled (UpSamplin  (None, None, None, 256)      0         ['fpn_c5p5[0][0]']            \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " fpn_c4p4 (Conv2D)           (None, None, None, 256)      262400    ['res4w_out[0][0]']           \n",
      "                                                                                                  \n",
      " fpn_p4add (Add)             (None, None, None, 256)      0         ['fpn_p5upsampled[0][0]',     \n",
      "                                                                     'fpn_c4p4[0][0]']            \n",
      "                                                                                                  \n",
      " fpn_p4upsampled (UpSamplin  (None, None, None, 256)      0         ['fpn_p4add[0][0]']           \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " fpn_c3p3 (Conv2D)           (None, None, None, 256)      131328    ['res3d_out[0][0]']           \n",
      "                                                                                                  \n",
      " fpn_p3add (Add)             (None, None, None, 256)      0         ['fpn_p4upsampled[0][0]',     \n",
      "                                                                     'fpn_c3p3[0][0]']            \n",
      "                                                                                                  \n",
      " fpn_p3upsampled (UpSamplin  (None, None, None, 256)      0         ['fpn_p3add[0][0]']           \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " fpn_c2p2 (Conv2D)           (None, None, None, 256)      65792     ['res2c_out[0][0]']           \n",
      "                                                                                                  \n",
      " fpn_p2add (Add)             (None, None, None, 256)      0         ['fpn_p3upsampled[0][0]',     \n",
      "                                                                     'fpn_c2p2[0][0]']            \n",
      "                                                                                                  \n",
      " fpn_p5 (Conv2D)             (None, None, None, 256)      590080    ['fpn_c5p5[0][0]']            \n",
      "                                                                                                  \n",
      " fpn_p2 (Conv2D)             (None, None, None, 256)      590080    ['fpn_p2add[0][0]']           \n",
      "                                                                                                  \n",
      " fpn_p3 (Conv2D)             (None, None, None, 256)      590080    ['fpn_p3add[0][0]']           \n",
      "                                                                                                  \n",
      " fpn_p4 (Conv2D)             (None, None, None, 256)      590080    ['fpn_p4add[0][0]']           \n",
      "                                                                                                  \n",
      " fpn_p6 (MaxPooling2D)       (None, None, None, 256)      0         ['fpn_p5[0][0]']              \n",
      "                                                                                                  \n",
      " rpn_model (Functional)      [(None, None, 2),            1189394   ['fpn_p2[0][0]',              \n",
      "                              (None, None, 2),                       'fpn_p3[0][0]',              \n",
      "                              (None, None, 4)]                       'fpn_p4[0][0]',              \n",
      "                                                                     'fpn_p5[0][0]',              \n",
      "                                                                     'fpn_p6[0][0]']              \n",
      "                                                                                                  \n",
      " rpn_bbox (Concatenate)      (None, None, 4)              0         ['rpn_model[0][2]',           \n",
      "                                                                     'rpn_model[1][2]',           \n",
      "                                                                     'rpn_model[2][2]',           \n",
      "                                                                     'rpn_model[3][2]',           \n",
      "                                                                     'rpn_model[4][2]']           \n",
      "                                                                                                  \n",
      " rpn_class (Concatenate)     (None, None, 2)              0         ['rpn_model[0][1]',           \n",
      "                                                                     'rpn_model[1][1]',           \n",
      "                                                                     'rpn_model[2][1]',           \n",
      "                                                                     'rpn_model[3][1]',           \n",
      "                                                                     'rpn_model[4][1]']           \n",
      "                                                                                                  \n",
      " anchors (ConstLayer)        (4, 65472, 4)                1047552   ['input_image[0][0]']         \n",
      "                                                                                                  \n",
      " input_gt_boxes (InputLayer  [(None, None, 4)]            0         []                            \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " ROI (ProposalLayer)         (4, 2000, 4)                 0         ['rpn_class[0][0]',           \n",
      "                                                                     'rpn_bbox[0][0]',            \n",
      "                                                                     'anchors[0][0]']             \n",
      "                                                                                                  \n",
      " input_gt_class_ids (InputL  [(None, None)]               0         []                            \n",
      " ayer)                                                                                            \n",
      "                                                                                                  \n",
      " lambda (Lambda)             (None, None, 4)              0         ['input_gt_boxes[0][0]',      \n",
      "                                                                     'input_image[0][0]']         \n",
      "                                                                                                  \n",
      " input_gt_masks (InputLayer  [(None, 512, 512, None)]     0         []                            \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " proposal_targets (Detectio  [(4, None, 4),               0         ['ROI[0][0]',                 \n",
      " nTargetLayer)                (4, None),                             'input_gt_class_ids[0][0]',  \n",
      "                              (4, None, 4),                          'lambda[0][0]',              \n",
      "                              (4, None, 28, 28)]                     'input_gt_masks[0][0]']      \n",
      "                                                                                                  \n",
      " input_image_meta (InputLay  [(None, 16)]                 0         []                            \n",
      " er)                                                                                              \n",
      "                                                                                                  \n",
      " roi_align_mask (PyramidROI  (4, None, 14, 14, 256)       0         ['proposal_targets[0][0]',    \n",
      " Align)                                                              'input_image_meta[0][0]',    \n",
      "                                                                     'fpn_p2[0][0]',              \n",
      "                                                                     'fpn_p3[0][0]',              \n",
      "                                                                     'fpn_p4[0][0]',              \n",
      "                                                                     'fpn_p5[0][0]']              \n",
      "                                                                                                  \n",
      " mrcnn_mask_conv1 (TimeDist  (4, None, 14, 14, 256)       590080    ['roi_align_mask[0][0]']      \n",
      " ributed)                                                                                         \n",
      "                                                                                                  \n",
      " mrcnn_mask_bn1 (TimeDistri  (4, None, 14, 14, 256)       1024      ['mrcnn_mask_conv1[0][0]']    \n",
      " buted)                                                                                           \n",
      "                                                                                                  \n",
      " activation_70 (Activation)  (4, None, 14, 14, 256)       0         ['mrcnn_mask_bn1[0][0]']      \n",
      "                                                                                                  \n",
      " mrcnn_mask_conv2 (TimeDist  (4, None, 14, 14, 256)       590080    ['activation_70[0][0]']       \n",
      " ributed)                                                                                         \n",
      "                                                                                                  \n",
      " roi_align_classifier (Pyra  (4, None, 7, 7, 256)         0         ['proposal_targets[0][0]',    \n",
      " midROIAlign)                                                        'input_image_meta[0][0]',    \n",
      "                                                                     'fpn_p2[0][0]',              \n",
      "                                                                     'fpn_p3[0][0]',              \n",
      "                                                                     'fpn_p4[0][0]',              \n",
      "                                                                     'fpn_p5[0][0]']              \n",
      "                                                                                                  \n",
      " mrcnn_mask_bn2 (TimeDistri  (4, None, 14, 14, 256)       1024      ['mrcnn_mask_conv2[0][0]']    \n",
      " buted)                                                                                           \n",
      "                                                                                                  \n",
      " mrcnn_class_conv1 (TimeDis  (4, None, 1, 1, 1024)        1284608   ['roi_align_classifier[0][0]']\n",
      " tributed)                                                0                                       \n",
      "                                                                                                  \n",
      " activation_71 (Activation)  (4, None, 14, 14, 256)       0         ['mrcnn_mask_bn2[0][0]']      \n",
      "                                                                                                  \n",
      " mrcnn_class_bn1 (TimeDistr  (4, None, 1, 1, 1024)        4096      ['mrcnn_class_conv1[0][0]']   \n",
      " ibuted)                                                                                          \n",
      "                                                                                                  \n",
      " mrcnn_mask_conv3 (TimeDist  (4, None, 14, 14, 256)       590080    ['activation_71[0][0]']       \n",
      " ributed)                                                                                         \n",
      "                                                                                                  \n",
      " activation_67 (Activation)  (4, None, 1, 1, 1024)        0         ['mrcnn_class_bn1[0][0]']     \n",
      "                                                                                                  \n",
      " mrcnn_mask_bn3 (TimeDistri  (4, None, 14, 14, 256)       1024      ['mrcnn_mask_conv3[0][0]']    \n",
      " buted)                                                                                           \n",
      "                                                                                                  \n",
      " mrcnn_class_conv2 (TimeDis  (4, None, 1, 1, 1024)        1049600   ['activation_67[0][0]']       \n",
      " tributed)                                                                                        \n",
      "                                                                                                  \n",
      " activation_72 (Activation)  (4, None, 14, 14, 256)       0         ['mrcnn_mask_bn3[0][0]']      \n",
      "                                                                                                  \n",
      " mrcnn_class_bn2 (TimeDistr  (4, None, 1, 1, 1024)        4096      ['mrcnn_class_conv2[0][0]']   \n",
      " ibuted)                                                                                          \n",
      "                                                                                                  \n",
      " mrcnn_mask_conv4 (TimeDist  (4, None, 14, 14, 256)       590080    ['activation_72[0][0]']       \n",
      " ributed)                                                                                         \n",
      "                                                                                                  \n",
      " activation_68 (Activation)  (4, None, 1, 1, 1024)        0         ['mrcnn_class_bn2[0][0]']     \n",
      "                                                                                                  \n",
      " mrcnn_mask_bn4 (TimeDistri  (4, None, 14, 14, 256)       1024      ['mrcnn_mask_conv4[0][0]']    \n",
      " buted)                                                                                           \n",
      "                                                                                                  \n",
      " pool_squeeze (Lambda)       (4, None, 1024)              0         ['activation_68[0][0]']       \n",
      "                                                                                                  \n",
      " activation_73 (Activation)  (4, None, 14, 14, 256)       0         ['mrcnn_mask_bn4[0][0]']      \n",
      "                                                                                                  \n",
      " mrcnn_bbox_fc (TimeDistrib  (4, None, 16)                16400     ['pool_squeeze[0][0]']        \n",
      " uted)                                                                                            \n",
      "                                                                                                  \n",
      " mrcnn_mask_deconv (TimeDis  (4, None, 28, 28, 256)       262400    ['activation_73[0][0]']       \n",
      " tributed)                                                                                        \n",
      "                                                                                                  \n",
      " input_rpn_match (InputLaye  [(None, None, 1)]            0         []                            \n",
      " r)                                                                                               \n",
      "                                                                                                  \n",
      " input_rpn_bbox (InputLayer  [(None, None, 4)]            0         []                            \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " rpn_class_logits (Concaten  (None, None, 2)              0         ['rpn_model[0][0]',           \n",
      " ate)                                                                'rpn_model[1][0]',           \n",
      "                                                                     'rpn_model[2][0]',           \n",
      "                                                                     'rpn_model[3][0]',           \n",
      "                                                                     'rpn_model[4][0]']           \n",
      "                                                                                                  \n",
      " mrcnn_class_logits (TimeDi  (4, None, 4)                 4100      ['pool_squeeze[0][0]']        \n",
      " stributed)                                                                                       \n",
      "                                                                                                  \n",
      " mrcnn_bbox (Reshape)        (4, None, 4, 4)              0         ['mrcnn_bbox_fc[0][0]']       \n",
      "                                                                                                  \n",
      " mrcnn_mask (TimeDistribute  (4, None, 28, 28, 4)         1028      ['mrcnn_mask_deconv[0][0]']   \n",
      " d)                                                                                               \n",
      "                                                                                                  \n",
      " lambda_3 (Lambda)           (None, 4)                    0         ['input_image_meta[0][0]']    \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 64791722 (247.16 MB)\n",
      "Trainable params: 0 (0.00 Byte)\n",
      "Non-trainable params: 64791722 (247.16 MB)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.compile(layers=\"head\")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting at epoch 0.\n",
      "\n",
      "Checkpoint Path: /mnt/c/Users/ChangGeng/Desktop/FAU/Semester 07/Bachelorarbeit/VisionTransformers/shoes/logs/55_shapes_resnet20241208T1756/mask_rcnn_55_shapes_resnet_{epoch:04d}.h5\n",
      "n workers used: 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "W0000 00:00:1733677026.513051   52374 op_level_cost_estimator.cc:699] Error in PredictCost() for the op: op: \"CropAndResize\" attr { key: \"T\" value { type: DT_FLOAT } } attr { key: \"extrapolation_value\" value { f: 0 } } attr { key: \"method\" value { s: \"bilinear\" } } inputs { dtype: DT_FLOAT shape { dim { size: -638 } dim { size: -121 } dim { size: -122 } dim { size: 1 } } } inputs { dtype: DT_FLOAT shape { dim { size: -24 } dim { size: 4 } } } inputs { dtype: DT_INT32 shape { dim { size: -24 } } } inputs { dtype: DT_INT32 shape { dim { size: 2 } } value { dtype: DT_INT32 tensor_shape { dim { size: 2 } } int_val: 28 } } device { type: \"GPU\" vendor: \"NVIDIA\" model: \"NVIDIA GeForce RTX 4090\" frequency: 2520 num_cores: 128 environment { key: \"architecture\" value: \"8.9\" } environment { key: \"cuda\" value: \"12000\" } environment { key: \"cudnn\" value: \"8800\" } num_registers: 65536 l1_cache_size: 24576 l2_cache_size: 75497472 shared_memory_size_per_multiprocessor: 102400 memory_size: 10180624384 bandwidth: 1008096000 } outputs { dtype: DT_FLOAT shape { dim { size: -24 } dim { size: 28 } dim { size: 28 } dim { size: 1 } } }\n",
      "W0000 00:00:1733677026.513348   52374 op_level_cost_estimator.cc:699] Error in PredictCost() for the op: op: \"CropAndResize\" attr { key: \"T\" value { type: DT_FLOAT } } attr { key: \"extrapolation_value\" value { f: 0 } } attr { key: \"method\" value { s: \"bilinear\" } } inputs { dtype: DT_FLOAT shape { dim { size: -696 } dim { size: -130 } dim { size: -131 } dim { size: 1 } } } inputs { dtype: DT_FLOAT shape { dim { size: -42 } dim { size: 4 } } } inputs { dtype: DT_INT32 shape { dim { size: -42 } } } inputs { dtype: DT_INT32 shape { dim { size: 2 } } value { dtype: DT_INT32 tensor_shape { dim { size: 2 } } int_val: 28 } } device { type: \"GPU\" vendor: \"NVIDIA\" model: \"NVIDIA GeForce RTX 4090\" frequency: 2520 num_cores: 128 environment { key: \"architecture\" value: \"8.9\" } environment { key: \"cuda\" value: \"12000\" } environment { key: \"cudnn\" value: \"8800\" } num_registers: 65536 l1_cache_size: 24576 l2_cache_size: 75497472 shared_memory_size_per_multiprocessor: 102400 memory_size: 10180624384 bandwidth: 1008096000 } outputs { dtype: DT_FLOAT shape { dim { size: -42 } dim { size: 28 } dim { size: 28 } dim { size: 1 } } }\n",
      "W0000 00:00:1733677026.513410   52374 op_level_cost_estimator.cc:699] Error in PredictCost() for the op: op: \"CropAndResize\" attr { key: \"T\" value { type: DT_FLOAT } } attr { key: \"extrapolation_value\" value { f: 0 } } attr { key: \"method\" value { s: \"bilinear\" } } inputs { dtype: DT_FLOAT shape { dim { size: -660 } dim { size: -124 } dim { size: -125 } dim { size: 1 } } } inputs { dtype: DT_FLOAT shape { dim { size: -30 } dim { size: 4 } } } inputs { dtype: DT_INT32 shape { dim { size: -30 } } } inputs { dtype: DT_INT32 shape { dim { size: 2 } } value { dtype: DT_INT32 tensor_shape { dim { size: 2 } } int_val: 28 } } device { type: \"GPU\" vendor: \"NVIDIA\" model: \"NVIDIA GeForce RTX 4090\" frequency: 2520 num_cores: 128 environment { key: \"architecture\" value: \"8.9\" } environment { key: \"cuda\" value: \"12000\" } environment { key: \"cudnn\" value: \"8800\" } num_registers: 65536 l1_cache_size: 24576 l2_cache_size: 75497472 shared_memory_size_per_multiprocessor: 102400 memory_size: 10180624384 bandwidth: 1008096000 } outputs { dtype: DT_FLOAT shape { dim { size: -30 } dim { size: 28 } dim { size: 28 } dim { size: 1 } } }\n",
      "W0000 00:00:1733677026.513459   52374 op_level_cost_estimator.cc:699] Error in PredictCost() for the op: op: \"CropAndResize\" attr { key: \"T\" value { type: DT_FLOAT } } attr { key: \"extrapolation_value\" value { f: 0 } } attr { key: \"method\" value { s: \"bilinear\" } } inputs { dtype: DT_FLOAT shape { dim { size: -681 } dim { size: -127 } dim { size: -128 } dim { size: 1 } } } inputs { dtype: DT_FLOAT shape { dim { size: -36 } dim { size: 4 } } } inputs { dtype: DT_INT32 shape { dim { size: -36 } } } inputs { dtype: DT_INT32 shape { dim { size: 2 } } value { dtype: DT_INT32 tensor_shape { dim { size: 2 } } int_val: 28 } } device { type: \"GPU\" vendor: \"NVIDIA\" model: \"NVIDIA GeForce RTX 4090\" frequency: 2520 num_cores: 128 environment { key: \"architecture\" value: \"8.9\" } environment { key: \"cuda\" value: \"12000\" } environment { key: \"cudnn\" value: \"8800\" } num_registers: 65536 l1_cache_size: 24576 l2_cache_size: 75497472 shared_memory_size_per_multiprocessor: 102400 memory_size: 10180624384 bandwidth: 1008096000 } outputs { dtype: DT_FLOAT shape { dim { size: -36 } dim { size: 28 } dim { size: 28 } dim { size: 1 } } }\n",
      "W0000 00:00:1733677026.515048   52374 op_level_cost_estimator.cc:699] Error in PredictCost() for the op: op: \"CropAndResize\" attr { key: \"T\" value { type: DT_FLOAT } } attr { key: \"extrapolation_value\" value { f: 0 } } attr { key: \"method\" value { s: \"bilinear\" } } inputs { dtype: DT_FLOAT shape { dim { size: -96 } dim { size: -440 } dim { size: -441 } dim { size: 256 } } } inputs { dtype: DT_FLOAT shape { dim { size: -81 } dim { size: 4 } } } inputs { dtype: DT_INT32 shape { dim { size: -81 } } } inputs { dtype: DT_INT32 shape { dim { size: 2 } } value { dtype: DT_INT32 tensor_shape { dim { size: 2 } } int_val: 7 } } device { type: \"GPU\" vendor: \"NVIDIA\" model: \"NVIDIA GeForce RTX 4090\" frequency: 2520 num_cores: 128 environment { key: \"architecture\" value: \"8.9\" } environment { key: \"cuda\" value: \"12000\" } environment { key: \"cudnn\" value: \"8800\" } num_registers: 65536 l1_cache_size: 24576 l2_cache_size: 75497472 shared_memory_size_per_multiprocessor: 102400 memory_size: 10180624384 bandwidth: 1008096000 } outputs { dtype: DT_FLOAT shape { dim { size: -81 } dim { size: 7 } dim { size: 7 } dim { size: 256 } } }\n",
      "W0000 00:00:1733677026.515095   52374 op_level_cost_estimator.cc:699] Error in PredictCost() for the op: op: \"CropAndResize\" attr { key: \"T\" value { type: DT_FLOAT } } attr { key: \"extrapolation_value\" value { f: 0 } } attr { key: \"method\" value { s: \"bilinear\" } } inputs { dtype: DT_FLOAT shape { dim { size: -96 } dim { size: -440 } dim { size: -441 } dim { size: 256 } } } inputs { dtype: DT_FLOAT shape { dim { size: -81 } dim { size: 4 } } } inputs { dtype: DT_INT32 shape { dim { size: -81 } } } inputs { dtype: DT_INT32 shape { dim { size: 2 } } value { dtype: DT_INT32 tensor_shape { dim { size: 2 } } int_val: 14 } } device { type: \"GPU\" vendor: \"NVIDIA\" model: \"NVIDIA GeForce RTX 4090\" frequency: 2520 num_cores: 128 environment { key: \"architecture\" value: \"8.9\" } environment { key: \"cuda\" value: \"12000\" } environment { key: \"cudnn\" value: \"8800\" } num_registers: 65536 l1_cache_size: 24576 l2_cache_size: 75497472 shared_memory_size_per_multiprocessor: 102400 memory_size: 10180624384 bandwidth: 1008096000 } outputs { dtype: DT_FLOAT shape { dim { size: -81 } dim { size: 14 } dim { size: 14 } dim { size: 256 } } }\n",
      "W0000 00:00:1733677026.515132   52374 op_level_cost_estimator.cc:699] Error in PredictCost() for the op: op: \"CropAndResize\" attr { key: \"T\" value { type: DT_FLOAT } } attr { key: \"extrapolation_value\" value { f: 0 } } attr { key: \"method\" value { s: \"bilinear\" } } inputs { dtype: DT_FLOAT shape { dim { size: -96 } dim { size: -430 } dim { size: -431 } dim { size: 256 } } } inputs { dtype: DT_FLOAT shape { dim { size: -83 } dim { size: 4 } } } inputs { dtype: DT_INT32 shape { dim { size: -83 } } } inputs { dtype: DT_INT32 shape { dim { size: 2 } } value { dtype: DT_INT32 tensor_shape { dim { size: 2 } } int_val: 7 } } device { type: \"GPU\" vendor: \"NVIDIA\" model: \"NVIDIA GeForce RTX 4090\" frequency: 2520 num_cores: 128 environment { key: \"architecture\" value: \"8.9\" } environment { key: \"cuda\" value: \"12000\" } environment { key: \"cudnn\" value: \"8800\" } num_registers: 65536 l1_cache_size: 24576 l2_cache_size: 75497472 shared_memory_size_per_multiprocessor: 102400 memory_size: 10180624384 bandwidth: 1008096000 } outputs { dtype: DT_FLOAT shape { dim { size: -83 } dim { size: 7 } dim { size: 7 } dim { size: 256 } } }\n",
      "W0000 00:00:1733677026.515156   52374 op_level_cost_estimator.cc:699] Error in PredictCost() for the op: op: \"CropAndResize\" attr { key: \"T\" value { type: DT_FLOAT } } attr { key: \"extrapolation_value\" value { f: 0 } } attr { key: \"method\" value { s: \"bilinear\" } } inputs { dtype: DT_FLOAT shape { dim { size: -96 } dim { size: -430 } dim { size: -431 } dim { size: 256 } } } inputs { dtype: DT_FLOAT shape { dim { size: -83 } dim { size: 4 } } } inputs { dtype: DT_INT32 shape { dim { size: -83 } } } inputs { dtype: DT_INT32 shape { dim { size: 2 } } value { dtype: DT_INT32 tensor_shape { dim { size: 2 } } int_val: 14 } } device { type: \"GPU\" vendor: \"NVIDIA\" model: \"NVIDIA GeForce RTX 4090\" frequency: 2520 num_cores: 128 environment { key: \"architecture\" value: \"8.9\" } environment { key: \"cuda\" value: \"12000\" } environment { key: \"cudnn\" value: \"8800\" } num_registers: 65536 l1_cache_size: 24576 l2_cache_size: 75497472 shared_memory_size_per_multiprocessor: 102400 memory_size: 10180624384 bandwidth: 1008096000 } outputs { dtype: DT_FLOAT shape { dim { size: -83 } dim { size: 14 } dim { size: 14 } dim { size: 256 } } }\n",
      "W0000 00:00:1733677026.515186   52374 op_level_cost_estimator.cc:699] Error in PredictCost() for the op: op: \"CropAndResize\" attr { key: \"T\" value { type: DT_FLOAT } } attr { key: \"extrapolation_value\" value { f: 0 } } attr { key: \"method\" value { s: \"bilinear\" } } inputs { dtype: DT_FLOAT shape { dim { size: -96 } dim { size: -418 } dim { size: -419 } dim { size: 256 } } } inputs { dtype: DT_FLOAT shape { dim { size: -85 } dim { size: 4 } } } inputs { dtype: DT_INT32 shape { dim { size: -85 } } } inputs { dtype: DT_INT32 shape { dim { size: 2 } } value { dtype: DT_INT32 tensor_shape { dim { size: 2 } } int_val: 7 } } device { type: \"GPU\" vendor: \"NVIDIA\" model: \"NVIDIA GeForce RTX 4090\" frequency: 2520 num_cores: 128 environment { key: \"architecture\" value: \"8.9\" } environment { key: \"cuda\" value: \"12000\" } environment { key: \"cudnn\" value: \"8800\" } num_registers: 65536 l1_cache_size: 24576 l2_cache_size: 75497472 shared_memory_size_per_multiprocessor: 102400 memory_size: 10180624384 bandwidth: 1008096000 } outputs { dtype: DT_FLOAT shape { dim { size: -85 } dim { size: 7 } dim { size: 7 } dim { size: 256 } } }\n",
      "W0000 00:00:1733677026.515208   52374 op_level_cost_estimator.cc:699] Error in PredictCost() for the op: op: \"CropAndResize\" attr { key: \"T\" value { type: DT_FLOAT } } attr { key: \"extrapolation_value\" value { f: 0 } } attr { key: \"method\" value { s: \"bilinear\" } } inputs { dtype: DT_FLOAT shape { dim { size: -96 } dim { size: -418 } dim { size: -419 } dim { size: 256 } } } inputs { dtype: DT_FLOAT shape { dim { size: -85 } dim { size: 4 } } } inputs { dtype: DT_INT32 shape { dim { size: -85 } } } inputs { dtype: DT_INT32 shape { dim { size: 2 } } value { dtype: DT_INT32 tensor_shape { dim { size: 2 } } int_val: 14 } } device { type: \"GPU\" vendor: \"NVIDIA\" model: \"NVIDIA GeForce RTX 4090\" frequency: 2520 num_cores: 128 environment { key: \"architecture\" value: \"8.9\" } environment { key: \"cuda\" value: \"12000\" } environment { key: \"cudnn\" value: \"8800\" } num_registers: 65536 l1_cache_size: 24576 l2_cache_size: 75497472 shared_memory_size_per_multiprocessor: 102400 memory_size: 10180624384 bandwidth: 1008096000 } outputs { dtype: DT_FLOAT shape { dim { size: -85 } dim { size: 14 } dim { size: 14 } dim { size: 256 } } }\n",
      "W0000 00:00:1733677026.515245   52374 op_level_cost_estimator.cc:699] Error in PredictCost() for the op: op: \"CropAndResize\" attr { key: \"T\" value { type: DT_FLOAT } } attr { key: \"extrapolation_value\" value { f: 0 } } attr { key: \"method\" value { s: \"bilinear\" } } inputs { dtype: DT_FLOAT shape { dim { size: -96 } dim { size: -404 } dim { size: -405 } dim { size: 256 } } } inputs { dtype: DT_FLOAT shape { dim { size: -87 } dim { size: 4 } } } inputs { dtype: DT_INT32 shape { dim { size: -87 } } } inputs { dtype: DT_INT32 shape { dim { size: 2 } } value { dtype: DT_INT32 tensor_shape { dim { size: 2 } } int_val: 7 } } device { type: \"GPU\" vendor: \"NVIDIA\" model: \"NVIDIA GeForce RTX 4090\" frequency: 2520 num_cores: 128 environment { key: \"architecture\" value: \"8.9\" } environment { key: \"cuda\" value: \"12000\" } environment { key: \"cudnn\" value: \"8800\" } num_registers: 65536 l1_cache_size: 24576 l2_cache_size: 75497472 shared_memory_size_per_multiprocessor: 102400 memory_size: 10180624384 bandwidth: 1008096000 } outputs { dtype: DT_FLOAT shape { dim { size: -87 } dim { size: 7 } dim { size: 7 } dim { size: 256 } } }\n",
      "W0000 00:00:1733677026.515278   52374 op_level_cost_estimator.cc:699] Error in PredictCost() for the op: op: \"CropAndResize\" attr { key: \"T\" value { type: DT_FLOAT } } attr { key: \"extrapolation_value\" value { f: 0 } } attr { key: \"method\" value { s: \"bilinear\" } } inputs { dtype: DT_FLOAT shape { dim { size: -96 } dim { size: -404 } dim { size: -405 } dim { size: 256 } } } inputs { dtype: DT_FLOAT shape { dim { size: -87 } dim { size: 4 } } } inputs { dtype: DT_INT32 shape { dim { size: -87 } } } inputs { dtype: DT_INT32 shape { dim { size: 2 } } value { dtype: DT_INT32 tensor_shape { dim { size: 2 } } int_val: 14 } } device { type: \"GPU\" vendor: \"NVIDIA\" model: \"NVIDIA GeForce RTX 4090\" frequency: 2520 num_cores: 128 environment { key: \"architecture\" value: \"8.9\" } environment { key: \"cuda\" value: \"12000\" } environment { key: \"cudnn\" value: \"8800\" } num_registers: 65536 l1_cache_size: 24576 l2_cache_size: 75497472 shared_memory_size_per_multiprocessor: 102400 memory_size: 10180624384 bandwidth: 1008096000 } outputs { dtype: DT_FLOAT shape { dim { size: -87 } dim { size: 14 } dim { size: 14 } dim { size: 256 } } }\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250/250 [==============================] - ETA: 0s - loss: 39.4611 - rpn_class_loss: 13.1891 - rpn_bbox_loss: 6.6839 - mrcnn_class_loss: 11.2467 - mrcnn_bbox_loss: 7.5036 - mrcnn_mask_loss: 1.2889"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1733677055.669019   52374 op_level_cost_estimator.cc:699] Error in PredictCost() for the op: op: \"CropAndResize\" attr { key: \"T\" value { type: DT_FLOAT } } attr { key: \"extrapolation_value\" value { f: 0 } } attr { key: \"method\" value { s: \"bilinear\" } } inputs { dtype: DT_FLOAT shape { dim { size: -638 } dim { size: -121 } dim { size: -122 } dim { size: 1 } } } inputs { dtype: DT_FLOAT shape { dim { size: -24 } dim { size: 4 } } } inputs { dtype: DT_INT32 shape { dim { size: -24 } } } inputs { dtype: DT_INT32 shape { dim { size: 2 } } value { dtype: DT_INT32 tensor_shape { dim { size: 2 } } int_val: 28 } } device { type: \"GPU\" vendor: \"NVIDIA\" model: \"NVIDIA GeForce RTX 4090\" frequency: 2520 num_cores: 128 environment { key: \"architecture\" value: \"8.9\" } environment { key: \"cuda\" value: \"12000\" } environment { key: \"cudnn\" value: \"8800\" } num_registers: 65536 l1_cache_size: 24576 l2_cache_size: 75497472 shared_memory_size_per_multiprocessor: 102400 memory_size: 10180624384 bandwidth: 1008096000 } outputs { dtype: DT_FLOAT shape { dim { size: -24 } dim { size: 28 } dim { size: 28 } dim { size: 1 } } }\n",
      "W0000 00:00:1733677055.669200   52374 op_level_cost_estimator.cc:699] Error in PredictCost() for the op: op: \"CropAndResize\" attr { key: \"T\" value { type: DT_FLOAT } } attr { key: \"extrapolation_value\" value { f: 0 } } attr { key: \"method\" value { s: \"bilinear\" } } inputs { dtype: DT_FLOAT shape { dim { size: -696 } dim { size: -130 } dim { size: -131 } dim { size: 1 } } } inputs { dtype: DT_FLOAT shape { dim { size: -42 } dim { size: 4 } } } inputs { dtype: DT_INT32 shape { dim { size: -42 } } } inputs { dtype: DT_INT32 shape { dim { size: 2 } } value { dtype: DT_INT32 tensor_shape { dim { size: 2 } } int_val: 28 } } device { type: \"GPU\" vendor: \"NVIDIA\" model: \"NVIDIA GeForce RTX 4090\" frequency: 2520 num_cores: 128 environment { key: \"architecture\" value: \"8.9\" } environment { key: \"cuda\" value: \"12000\" } environment { key: \"cudnn\" value: \"8800\" } num_registers: 65536 l1_cache_size: 24576 l2_cache_size: 75497472 shared_memory_size_per_multiprocessor: 102400 memory_size: 10180624384 bandwidth: 1008096000 } outputs { dtype: DT_FLOAT shape { dim { size: -42 } dim { size: 28 } dim { size: 28 } dim { size: 1 } } }\n",
      "W0000 00:00:1733677055.669261   52374 op_level_cost_estimator.cc:699] Error in PredictCost() for the op: op: \"CropAndResize\" attr { key: \"T\" value { type: DT_FLOAT } } attr { key: \"extrapolation_value\" value { f: 0 } } attr { key: \"method\" value { s: \"bilinear\" } } inputs { dtype: DT_FLOAT shape { dim { size: -660 } dim { size: -124 } dim { size: -125 } dim { size: 1 } } } inputs { dtype: DT_FLOAT shape { dim { size: -30 } dim { size: 4 } } } inputs { dtype: DT_INT32 shape { dim { size: -30 } } } inputs { dtype: DT_INT32 shape { dim { size: 2 } } value { dtype: DT_INT32 tensor_shape { dim { size: 2 } } int_val: 28 } } device { type: \"GPU\" vendor: \"NVIDIA\" model: \"NVIDIA GeForce RTX 4090\" frequency: 2520 num_cores: 128 environment { key: \"architecture\" value: \"8.9\" } environment { key: \"cuda\" value: \"12000\" } environment { key: \"cudnn\" value: \"8800\" } num_registers: 65536 l1_cache_size: 24576 l2_cache_size: 75497472 shared_memory_size_per_multiprocessor: 102400 memory_size: 10180624384 bandwidth: 1008096000 } outputs { dtype: DT_FLOAT shape { dim { size: -30 } dim { size: 28 } dim { size: 28 } dim { size: 1 } } }\n",
      "W0000 00:00:1733677055.669309   52374 op_level_cost_estimator.cc:699] Error in PredictCost() for the op: op: \"CropAndResize\" attr { key: \"T\" value { type: DT_FLOAT } } attr { key: \"extrapolation_value\" value { f: 0 } } attr { key: \"method\" value { s: \"bilinear\" } } inputs { dtype: DT_FLOAT shape { dim { size: -681 } dim { size: -127 } dim { size: -128 } dim { size: 1 } } } inputs { dtype: DT_FLOAT shape { dim { size: -36 } dim { size: 4 } } } inputs { dtype: DT_INT32 shape { dim { size: -36 } } } inputs { dtype: DT_INT32 shape { dim { size: 2 } } value { dtype: DT_INT32 tensor_shape { dim { size: 2 } } int_val: 28 } } device { type: \"GPU\" vendor: \"NVIDIA\" model: \"NVIDIA GeForce RTX 4090\" frequency: 2520 num_cores: 128 environment { key: \"architecture\" value: \"8.9\" } environment { key: \"cuda\" value: \"12000\" } environment { key: \"cudnn\" value: \"8800\" } num_registers: 65536 l1_cache_size: 24576 l2_cache_size: 75497472 shared_memory_size_per_multiprocessor: 102400 memory_size: 10180624384 bandwidth: 1008096000 } outputs { dtype: DT_FLOAT shape { dim { size: -36 } dim { size: 28 } dim { size: 28 } dim { size: 1 } } }\n",
      "W0000 00:00:1733677055.671153   52374 op_level_cost_estimator.cc:699] Error in PredictCost() for the op: op: \"CropAndResize\" attr { key: \"T\" value { type: DT_FLOAT } } attr { key: \"extrapolation_value\" value { f: 0 } } attr { key: \"method\" value { s: \"bilinear\" } } inputs { dtype: DT_FLOAT shape { dim { size: -96 } dim { size: -440 } dim { size: -441 } dim { size: 256 } } } inputs { dtype: DT_FLOAT shape { dim { size: -81 } dim { size: 4 } } } inputs { dtype: DT_INT32 shape { dim { size: -81 } } } inputs { dtype: DT_INT32 shape { dim { size: 2 } } value { dtype: DT_INT32 tensor_shape { dim { size: 2 } } int_val: 7 } } device { type: \"GPU\" vendor: \"NVIDIA\" model: \"NVIDIA GeForce RTX 4090\" frequency: 2520 num_cores: 128 environment { key: \"architecture\" value: \"8.9\" } environment { key: \"cuda\" value: \"12000\" } environment { key: \"cudnn\" value: \"8800\" } num_registers: 65536 l1_cache_size: 24576 l2_cache_size: 75497472 shared_memory_size_per_multiprocessor: 102400 memory_size: 10180624384 bandwidth: 1008096000 } outputs { dtype: DT_FLOAT shape { dim { size: -81 } dim { size: 7 } dim { size: 7 } dim { size: 256 } } }\n",
      "W0000 00:00:1733677055.671203   52374 op_level_cost_estimator.cc:699] Error in PredictCost() for the op: op: \"CropAndResize\" attr { key: \"T\" value { type: DT_FLOAT } } attr { key: \"extrapolation_value\" value { f: 0 } } attr { key: \"method\" value { s: \"bilinear\" } } inputs { dtype: DT_FLOAT shape { dim { size: -96 } dim { size: -440 } dim { size: -441 } dim { size: 256 } } } inputs { dtype: DT_FLOAT shape { dim { size: -81 } dim { size: 4 } } } inputs { dtype: DT_INT32 shape { dim { size: -81 } } } inputs { dtype: DT_INT32 shape { dim { size: 2 } } value { dtype: DT_INT32 tensor_shape { dim { size: 2 } } int_val: 14 } } device { type: \"GPU\" vendor: \"NVIDIA\" model: \"NVIDIA GeForce RTX 4090\" frequency: 2520 num_cores: 128 environment { key: \"architecture\" value: \"8.9\" } environment { key: \"cuda\" value: \"12000\" } environment { key: \"cudnn\" value: \"8800\" } num_registers: 65536 l1_cache_size: 24576 l2_cache_size: 75497472 shared_memory_size_per_multiprocessor: 102400 memory_size: 10180624384 bandwidth: 1008096000 } outputs { dtype: DT_FLOAT shape { dim { size: -81 } dim { size: 14 } dim { size: 14 } dim { size: 256 } } }\n",
      "W0000 00:00:1733677055.671228   52374 op_level_cost_estimator.cc:699] Error in PredictCost() for the op: op: \"CropAndResize\" attr { key: \"T\" value { type: DT_FLOAT } } attr { key: \"extrapolation_value\" value { f: 0 } } attr { key: \"method\" value { s: \"bilinear\" } } inputs { dtype: DT_FLOAT shape { dim { size: -96 } dim { size: -430 } dim { size: -431 } dim { size: 256 } } } inputs { dtype: DT_FLOAT shape { dim { size: -83 } dim { size: 4 } } } inputs { dtype: DT_INT32 shape { dim { size: -83 } } } inputs { dtype: DT_INT32 shape { dim { size: 2 } } value { dtype: DT_INT32 tensor_shape { dim { size: 2 } } int_val: 7 } } device { type: \"GPU\" vendor: \"NVIDIA\" model: \"NVIDIA GeForce RTX 4090\" frequency: 2520 num_cores: 128 environment { key: \"architecture\" value: \"8.9\" } environment { key: \"cuda\" value: \"12000\" } environment { key: \"cudnn\" value: \"8800\" } num_registers: 65536 l1_cache_size: 24576 l2_cache_size: 75497472 shared_memory_size_per_multiprocessor: 102400 memory_size: 10180624384 bandwidth: 1008096000 } outputs { dtype: DT_FLOAT shape { dim { size: -83 } dim { size: 7 } dim { size: 7 } dim { size: 256 } } }\n",
      "W0000 00:00:1733677055.671248   52374 op_level_cost_estimator.cc:699] Error in PredictCost() for the op: op: \"CropAndResize\" attr { key: \"T\" value { type: DT_FLOAT } } attr { key: \"extrapolation_value\" value { f: 0 } } attr { key: \"method\" value { s: \"bilinear\" } } inputs { dtype: DT_FLOAT shape { dim { size: -96 } dim { size: -430 } dim { size: -431 } dim { size: 256 } } } inputs { dtype: DT_FLOAT shape { dim { size: -83 } dim { size: 4 } } } inputs { dtype: DT_INT32 shape { dim { size: -83 } } } inputs { dtype: DT_INT32 shape { dim { size: 2 } } value { dtype: DT_INT32 tensor_shape { dim { size: 2 } } int_val: 14 } } device { type: \"GPU\" vendor: \"NVIDIA\" model: \"NVIDIA GeForce RTX 4090\" frequency: 2520 num_cores: 128 environment { key: \"architecture\" value: \"8.9\" } environment { key: \"cuda\" value: \"12000\" } environment { key: \"cudnn\" value: \"8800\" } num_registers: 65536 l1_cache_size: 24576 l2_cache_size: 75497472 shared_memory_size_per_multiprocessor: 102400 memory_size: 10180624384 bandwidth: 1008096000 } outputs { dtype: DT_FLOAT shape { dim { size: -83 } dim { size: 14 } dim { size: 14 } dim { size: 256 } } }\n",
      "W0000 00:00:1733677055.671278   52374 op_level_cost_estimator.cc:699] Error in PredictCost() for the op: op: \"CropAndResize\" attr { key: \"T\" value { type: DT_FLOAT } } attr { key: \"extrapolation_value\" value { f: 0 } } attr { key: \"method\" value { s: \"bilinear\" } } inputs { dtype: DT_FLOAT shape { dim { size: -96 } dim { size: -418 } dim { size: -419 } dim { size: 256 } } } inputs { dtype: DT_FLOAT shape { dim { size: -85 } dim { size: 4 } } } inputs { dtype: DT_INT32 shape { dim { size: -85 } } } inputs { dtype: DT_INT32 shape { dim { size: 2 } } value { dtype: DT_INT32 tensor_shape { dim { size: 2 } } int_val: 7 } } device { type: \"GPU\" vendor: \"NVIDIA\" model: \"NVIDIA GeForce RTX 4090\" frequency: 2520 num_cores: 128 environment { key: \"architecture\" value: \"8.9\" } environment { key: \"cuda\" value: \"12000\" } environment { key: \"cudnn\" value: \"8800\" } num_registers: 65536 l1_cache_size: 24576 l2_cache_size: 75497472 shared_memory_size_per_multiprocessor: 102400 memory_size: 10180624384 bandwidth: 1008096000 } outputs { dtype: DT_FLOAT shape { dim { size: -85 } dim { size: 7 } dim { size: 7 } dim { size: 256 } } }\n",
      "W0000 00:00:1733677055.671301   52374 op_level_cost_estimator.cc:699] Error in PredictCost() for the op: op: \"CropAndResize\" attr { key: \"T\" value { type: DT_FLOAT } } attr { key: \"extrapolation_value\" value { f: 0 } } attr { key: \"method\" value { s: \"bilinear\" } } inputs { dtype: DT_FLOAT shape { dim { size: -96 } dim { size: -418 } dim { size: -419 } dim { size: 256 } } } inputs { dtype: DT_FLOAT shape { dim { size: -85 } dim { size: 4 } } } inputs { dtype: DT_INT32 shape { dim { size: -85 } } } inputs { dtype: DT_INT32 shape { dim { size: 2 } } value { dtype: DT_INT32 tensor_shape { dim { size: 2 } } int_val: 14 } } device { type: \"GPU\" vendor: \"NVIDIA\" model: \"NVIDIA GeForce RTX 4090\" frequency: 2520 num_cores: 128 environment { key: \"architecture\" value: \"8.9\" } environment { key: \"cuda\" value: \"12000\" } environment { key: \"cudnn\" value: \"8800\" } num_registers: 65536 l1_cache_size: 24576 l2_cache_size: 75497472 shared_memory_size_per_multiprocessor: 102400 memory_size: 10180624384 bandwidth: 1008096000 } outputs { dtype: DT_FLOAT shape { dim { size: -85 } dim { size: 14 } dim { size: 14 } dim { size: 256 } } }\n",
      "W0000 00:00:1733677055.671340   52374 op_level_cost_estimator.cc:699] Error in PredictCost() for the op: op: \"CropAndResize\" attr { key: \"T\" value { type: DT_FLOAT } } attr { key: \"extrapolation_value\" value { f: 0 } } attr { key: \"method\" value { s: \"bilinear\" } } inputs { dtype: DT_FLOAT shape { dim { size: -96 } dim { size: -404 } dim { size: -405 } dim { size: 256 } } } inputs { dtype: DT_FLOAT shape { dim { size: -87 } dim { size: 4 } } } inputs { dtype: DT_INT32 shape { dim { size: -87 } } } inputs { dtype: DT_INT32 shape { dim { size: 2 } } value { dtype: DT_INT32 tensor_shape { dim { size: 2 } } int_val: 7 } } device { type: \"GPU\" vendor: \"NVIDIA\" model: \"NVIDIA GeForce RTX 4090\" frequency: 2520 num_cores: 128 environment { key: \"architecture\" value: \"8.9\" } environment { key: \"cuda\" value: \"12000\" } environment { key: \"cudnn\" value: \"8800\" } num_registers: 65536 l1_cache_size: 24576 l2_cache_size: 75497472 shared_memory_size_per_multiprocessor: 102400 memory_size: 10180624384 bandwidth: 1008096000 } outputs { dtype: DT_FLOAT shape { dim { size: -87 } dim { size: 7 } dim { size: 7 } dim { size: 256 } } }\n",
      "W0000 00:00:1733677055.671373   52374 op_level_cost_estimator.cc:699] Error in PredictCost() for the op: op: \"CropAndResize\" attr { key: \"T\" value { type: DT_FLOAT } } attr { key: \"extrapolation_value\" value { f: 0 } } attr { key: \"method\" value { s: \"bilinear\" } } inputs { dtype: DT_FLOAT shape { dim { size: -96 } dim { size: -404 } dim { size: -405 } dim { size: 256 } } } inputs { dtype: DT_FLOAT shape { dim { size: -87 } dim { size: 4 } } } inputs { dtype: DT_INT32 shape { dim { size: -87 } } } inputs { dtype: DT_INT32 shape { dim { size: 2 } } value { dtype: DT_INT32 tensor_shape { dim { size: 2 } } int_val: 14 } } device { type: \"GPU\" vendor: \"NVIDIA\" model: \"NVIDIA GeForce RTX 4090\" frequency: 2520 num_cores: 128 environment { key: \"architecture\" value: \"8.9\" } environment { key: \"cuda\" value: \"12000\" } environment { key: \"cudnn\" value: \"8800\" } num_registers: 65536 l1_cache_size: 24576 l2_cache_size: 75497472 shared_memory_size_per_multiprocessor: 102400 memory_size: 10180624384 bandwidth: 1008096000 } outputs { dtype: DT_FLOAT shape { dim { size: -87 } dim { size: 14 } dim { size: 14 } dim { size: 256 } } }\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250/250 [==============================] - 40s 121ms/step - loss: 39.4611 - rpn_class_loss: 13.1891 - rpn_bbox_loss: 6.6839 - mrcnn_class_loss: 11.2458 - mrcnn_bbox_loss: 7.5028 - mrcnn_mask_loss: 1.2888 - val_loss: 39.8793 - val_rpn_class_loss: 13.3999 - val_rpn_bbox_loss: 6.9760 - val_mrcnn_class_loss: 11.0297 - val_mrcnn_bbox_loss: 7.1984 - val_mrcnn_mask_loss: 1.2752 - lr: 0.0010\n"
     ]
    }
   ],
   "source": [
    "model.train(dataset_train, dataset_val, \n",
    "            epochs=EPOCHS[0], \n",
    "            augmentations=None, #augmentation, \n",
    "            custom_callbacks=[stop_early, reduce_lr, csv_logger_head])\n",
    "history = model.keras_model.history.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selecting layers to train\n",
      "conv1                  (Conv2D)\n",
      "bn_conv1               (BatchNorm)\n",
      "res2a_branch2a         (Conv2D)\n",
      "bn2a_branch2a          (BatchNorm)\n",
      "res2a_branch2b         (Conv2D)\n",
      "bn2a_branch2b          (BatchNorm)\n",
      "res2a_branch2c         (Conv2D)\n",
      "res2a_branch1          (Conv2D)\n",
      "bn2a_branch2c          (BatchNorm)\n",
      "bn2a_branch1           (BatchNorm)\n",
      "res2b_branch2a         (Conv2D)\n",
      "bn2b_branch2a          (BatchNorm)\n",
      "res2b_branch2b         (Conv2D)\n",
      "bn2b_branch2b          (BatchNorm)\n",
      "res2b_branch2c         (Conv2D)\n",
      "bn2b_branch2c          (BatchNorm)\n",
      "res2c_branch2a         (Conv2D)\n",
      "bn2c_branch2a          (BatchNorm)\n",
      "res2c_branch2b         (Conv2D)\n",
      "bn2c_branch2b          (BatchNorm)\n",
      "res2c_branch2c         (Conv2D)\n",
      "bn2c_branch2c          (BatchNorm)\n",
      "res3a_branch2a         (Conv2D)\n",
      "bn3a_branch2a          (BatchNorm)\n",
      "res3a_branch2b         (Conv2D)\n",
      "bn3a_branch2b          (BatchNorm)\n",
      "res3a_branch2c         (Conv2D)\n",
      "res3a_branch1          (Conv2D)\n",
      "bn3a_branch2c          (BatchNorm)\n",
      "bn3a_branch1           (BatchNorm)\n",
      "res3b_branch2a         (Conv2D)\n",
      "bn3b_branch2a          (BatchNorm)\n",
      "res3b_branch2b         (Conv2D)\n",
      "bn3b_branch2b          (BatchNorm)\n",
      "res3b_branch2c         (Conv2D)\n",
      "bn3b_branch2c          (BatchNorm)\n",
      "res3c_branch2a         (Conv2D)\n",
      "bn3c_branch2a          (BatchNorm)\n",
      "res3c_branch2b         (Conv2D)\n",
      "bn3c_branch2b          (BatchNorm)\n",
      "res3c_branch2c         (Conv2D)\n",
      "bn3c_branch2c          (BatchNorm)\n",
      "res3d_branch2a         (Conv2D)\n",
      "bn3d_branch2a          (BatchNorm)\n",
      "res3d_branch2b         (Conv2D)\n",
      "bn3d_branch2b          (BatchNorm)\n",
      "res3d_branch2c         (Conv2D)\n",
      "bn3d_branch2c          (BatchNorm)\n",
      "res4a_branch2a         (Conv2D)\n",
      "bn4a_branch2a          (BatchNorm)\n",
      "res4a_branch2b         (Conv2D)\n",
      "bn4a_branch2b          (BatchNorm)\n",
      "res4a_branch2c         (Conv2D)\n",
      "res4a_branch1          (Conv2D)\n",
      "bn4a_branch2c          (BatchNorm)\n",
      "bn4a_branch1           (BatchNorm)\n",
      "res4b_branch2a         (Conv2D)\n",
      "bn4b_branch2a          (BatchNorm)\n",
      "res4b_branch2b         (Conv2D)\n",
      "bn4b_branch2b          (BatchNorm)\n",
      "res4b_branch2c         (Conv2D)\n",
      "bn4b_branch2c          (BatchNorm)\n",
      "res4c_branch2a         (Conv2D)\n",
      "bn4c_branch2a          (BatchNorm)\n",
      "res4c_branch2b         (Conv2D)\n",
      "bn4c_branch2b          (BatchNorm)\n",
      "res4c_branch2c         (Conv2D)\n",
      "bn4c_branch2c          (BatchNorm)\n",
      "res4d_branch2a         (Conv2D)\n",
      "bn4d_branch2a          (BatchNorm)\n",
      "res4d_branch2b         (Conv2D)\n",
      "bn4d_branch2b          (BatchNorm)\n",
      "res4d_branch2c         (Conv2D)\n",
      "bn4d_branch2c          (BatchNorm)\n",
      "res4e_branch2a         (Conv2D)\n",
      "bn4e_branch2a          (BatchNorm)\n",
      "res4e_branch2b         (Conv2D)\n",
      "bn4e_branch2b          (BatchNorm)\n",
      "res4e_branch2c         (Conv2D)\n",
      "bn4e_branch2c          (BatchNorm)\n",
      "res4f_branch2a         (Conv2D)\n",
      "bn4f_branch2a          (BatchNorm)\n",
      "res4f_branch2b         (Conv2D)\n",
      "bn4f_branch2b          (BatchNorm)\n",
      "res4f_branch2c         (Conv2D)\n",
      "bn4f_branch2c          (BatchNorm)\n",
      "res4g_branch2a         (Conv2D)\n",
      "bn4g_branch2a          (BatchNorm)\n",
      "res4g_branch2b         (Conv2D)\n",
      "bn4g_branch2b          (BatchNorm)\n",
      "res4g_branch2c         (Conv2D)\n",
      "bn4g_branch2c          (BatchNorm)\n",
      "res4h_branch2a         (Conv2D)\n",
      "bn4h_branch2a          (BatchNorm)\n",
      "res4h_branch2b         (Conv2D)\n",
      "bn4h_branch2b          (BatchNorm)\n",
      "res4h_branch2c         (Conv2D)\n",
      "bn4h_branch2c          (BatchNorm)\n",
      "res4i_branch2a         (Conv2D)\n",
      "bn4i_branch2a          (BatchNorm)\n",
      "res4i_branch2b         (Conv2D)\n",
      "bn4i_branch2b          (BatchNorm)\n",
      "res4i_branch2c         (Conv2D)\n",
      "bn4i_branch2c          (BatchNorm)\n",
      "res4j_branch2a         (Conv2D)\n",
      "bn4j_branch2a          (BatchNorm)\n",
      "res4j_branch2b         (Conv2D)\n",
      "bn4j_branch2b          (BatchNorm)\n",
      "res4j_branch2c         (Conv2D)\n",
      "bn4j_branch2c          (BatchNorm)\n",
      "res4k_branch2a         (Conv2D)\n",
      "bn4k_branch2a          (BatchNorm)\n",
      "res4k_branch2b         (Conv2D)\n",
      "bn4k_branch2b          (BatchNorm)\n",
      "res4k_branch2c         (Conv2D)\n",
      "bn4k_branch2c          (BatchNorm)\n",
      "res4l_branch2a         (Conv2D)\n",
      "bn4l_branch2a          (BatchNorm)\n",
      "res4l_branch2b         (Conv2D)\n",
      "bn4l_branch2b          (BatchNorm)\n",
      "res4l_branch2c         (Conv2D)\n",
      "bn4l_branch2c          (BatchNorm)\n",
      "res4m_branch2a         (Conv2D)\n",
      "bn4m_branch2a          (BatchNorm)\n",
      "res4m_branch2b         (Conv2D)\n",
      "bn4m_branch2b          (BatchNorm)\n",
      "res4m_branch2c         (Conv2D)\n",
      "bn4m_branch2c          (BatchNorm)\n",
      "res4n_branch2a         (Conv2D)\n",
      "bn4n_branch2a          (BatchNorm)\n",
      "res4n_branch2b         (Conv2D)\n",
      "bn4n_branch2b          (BatchNorm)\n",
      "res4n_branch2c         (Conv2D)\n",
      "bn4n_branch2c          (BatchNorm)\n",
      "res4o_branch2a         (Conv2D)\n",
      "bn4o_branch2a          (BatchNorm)\n",
      "res4o_branch2b         (Conv2D)\n",
      "bn4o_branch2b          (BatchNorm)\n",
      "res4o_branch2c         (Conv2D)\n",
      "bn4o_branch2c          (BatchNorm)\n",
      "res4p_branch2a         (Conv2D)\n",
      "bn4p_branch2a          (BatchNorm)\n",
      "res4p_branch2b         (Conv2D)\n",
      "bn4p_branch2b          (BatchNorm)\n",
      "res4p_branch2c         (Conv2D)\n",
      "bn4p_branch2c          (BatchNorm)\n",
      "res4q_branch2a         (Conv2D)\n",
      "bn4q_branch2a          (BatchNorm)\n",
      "res4q_branch2b         (Conv2D)\n",
      "bn4q_branch2b          (BatchNorm)\n",
      "res4q_branch2c         (Conv2D)\n",
      "bn4q_branch2c          (BatchNorm)\n",
      "res4r_branch2a         (Conv2D)\n",
      "bn4r_branch2a          (BatchNorm)\n",
      "res4r_branch2b         (Conv2D)\n",
      "bn4r_branch2b          (BatchNorm)\n",
      "res4r_branch2c         (Conv2D)\n",
      "bn4r_branch2c          (BatchNorm)\n",
      "res4s_branch2a         (Conv2D)\n",
      "bn4s_branch2a          (BatchNorm)\n",
      "res4s_branch2b         (Conv2D)\n",
      "bn4s_branch2b          (BatchNorm)\n",
      "res4s_branch2c         (Conv2D)\n",
      "bn4s_branch2c          (BatchNorm)\n",
      "res4t_branch2a         (Conv2D)\n",
      "bn4t_branch2a          (BatchNorm)\n",
      "res4t_branch2b         (Conv2D)\n",
      "bn4t_branch2b          (BatchNorm)\n",
      "res4t_branch2c         (Conv2D)\n",
      "bn4t_branch2c          (BatchNorm)\n",
      "res4u_branch2a         (Conv2D)\n",
      "bn4u_branch2a          (BatchNorm)\n",
      "res4u_branch2b         (Conv2D)\n",
      "bn4u_branch2b          (BatchNorm)\n",
      "res4u_branch2c         (Conv2D)\n",
      "bn4u_branch2c          (BatchNorm)\n",
      "res4v_branch2a         (Conv2D)\n",
      "bn4v_branch2a          (BatchNorm)\n",
      "res4v_branch2b         (Conv2D)\n",
      "bn4v_branch2b          (BatchNorm)\n",
      "res4v_branch2c         (Conv2D)\n",
      "bn4v_branch2c          (BatchNorm)\n",
      "res4w_branch2a         (Conv2D)\n",
      "bn4w_branch2a          (BatchNorm)\n",
      "res4w_branch2b         (Conv2D)\n",
      "bn4w_branch2b          (BatchNorm)\n",
      "res4w_branch2c         (Conv2D)\n",
      "bn4w_branch2c          (BatchNorm)\n",
      "res5a_branch2a         (Conv2D)\n",
      "bn5a_branch2a          (BatchNorm)\n",
      "res5a_branch2b         (Conv2D)\n",
      "bn5a_branch2b          (BatchNorm)\n",
      "res5a_branch2c         (Conv2D)\n",
      "res5a_branch1          (Conv2D)\n",
      "bn5a_branch2c          (BatchNorm)\n",
      "bn5a_branch1           (BatchNorm)\n",
      "res5b_branch2a         (Conv2D)\n",
      "bn5b_branch2a          (BatchNorm)\n",
      "res5b_branch2b         (Conv2D)\n",
      "bn5b_branch2b          (BatchNorm)\n",
      "res5b_branch2c         (Conv2D)\n",
      "bn5b_branch2c          (BatchNorm)\n",
      "res5c_branch2a         (Conv2D)\n",
      "bn5c_branch2a          (BatchNorm)\n",
      "res5c_branch2b         (Conv2D)\n",
      "bn5c_branch2b          (BatchNorm)\n",
      "res5c_branch2c         (Conv2D)\n",
      "bn5c_branch2c          (BatchNorm)\n",
      "fpn_c5p5               (Conv2D)\n",
      "fpn_c4p4               (Conv2D)\n",
      "fpn_c3p3               (Conv2D)\n",
      "fpn_c2p2               (Conv2D)\n",
      "fpn_p5                 (Conv2D)\n",
      "fpn_p2                 (Conv2D)\n",
      "fpn_p3                 (Conv2D)\n",
      "fpn_p4                 (Conv2D)\n",
      "rpn_model              (Functional)\n",
      "anchors                (ConstLayer)\n",
      "mrcnn_mask_conv1       (TimeDistributed)\n",
      "mrcnn_mask_bn1         (TimeDistributed)\n",
      "mrcnn_mask_conv2       (TimeDistributed)\n",
      "mrcnn_mask_bn2         (TimeDistributed)\n",
      "mrcnn_class_conv1      (TimeDistributed)\n",
      "mrcnn_class_bn1        (TimeDistributed)\n",
      "mrcnn_mask_conv3       (TimeDistributed)\n",
      "mrcnn_mask_bn3         (TimeDistributed)\n",
      "mrcnn_class_conv2      (TimeDistributed)\n",
      "mrcnn_class_bn2        (TimeDistributed)\n",
      "mrcnn_mask_conv4       (TimeDistributed)\n",
      "mrcnn_mask_bn4         (TimeDistributed)\n",
      "mrcnn_bbox_fc          (TimeDistributed)\n",
      "mrcnn_mask_deconv      (TimeDistributed)\n",
      "mrcnn_class_logits     (TimeDistributed)\n",
      "mrcnn_mask             (TimeDistributed)\n",
      "Model: \"mask_rcnn\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_image (InputLayer)    [(None, None, None, 3)]      0         []                            \n",
      "                                                                                                  \n",
      " zero_padding2d (ZeroPaddin  (None, None, None, 3)        0         ['input_image[0][0]']         \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv1 (Conv2D)              (None, None, None, 64)       9472      ['zero_padding2d[0][0]']      \n",
      "                                                                                                  \n",
      " bn_conv1 (BatchNorm)        (None, None, None, 64)       256       ['conv1[0][0]']               \n",
      "                                                                                                  \n",
      " activation (Activation)     (None, None, None, 64)       0         ['bn_conv1[0][0]']            \n",
      "                                                                                                  \n",
      " max_pooling2d (MaxPooling2  (None, None, None, 64)       0         ['activation[0][0]']          \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " res2a_branch2a (Conv2D)     (None, None, None, 64)       4160      ['max_pooling2d[0][0]']       \n",
      "                                                                                                  \n",
      " bn2a_branch2a (BatchNorm)   (None, None, None, 64)       256       ['res2a_branch2a[0][0]']      \n",
      "                                                                                                  \n",
      " activation_1 (Activation)   (None, None, None, 64)       0         ['bn2a_branch2a[0][0]']       \n",
      "                                                                                                  \n",
      " res2a_branch2b (Conv2D)     (None, None, None, 64)       36928     ['activation_1[0][0]']        \n",
      "                                                                                                  \n",
      " bn2a_branch2b (BatchNorm)   (None, None, None, 64)       256       ['res2a_branch2b[0][0]']      \n",
      "                                                                                                  \n",
      " activation_2 (Activation)   (None, None, None, 64)       0         ['bn2a_branch2b[0][0]']       \n",
      "                                                                                                  \n",
      " res2a_branch2c (Conv2D)     (None, None, None, 256)      16640     ['activation_2[0][0]']        \n",
      "                                                                                                  \n",
      " res2a_branch1 (Conv2D)      (None, None, None, 256)      16640     ['max_pooling2d[0][0]']       \n",
      "                                                                                                  \n",
      " bn2a_branch2c (BatchNorm)   (None, None, None, 256)      1024      ['res2a_branch2c[0][0]']      \n",
      "                                                                                                  \n",
      " bn2a_branch1 (BatchNorm)    (None, None, None, 256)      1024      ['res2a_branch1[0][0]']       \n",
      "                                                                                                  \n",
      " add (Add)                   (None, None, None, 256)      0         ['bn2a_branch2c[0][0]',       \n",
      "                                                                     'bn2a_branch1[0][0]']        \n",
      "                                                                                                  \n",
      " res2a_out (Activation)      (None, None, None, 256)      0         ['add[0][0]']                 \n",
      "                                                                                                  \n",
      " res2b_branch2a (Conv2D)     (None, None, None, 64)       16448     ['res2a_out[0][0]']           \n",
      "                                                                                                  \n",
      " bn2b_branch2a (BatchNorm)   (None, None, None, 64)       256       ['res2b_branch2a[0][0]']      \n",
      "                                                                                                  \n",
      " activation_3 (Activation)   (None, None, None, 64)       0         ['bn2b_branch2a[0][0]']       \n",
      "                                                                                                  \n",
      " res2b_branch2b (Conv2D)     (None, None, None, 64)       36928     ['activation_3[0][0]']        \n",
      "                                                                                                  \n",
      " bn2b_branch2b (BatchNorm)   (None, None, None, 64)       256       ['res2b_branch2b[0][0]']      \n",
      "                                                                                                  \n",
      " activation_4 (Activation)   (None, None, None, 64)       0         ['bn2b_branch2b[0][0]']       \n",
      "                                                                                                  \n",
      " res2b_branch2c (Conv2D)     (None, None, None, 256)      16640     ['activation_4[0][0]']        \n",
      "                                                                                                  \n",
      " bn2b_branch2c (BatchNorm)   (None, None, None, 256)      1024      ['res2b_branch2c[0][0]']      \n",
      "                                                                                                  \n",
      " add_1 (Add)                 (None, None, None, 256)      0         ['bn2b_branch2c[0][0]',       \n",
      "                                                                     'res2a_out[0][0]']           \n",
      "                                                                                                  \n",
      " res2b_out (Activation)      (None, None, None, 256)      0         ['add_1[0][0]']               \n",
      "                                                                                                  \n",
      " res2c_branch2a (Conv2D)     (None, None, None, 64)       16448     ['res2b_out[0][0]']           \n",
      "                                                                                                  \n",
      " bn2c_branch2a (BatchNorm)   (None, None, None, 64)       256       ['res2c_branch2a[0][0]']      \n",
      "                                                                                                  \n",
      " activation_5 (Activation)   (None, None, None, 64)       0         ['bn2c_branch2a[0][0]']       \n",
      "                                                                                                  \n",
      " res2c_branch2b (Conv2D)     (None, None, None, 64)       36928     ['activation_5[0][0]']        \n",
      "                                                                                                  \n",
      " bn2c_branch2b (BatchNorm)   (None, None, None, 64)       256       ['res2c_branch2b[0][0]']      \n",
      "                                                                                                  \n",
      " activation_6 (Activation)   (None, None, None, 64)       0         ['bn2c_branch2b[0][0]']       \n",
      "                                                                                                  \n",
      " res2c_branch2c (Conv2D)     (None, None, None, 256)      16640     ['activation_6[0][0]']        \n",
      "                                                                                                  \n",
      " bn2c_branch2c (BatchNorm)   (None, None, None, 256)      1024      ['res2c_branch2c[0][0]']      \n",
      "                                                                                                  \n",
      " add_2 (Add)                 (None, None, None, 256)      0         ['bn2c_branch2c[0][0]',       \n",
      "                                                                     'res2b_out[0][0]']           \n",
      "                                                                                                  \n",
      " res2c_out (Activation)      (None, None, None, 256)      0         ['add_2[0][0]']               \n",
      "                                                                                                  \n",
      " res3a_branch2a (Conv2D)     (None, None, None, 128)      32896     ['res2c_out[0][0]']           \n",
      "                                                                                                  \n",
      " bn3a_branch2a (BatchNorm)   (None, None, None, 128)      512       ['res3a_branch2a[0][0]']      \n",
      "                                                                                                  \n",
      " activation_7 (Activation)   (None, None, None, 128)      0         ['bn3a_branch2a[0][0]']       \n",
      "                                                                                                  \n",
      " res3a_branch2b (Conv2D)     (None, None, None, 128)      147584    ['activation_7[0][0]']        \n",
      "                                                                                                  \n",
      " bn3a_branch2b (BatchNorm)   (None, None, None, 128)      512       ['res3a_branch2b[0][0]']      \n",
      "                                                                                                  \n",
      " activation_8 (Activation)   (None, None, None, 128)      0         ['bn3a_branch2b[0][0]']       \n",
      "                                                                                                  \n",
      " res3a_branch2c (Conv2D)     (None, None, None, 512)      66048     ['activation_8[0][0]']        \n",
      "                                                                                                  \n",
      " res3a_branch1 (Conv2D)      (None, None, None, 512)      131584    ['res2c_out[0][0]']           \n",
      "                                                                                                  \n",
      " bn3a_branch2c (BatchNorm)   (None, None, None, 512)      2048      ['res3a_branch2c[0][0]']      \n",
      "                                                                                                  \n",
      " bn3a_branch1 (BatchNorm)    (None, None, None, 512)      2048      ['res3a_branch1[0][0]']       \n",
      "                                                                                                  \n",
      " add_3 (Add)                 (None, None, None, 512)      0         ['bn3a_branch2c[0][0]',       \n",
      "                                                                     'bn3a_branch1[0][0]']        \n",
      "                                                                                                  \n",
      " res3a_out (Activation)      (None, None, None, 512)      0         ['add_3[0][0]']               \n",
      "                                                                                                  \n",
      " res3b_branch2a (Conv2D)     (None, None, None, 128)      65664     ['res3a_out[0][0]']           \n",
      "                                                                                                  \n",
      " bn3b_branch2a (BatchNorm)   (None, None, None, 128)      512       ['res3b_branch2a[0][0]']      \n",
      "                                                                                                  \n",
      " activation_9 (Activation)   (None, None, None, 128)      0         ['bn3b_branch2a[0][0]']       \n",
      "                                                                                                  \n",
      " res3b_branch2b (Conv2D)     (None, None, None, 128)      147584    ['activation_9[0][0]']        \n",
      "                                                                                                  \n",
      " bn3b_branch2b (BatchNorm)   (None, None, None, 128)      512       ['res3b_branch2b[0][0]']      \n",
      "                                                                                                  \n",
      " activation_10 (Activation)  (None, None, None, 128)      0         ['bn3b_branch2b[0][0]']       \n",
      "                                                                                                  \n",
      " res3b_branch2c (Conv2D)     (None, None, None, 512)      66048     ['activation_10[0][0]']       \n",
      "                                                                                                  \n",
      " bn3b_branch2c (BatchNorm)   (None, None, None, 512)      2048      ['res3b_branch2c[0][0]']      \n",
      "                                                                                                  \n",
      " add_4 (Add)                 (None, None, None, 512)      0         ['bn3b_branch2c[0][0]',       \n",
      "                                                                     'res3a_out[0][0]']           \n",
      "                                                                                                  \n",
      " res3b_out (Activation)      (None, None, None, 512)      0         ['add_4[0][0]']               \n",
      "                                                                                                  \n",
      " res3c_branch2a (Conv2D)     (None, None, None, 128)      65664     ['res3b_out[0][0]']           \n",
      "                                                                                                  \n",
      " bn3c_branch2a (BatchNorm)   (None, None, None, 128)      512       ['res3c_branch2a[0][0]']      \n",
      "                                                                                                  \n",
      " activation_11 (Activation)  (None, None, None, 128)      0         ['bn3c_branch2a[0][0]']       \n",
      "                                                                                                  \n",
      " res3c_branch2b (Conv2D)     (None, None, None, 128)      147584    ['activation_11[0][0]']       \n",
      "                                                                                                  \n",
      " bn3c_branch2b (BatchNorm)   (None, None, None, 128)      512       ['res3c_branch2b[0][0]']      \n",
      "                                                                                                  \n",
      " activation_12 (Activation)  (None, None, None, 128)      0         ['bn3c_branch2b[0][0]']       \n",
      "                                                                                                  \n",
      " res3c_branch2c (Conv2D)     (None, None, None, 512)      66048     ['activation_12[0][0]']       \n",
      "                                                                                                  \n",
      " bn3c_branch2c (BatchNorm)   (None, None, None, 512)      2048      ['res3c_branch2c[0][0]']      \n",
      "                                                                                                  \n",
      " add_5 (Add)                 (None, None, None, 512)      0         ['bn3c_branch2c[0][0]',       \n",
      "                                                                     'res3b_out[0][0]']           \n",
      "                                                                                                  \n",
      " res3c_out (Activation)      (None, None, None, 512)      0         ['add_5[0][0]']               \n",
      "                                                                                                  \n",
      " res3d_branch2a (Conv2D)     (None, None, None, 128)      65664     ['res3c_out[0][0]']           \n",
      "                                                                                                  \n",
      " bn3d_branch2a (BatchNorm)   (None, None, None, 128)      512       ['res3d_branch2a[0][0]']      \n",
      "                                                                                                  \n",
      " activation_13 (Activation)  (None, None, None, 128)      0         ['bn3d_branch2a[0][0]']       \n",
      "                                                                                                  \n",
      " res3d_branch2b (Conv2D)     (None, None, None, 128)      147584    ['activation_13[0][0]']       \n",
      "                                                                                                  \n",
      " bn3d_branch2b (BatchNorm)   (None, None, None, 128)      512       ['res3d_branch2b[0][0]']      \n",
      "                                                                                                  \n",
      " activation_14 (Activation)  (None, None, None, 128)      0         ['bn3d_branch2b[0][0]']       \n",
      "                                                                                                  \n",
      " res3d_branch2c (Conv2D)     (None, None, None, 512)      66048     ['activation_14[0][0]']       \n",
      "                                                                                                  \n",
      " bn3d_branch2c (BatchNorm)   (None, None, None, 512)      2048      ['res3d_branch2c[0][0]']      \n",
      "                                                                                                  \n",
      " add_6 (Add)                 (None, None, None, 512)      0         ['bn3d_branch2c[0][0]',       \n",
      "                                                                     'res3c_out[0][0]']           \n",
      "                                                                                                  \n",
      " res3d_out (Activation)      (None, None, None, 512)      0         ['add_6[0][0]']               \n",
      "                                                                                                  \n",
      " res4a_branch2a (Conv2D)     (None, None, None, 256)      131328    ['res3d_out[0][0]']           \n",
      "                                                                                                  \n",
      " bn4a_branch2a (BatchNorm)   (None, None, None, 256)      1024      ['res4a_branch2a[0][0]']      \n",
      "                                                                                                  \n",
      " activation_15 (Activation)  (None, None, None, 256)      0         ['bn4a_branch2a[0][0]']       \n",
      "                                                                                                  \n",
      " res4a_branch2b (Conv2D)     (None, None, None, 256)      590080    ['activation_15[0][0]']       \n",
      "                                                                                                  \n",
      " bn4a_branch2b (BatchNorm)   (None, None, None, 256)      1024      ['res4a_branch2b[0][0]']      \n",
      "                                                                                                  \n",
      " activation_16 (Activation)  (None, None, None, 256)      0         ['bn4a_branch2b[0][0]']       \n",
      "                                                                                                  \n",
      " res4a_branch2c (Conv2D)     (None, None, None, 1024)     263168    ['activation_16[0][0]']       \n",
      "                                                                                                  \n",
      " res4a_branch1 (Conv2D)      (None, None, None, 1024)     525312    ['res3d_out[0][0]']           \n",
      "                                                                                                  \n",
      " bn4a_branch2c (BatchNorm)   (None, None, None, 1024)     4096      ['res4a_branch2c[0][0]']      \n",
      "                                                                                                  \n",
      " bn4a_branch1 (BatchNorm)    (None, None, None, 1024)     4096      ['res4a_branch1[0][0]']       \n",
      "                                                                                                  \n",
      " add_7 (Add)                 (None, None, None, 1024)     0         ['bn4a_branch2c[0][0]',       \n",
      "                                                                     'bn4a_branch1[0][0]']        \n",
      "                                                                                                  \n",
      " res4a_out (Activation)      (None, None, None, 1024)     0         ['add_7[0][0]']               \n",
      "                                                                                                  \n",
      " res4b_branch2a (Conv2D)     (None, None, None, 256)      262400    ['res4a_out[0][0]']           \n",
      "                                                                                                  \n",
      " bn4b_branch2a (BatchNorm)   (None, None, None, 256)      1024      ['res4b_branch2a[0][0]']      \n",
      "                                                                                                  \n",
      " activation_17 (Activation)  (None, None, None, 256)      0         ['bn4b_branch2a[0][0]']       \n",
      "                                                                                                  \n",
      " res4b_branch2b (Conv2D)     (None, None, None, 256)      590080    ['activation_17[0][0]']       \n",
      "                                                                                                  \n",
      " bn4b_branch2b (BatchNorm)   (None, None, None, 256)      1024      ['res4b_branch2b[0][0]']      \n",
      "                                                                                                  \n",
      " activation_18 (Activation)  (None, None, None, 256)      0         ['bn4b_branch2b[0][0]']       \n",
      "                                                                                                  \n",
      " res4b_branch2c (Conv2D)     (None, None, None, 1024)     263168    ['activation_18[0][0]']       \n",
      "                                                                                                  \n",
      " bn4b_branch2c (BatchNorm)   (None, None, None, 1024)     4096      ['res4b_branch2c[0][0]']      \n",
      "                                                                                                  \n",
      " add_8 (Add)                 (None, None, None, 1024)     0         ['bn4b_branch2c[0][0]',       \n",
      "                                                                     'res4a_out[0][0]']           \n",
      "                                                                                                  \n",
      " res4b_out (Activation)      (None, None, None, 1024)     0         ['add_8[0][0]']               \n",
      "                                                                                                  \n",
      " res4c_branch2a (Conv2D)     (None, None, None, 256)      262400    ['res4b_out[0][0]']           \n",
      "                                                                                                  \n",
      " bn4c_branch2a (BatchNorm)   (None, None, None, 256)      1024      ['res4c_branch2a[0][0]']      \n",
      "                                                                                                  \n",
      " activation_19 (Activation)  (None, None, None, 256)      0         ['bn4c_branch2a[0][0]']       \n",
      "                                                                                                  \n",
      " res4c_branch2b (Conv2D)     (None, None, None, 256)      590080    ['activation_19[0][0]']       \n",
      "                                                                                                  \n",
      " bn4c_branch2b (BatchNorm)   (None, None, None, 256)      1024      ['res4c_branch2b[0][0]']      \n",
      "                                                                                                  \n",
      " activation_20 (Activation)  (None, None, None, 256)      0         ['bn4c_branch2b[0][0]']       \n",
      "                                                                                                  \n",
      " res4c_branch2c (Conv2D)     (None, None, None, 1024)     263168    ['activation_20[0][0]']       \n",
      "                                                                                                  \n",
      " bn4c_branch2c (BatchNorm)   (None, None, None, 1024)     4096      ['res4c_branch2c[0][0]']      \n",
      "                                                                                                  \n",
      " add_9 (Add)                 (None, None, None, 1024)     0         ['bn4c_branch2c[0][0]',       \n",
      "                                                                     'res4b_out[0][0]']           \n",
      "                                                                                                  \n",
      " res4c_out (Activation)      (None, None, None, 1024)     0         ['add_9[0][0]']               \n",
      "                                                                                                  \n",
      " res4d_branch2a (Conv2D)     (None, None, None, 256)      262400    ['res4c_out[0][0]']           \n",
      "                                                                                                  \n",
      " bn4d_branch2a (BatchNorm)   (None, None, None, 256)      1024      ['res4d_branch2a[0][0]']      \n",
      "                                                                                                  \n",
      " activation_21 (Activation)  (None, None, None, 256)      0         ['bn4d_branch2a[0][0]']       \n",
      "                                                                                                  \n",
      " res4d_branch2b (Conv2D)     (None, None, None, 256)      590080    ['activation_21[0][0]']       \n",
      "                                                                                                  \n",
      " bn4d_branch2b (BatchNorm)   (None, None, None, 256)      1024      ['res4d_branch2b[0][0]']      \n",
      "                                                                                                  \n",
      " activation_22 (Activation)  (None, None, None, 256)      0         ['bn4d_branch2b[0][0]']       \n",
      "                                                                                                  \n",
      " res4d_branch2c (Conv2D)     (None, None, None, 1024)     263168    ['activation_22[0][0]']       \n",
      "                                                                                                  \n",
      " bn4d_branch2c (BatchNorm)   (None, None, None, 1024)     4096      ['res4d_branch2c[0][0]']      \n",
      "                                                                                                  \n",
      " add_10 (Add)                (None, None, None, 1024)     0         ['bn4d_branch2c[0][0]',       \n",
      "                                                                     'res4c_out[0][0]']           \n",
      "                                                                                                  \n",
      " res4d_out (Activation)      (None, None, None, 1024)     0         ['add_10[0][0]']              \n",
      "                                                                                                  \n",
      " res4e_branch2a (Conv2D)     (None, None, None, 256)      262400    ['res4d_out[0][0]']           \n",
      "                                                                                                  \n",
      " bn4e_branch2a (BatchNorm)   (None, None, None, 256)      1024      ['res4e_branch2a[0][0]']      \n",
      "                                                                                                  \n",
      " activation_23 (Activation)  (None, None, None, 256)      0         ['bn4e_branch2a[0][0]']       \n",
      "                                                                                                  \n",
      " res4e_branch2b (Conv2D)     (None, None, None, 256)      590080    ['activation_23[0][0]']       \n",
      "                                                                                                  \n",
      " bn4e_branch2b (BatchNorm)   (None, None, None, 256)      1024      ['res4e_branch2b[0][0]']      \n",
      "                                                                                                  \n",
      " activation_24 (Activation)  (None, None, None, 256)      0         ['bn4e_branch2b[0][0]']       \n",
      "                                                                                                  \n",
      " res4e_branch2c (Conv2D)     (None, None, None, 1024)     263168    ['activation_24[0][0]']       \n",
      "                                                                                                  \n",
      " bn4e_branch2c (BatchNorm)   (None, None, None, 1024)     4096      ['res4e_branch2c[0][0]']      \n",
      "                                                                                                  \n",
      " add_11 (Add)                (None, None, None, 1024)     0         ['bn4e_branch2c[0][0]',       \n",
      "                                                                     'res4d_out[0][0]']           \n",
      "                                                                                                  \n",
      " res4e_out (Activation)      (None, None, None, 1024)     0         ['add_11[0][0]']              \n",
      "                                                                                                  \n",
      " res4f_branch2a (Conv2D)     (None, None, None, 256)      262400    ['res4e_out[0][0]']           \n",
      "                                                                                                  \n",
      " bn4f_branch2a (BatchNorm)   (None, None, None, 256)      1024      ['res4f_branch2a[0][0]']      \n",
      "                                                                                                  \n",
      " activation_25 (Activation)  (None, None, None, 256)      0         ['bn4f_branch2a[0][0]']       \n",
      "                                                                                                  \n",
      " res4f_branch2b (Conv2D)     (None, None, None, 256)      590080    ['activation_25[0][0]']       \n",
      "                                                                                                  \n",
      " bn4f_branch2b (BatchNorm)   (None, None, None, 256)      1024      ['res4f_branch2b[0][0]']      \n",
      "                                                                                                  \n",
      " activation_26 (Activation)  (None, None, None, 256)      0         ['bn4f_branch2b[0][0]']       \n",
      "                                                                                                  \n",
      " res4f_branch2c (Conv2D)     (None, None, None, 1024)     263168    ['activation_26[0][0]']       \n",
      "                                                                                                  \n",
      " bn4f_branch2c (BatchNorm)   (None, None, None, 1024)     4096      ['res4f_branch2c[0][0]']      \n",
      "                                                                                                  \n",
      " add_12 (Add)                (None, None, None, 1024)     0         ['bn4f_branch2c[0][0]',       \n",
      "                                                                     'res4e_out[0][0]']           \n",
      "                                                                                                  \n",
      " res4f_out (Activation)      (None, None, None, 1024)     0         ['add_12[0][0]']              \n",
      "                                                                                                  \n",
      " res4g_branch2a (Conv2D)     (None, None, None, 256)      262400    ['res4f_out[0][0]']           \n",
      "                                                                                                  \n",
      " bn4g_branch2a (BatchNorm)   (None, None, None, 256)      1024      ['res4g_branch2a[0][0]']      \n",
      "                                                                                                  \n",
      " activation_27 (Activation)  (None, None, None, 256)      0         ['bn4g_branch2a[0][0]']       \n",
      "                                                                                                  \n",
      " res4g_branch2b (Conv2D)     (None, None, None, 256)      590080    ['activation_27[0][0]']       \n",
      "                                                                                                  \n",
      " bn4g_branch2b (BatchNorm)   (None, None, None, 256)      1024      ['res4g_branch2b[0][0]']      \n",
      "                                                                                                  \n",
      " activation_28 (Activation)  (None, None, None, 256)      0         ['bn4g_branch2b[0][0]']       \n",
      "                                                                                                  \n",
      " res4g_branch2c (Conv2D)     (None, None, None, 1024)     263168    ['activation_28[0][0]']       \n",
      "                                                                                                  \n",
      " bn4g_branch2c (BatchNorm)   (None, None, None, 1024)     4096      ['res4g_branch2c[0][0]']      \n",
      "                                                                                                  \n",
      " add_13 (Add)                (None, None, None, 1024)     0         ['bn4g_branch2c[0][0]',       \n",
      "                                                                     'res4f_out[0][0]']           \n",
      "                                                                                                  \n",
      " res4g_out (Activation)      (None, None, None, 1024)     0         ['add_13[0][0]']              \n",
      "                                                                                                  \n",
      " res4h_branch2a (Conv2D)     (None, None, None, 256)      262400    ['res4g_out[0][0]']           \n",
      "                                                                                                  \n",
      " bn4h_branch2a (BatchNorm)   (None, None, None, 256)      1024      ['res4h_branch2a[0][0]']      \n",
      "                                                                                                  \n",
      " activation_29 (Activation)  (None, None, None, 256)      0         ['bn4h_branch2a[0][0]']       \n",
      "                                                                                                  \n",
      " res4h_branch2b (Conv2D)     (None, None, None, 256)      590080    ['activation_29[0][0]']       \n",
      "                                                                                                  \n",
      " bn4h_branch2b (BatchNorm)   (None, None, None, 256)      1024      ['res4h_branch2b[0][0]']      \n",
      "                                                                                                  \n",
      " activation_30 (Activation)  (None, None, None, 256)      0         ['bn4h_branch2b[0][0]']       \n",
      "                                                                                                  \n",
      " res4h_branch2c (Conv2D)     (None, None, None, 1024)     263168    ['activation_30[0][0]']       \n",
      "                                                                                                  \n",
      " bn4h_branch2c (BatchNorm)   (None, None, None, 1024)     4096      ['res4h_branch2c[0][0]']      \n",
      "                                                                                                  \n",
      " add_14 (Add)                (None, None, None, 1024)     0         ['bn4h_branch2c[0][0]',       \n",
      "                                                                     'res4g_out[0][0]']           \n",
      "                                                                                                  \n",
      " res4h_out (Activation)      (None, None, None, 1024)     0         ['add_14[0][0]']              \n",
      "                                                                                                  \n",
      " res4i_branch2a (Conv2D)     (None, None, None, 256)      262400    ['res4h_out[0][0]']           \n",
      "                                                                                                  \n",
      " bn4i_branch2a (BatchNorm)   (None, None, None, 256)      1024      ['res4i_branch2a[0][0]']      \n",
      "                                                                                                  \n",
      " activation_31 (Activation)  (None, None, None, 256)      0         ['bn4i_branch2a[0][0]']       \n",
      "                                                                                                  \n",
      " res4i_branch2b (Conv2D)     (None, None, None, 256)      590080    ['activation_31[0][0]']       \n",
      "                                                                                                  \n",
      " bn4i_branch2b (BatchNorm)   (None, None, None, 256)      1024      ['res4i_branch2b[0][0]']      \n",
      "                                                                                                  \n",
      " activation_32 (Activation)  (None, None, None, 256)      0         ['bn4i_branch2b[0][0]']       \n",
      "                                                                                                  \n",
      " res4i_branch2c (Conv2D)     (None, None, None, 1024)     263168    ['activation_32[0][0]']       \n",
      "                                                                                                  \n",
      " bn4i_branch2c (BatchNorm)   (None, None, None, 1024)     4096      ['res4i_branch2c[0][0]']      \n",
      "                                                                                                  \n",
      " add_15 (Add)                (None, None, None, 1024)     0         ['bn4i_branch2c[0][0]',       \n",
      "                                                                     'res4h_out[0][0]']           \n",
      "                                                                                                  \n",
      " res4i_out (Activation)      (None, None, None, 1024)     0         ['add_15[0][0]']              \n",
      "                                                                                                  \n",
      " res4j_branch2a (Conv2D)     (None, None, None, 256)      262400    ['res4i_out[0][0]']           \n",
      "                                                                                                  \n",
      " bn4j_branch2a (BatchNorm)   (None, None, None, 256)      1024      ['res4j_branch2a[0][0]']      \n",
      "                                                                                                  \n",
      " activation_33 (Activation)  (None, None, None, 256)      0         ['bn4j_branch2a[0][0]']       \n",
      "                                                                                                  \n",
      " res4j_branch2b (Conv2D)     (None, None, None, 256)      590080    ['activation_33[0][0]']       \n",
      "                                                                                                  \n",
      " bn4j_branch2b (BatchNorm)   (None, None, None, 256)      1024      ['res4j_branch2b[0][0]']      \n",
      "                                                                                                  \n",
      " activation_34 (Activation)  (None, None, None, 256)      0         ['bn4j_branch2b[0][0]']       \n",
      "                                                                                                  \n",
      " res4j_branch2c (Conv2D)     (None, None, None, 1024)     263168    ['activation_34[0][0]']       \n",
      "                                                                                                  \n",
      " bn4j_branch2c (BatchNorm)   (None, None, None, 1024)     4096      ['res4j_branch2c[0][0]']      \n",
      "                                                                                                  \n",
      " add_16 (Add)                (None, None, None, 1024)     0         ['bn4j_branch2c[0][0]',       \n",
      "                                                                     'res4i_out[0][0]']           \n",
      "                                                                                                  \n",
      " res4j_out (Activation)      (None, None, None, 1024)     0         ['add_16[0][0]']              \n",
      "                                                                                                  \n",
      " res4k_branch2a (Conv2D)     (None, None, None, 256)      262400    ['res4j_out[0][0]']           \n",
      "                                                                                                  \n",
      " bn4k_branch2a (BatchNorm)   (None, None, None, 256)      1024      ['res4k_branch2a[0][0]']      \n",
      "                                                                                                  \n",
      " activation_35 (Activation)  (None, None, None, 256)      0         ['bn4k_branch2a[0][0]']       \n",
      "                                                                                                  \n",
      " res4k_branch2b (Conv2D)     (None, None, None, 256)      590080    ['activation_35[0][0]']       \n",
      "                                                                                                  \n",
      " bn4k_branch2b (BatchNorm)   (None, None, None, 256)      1024      ['res4k_branch2b[0][0]']      \n",
      "                                                                                                  \n",
      " activation_36 (Activation)  (None, None, None, 256)      0         ['bn4k_branch2b[0][0]']       \n",
      "                                                                                                  \n",
      " res4k_branch2c (Conv2D)     (None, None, None, 1024)     263168    ['activation_36[0][0]']       \n",
      "                                                                                                  \n",
      " bn4k_branch2c (BatchNorm)   (None, None, None, 1024)     4096      ['res4k_branch2c[0][0]']      \n",
      "                                                                                                  \n",
      " add_17 (Add)                (None, None, None, 1024)     0         ['bn4k_branch2c[0][0]',       \n",
      "                                                                     'res4j_out[0][0]']           \n",
      "                                                                                                  \n",
      " res4k_out (Activation)      (None, None, None, 1024)     0         ['add_17[0][0]']              \n",
      "                                                                                                  \n",
      " res4l_branch2a (Conv2D)     (None, None, None, 256)      262400    ['res4k_out[0][0]']           \n",
      "                                                                                                  \n",
      " bn4l_branch2a (BatchNorm)   (None, None, None, 256)      1024      ['res4l_branch2a[0][0]']      \n",
      "                                                                                                  \n",
      " activation_37 (Activation)  (None, None, None, 256)      0         ['bn4l_branch2a[0][0]']       \n",
      "                                                                                                  \n",
      " res4l_branch2b (Conv2D)     (None, None, None, 256)      590080    ['activation_37[0][0]']       \n",
      "                                                                                                  \n",
      " bn4l_branch2b (BatchNorm)   (None, None, None, 256)      1024      ['res4l_branch2b[0][0]']      \n",
      "                                                                                                  \n",
      " activation_38 (Activation)  (None, None, None, 256)      0         ['bn4l_branch2b[0][0]']       \n",
      "                                                                                                  \n",
      " res4l_branch2c (Conv2D)     (None, None, None, 1024)     263168    ['activation_38[0][0]']       \n",
      "                                                                                                  \n",
      " bn4l_branch2c (BatchNorm)   (None, None, None, 1024)     4096      ['res4l_branch2c[0][0]']      \n",
      "                                                                                                  \n",
      " add_18 (Add)                (None, None, None, 1024)     0         ['bn4l_branch2c[0][0]',       \n",
      "                                                                     'res4k_out[0][0]']           \n",
      "                                                                                                  \n",
      " res4l_out (Activation)      (None, None, None, 1024)     0         ['add_18[0][0]']              \n",
      "                                                                                                  \n",
      " res4m_branch2a (Conv2D)     (None, None, None, 256)      262400    ['res4l_out[0][0]']           \n",
      "                                                                                                  \n",
      " bn4m_branch2a (BatchNorm)   (None, None, None, 256)      1024      ['res4m_branch2a[0][0]']      \n",
      "                                                                                                  \n",
      " activation_39 (Activation)  (None, None, None, 256)      0         ['bn4m_branch2a[0][0]']       \n",
      "                                                                                                  \n",
      " res4m_branch2b (Conv2D)     (None, None, None, 256)      590080    ['activation_39[0][0]']       \n",
      "                                                                                                  \n",
      " bn4m_branch2b (BatchNorm)   (None, None, None, 256)      1024      ['res4m_branch2b[0][0]']      \n",
      "                                                                                                  \n",
      " activation_40 (Activation)  (None, None, None, 256)      0         ['bn4m_branch2b[0][0]']       \n",
      "                                                                                                  \n",
      " res4m_branch2c (Conv2D)     (None, None, None, 1024)     263168    ['activation_40[0][0]']       \n",
      "                                                                                                  \n",
      " bn4m_branch2c (BatchNorm)   (None, None, None, 1024)     4096      ['res4m_branch2c[0][0]']      \n",
      "                                                                                                  \n",
      " add_19 (Add)                (None, None, None, 1024)     0         ['bn4m_branch2c[0][0]',       \n",
      "                                                                     'res4l_out[0][0]']           \n",
      "                                                                                                  \n",
      " res4m_out (Activation)      (None, None, None, 1024)     0         ['add_19[0][0]']              \n",
      "                                                                                                  \n",
      " res4n_branch2a (Conv2D)     (None, None, None, 256)      262400    ['res4m_out[0][0]']           \n",
      "                                                                                                  \n",
      " bn4n_branch2a (BatchNorm)   (None, None, None, 256)      1024      ['res4n_branch2a[0][0]']      \n",
      "                                                                                                  \n",
      " activation_41 (Activation)  (None, None, None, 256)      0         ['bn4n_branch2a[0][0]']       \n",
      "                                                                                                  \n",
      " res4n_branch2b (Conv2D)     (None, None, None, 256)      590080    ['activation_41[0][0]']       \n",
      "                                                                                                  \n",
      " bn4n_branch2b (BatchNorm)   (None, None, None, 256)      1024      ['res4n_branch2b[0][0]']      \n",
      "                                                                                                  \n",
      " activation_42 (Activation)  (None, None, None, 256)      0         ['bn4n_branch2b[0][0]']       \n",
      "                                                                                                  \n",
      " res4n_branch2c (Conv2D)     (None, None, None, 1024)     263168    ['activation_42[0][0]']       \n",
      "                                                                                                  \n",
      " bn4n_branch2c (BatchNorm)   (None, None, None, 1024)     4096      ['res4n_branch2c[0][0]']      \n",
      "                                                                                                  \n",
      " add_20 (Add)                (None, None, None, 1024)     0         ['bn4n_branch2c[0][0]',       \n",
      "                                                                     'res4m_out[0][0]']           \n",
      "                                                                                                  \n",
      " res4n_out (Activation)      (None, None, None, 1024)     0         ['add_20[0][0]']              \n",
      "                                                                                                  \n",
      " res4o_branch2a (Conv2D)     (None, None, None, 256)      262400    ['res4n_out[0][0]']           \n",
      "                                                                                                  \n",
      " bn4o_branch2a (BatchNorm)   (None, None, None, 256)      1024      ['res4o_branch2a[0][0]']      \n",
      "                                                                                                  \n",
      " activation_43 (Activation)  (None, None, None, 256)      0         ['bn4o_branch2a[0][0]']       \n",
      "                                                                                                  \n",
      " res4o_branch2b (Conv2D)     (None, None, None, 256)      590080    ['activation_43[0][0]']       \n",
      "                                                                                                  \n",
      " bn4o_branch2b (BatchNorm)   (None, None, None, 256)      1024      ['res4o_branch2b[0][0]']      \n",
      "                                                                                                  \n",
      " activation_44 (Activation)  (None, None, None, 256)      0         ['bn4o_branch2b[0][0]']       \n",
      "                                                                                                  \n",
      " res4o_branch2c (Conv2D)     (None, None, None, 1024)     263168    ['activation_44[0][0]']       \n",
      "                                                                                                  \n",
      " bn4o_branch2c (BatchNorm)   (None, None, None, 1024)     4096      ['res4o_branch2c[0][0]']      \n",
      "                                                                                                  \n",
      " add_21 (Add)                (None, None, None, 1024)     0         ['bn4o_branch2c[0][0]',       \n",
      "                                                                     'res4n_out[0][0]']           \n",
      "                                                                                                  \n",
      " res4o_out (Activation)      (None, None, None, 1024)     0         ['add_21[0][0]']              \n",
      "                                                                                                  \n",
      " res4p_branch2a (Conv2D)     (None, None, None, 256)      262400    ['res4o_out[0][0]']           \n",
      "                                                                                                  \n",
      " bn4p_branch2a (BatchNorm)   (None, None, None, 256)      1024      ['res4p_branch2a[0][0]']      \n",
      "                                                                                                  \n",
      " activation_45 (Activation)  (None, None, None, 256)      0         ['bn4p_branch2a[0][0]']       \n",
      "                                                                                                  \n",
      " res4p_branch2b (Conv2D)     (None, None, None, 256)      590080    ['activation_45[0][0]']       \n",
      "                                                                                                  \n",
      " bn4p_branch2b (BatchNorm)   (None, None, None, 256)      1024      ['res4p_branch2b[0][0]']      \n",
      "                                                                                                  \n",
      " activation_46 (Activation)  (None, None, None, 256)      0         ['bn4p_branch2b[0][0]']       \n",
      "                                                                                                  \n",
      " res4p_branch2c (Conv2D)     (None, None, None, 1024)     263168    ['activation_46[0][0]']       \n",
      "                                                                                                  \n",
      " bn4p_branch2c (BatchNorm)   (None, None, None, 1024)     4096      ['res4p_branch2c[0][0]']      \n",
      "                                                                                                  \n",
      " add_22 (Add)                (None, None, None, 1024)     0         ['bn4p_branch2c[0][0]',       \n",
      "                                                                     'res4o_out[0][0]']           \n",
      "                                                                                                  \n",
      " res4p_out (Activation)      (None, None, None, 1024)     0         ['add_22[0][0]']              \n",
      "                                                                                                  \n",
      " res4q_branch2a (Conv2D)     (None, None, None, 256)      262400    ['res4p_out[0][0]']           \n",
      "                                                                                                  \n",
      " bn4q_branch2a (BatchNorm)   (None, None, None, 256)      1024      ['res4q_branch2a[0][0]']      \n",
      "                                                                                                  \n",
      " activation_47 (Activation)  (None, None, None, 256)      0         ['bn4q_branch2a[0][0]']       \n",
      "                                                                                                  \n",
      " res4q_branch2b (Conv2D)     (None, None, None, 256)      590080    ['activation_47[0][0]']       \n",
      "                                                                                                  \n",
      " bn4q_branch2b (BatchNorm)   (None, None, None, 256)      1024      ['res4q_branch2b[0][0]']      \n",
      "                                                                                                  \n",
      " activation_48 (Activation)  (None, None, None, 256)      0         ['bn4q_branch2b[0][0]']       \n",
      "                                                                                                  \n",
      " res4q_branch2c (Conv2D)     (None, None, None, 1024)     263168    ['activation_48[0][0]']       \n",
      "                                                                                                  \n",
      " bn4q_branch2c (BatchNorm)   (None, None, None, 1024)     4096      ['res4q_branch2c[0][0]']      \n",
      "                                                                                                  \n",
      " add_23 (Add)                (None, None, None, 1024)     0         ['bn4q_branch2c[0][0]',       \n",
      "                                                                     'res4p_out[0][0]']           \n",
      "                                                                                                  \n",
      " res4q_out (Activation)      (None, None, None, 1024)     0         ['add_23[0][0]']              \n",
      "                                                                                                  \n",
      " res4r_branch2a (Conv2D)     (None, None, None, 256)      262400    ['res4q_out[0][0]']           \n",
      "                                                                                                  \n",
      " bn4r_branch2a (BatchNorm)   (None, None, None, 256)      1024      ['res4r_branch2a[0][0]']      \n",
      "                                                                                                  \n",
      " activation_49 (Activation)  (None, None, None, 256)      0         ['bn4r_branch2a[0][0]']       \n",
      "                                                                                                  \n",
      " res4r_branch2b (Conv2D)     (None, None, None, 256)      590080    ['activation_49[0][0]']       \n",
      "                                                                                                  \n",
      " bn4r_branch2b (BatchNorm)   (None, None, None, 256)      1024      ['res4r_branch2b[0][0]']      \n",
      "                                                                                                  \n",
      " activation_50 (Activation)  (None, None, None, 256)      0         ['bn4r_branch2b[0][0]']       \n",
      "                                                                                                  \n",
      " res4r_branch2c (Conv2D)     (None, None, None, 1024)     263168    ['activation_50[0][0]']       \n",
      "                                                                                                  \n",
      " bn4r_branch2c (BatchNorm)   (None, None, None, 1024)     4096      ['res4r_branch2c[0][0]']      \n",
      "                                                                                                  \n",
      " add_24 (Add)                (None, None, None, 1024)     0         ['bn4r_branch2c[0][0]',       \n",
      "                                                                     'res4q_out[0][0]']           \n",
      "                                                                                                  \n",
      " res4r_out (Activation)      (None, None, None, 1024)     0         ['add_24[0][0]']              \n",
      "                                                                                                  \n",
      " res4s_branch2a (Conv2D)     (None, None, None, 256)      262400    ['res4r_out[0][0]']           \n",
      "                                                                                                  \n",
      " bn4s_branch2a (BatchNorm)   (None, None, None, 256)      1024      ['res4s_branch2a[0][0]']      \n",
      "                                                                                                  \n",
      " activation_51 (Activation)  (None, None, None, 256)      0         ['bn4s_branch2a[0][0]']       \n",
      "                                                                                                  \n",
      " res4s_branch2b (Conv2D)     (None, None, None, 256)      590080    ['activation_51[0][0]']       \n",
      "                                                                                                  \n",
      " bn4s_branch2b (BatchNorm)   (None, None, None, 256)      1024      ['res4s_branch2b[0][0]']      \n",
      "                                                                                                  \n",
      " activation_52 (Activation)  (None, None, None, 256)      0         ['bn4s_branch2b[0][0]']       \n",
      "                                                                                                  \n",
      " res4s_branch2c (Conv2D)     (None, None, None, 1024)     263168    ['activation_52[0][0]']       \n",
      "                                                                                                  \n",
      " bn4s_branch2c (BatchNorm)   (None, None, None, 1024)     4096      ['res4s_branch2c[0][0]']      \n",
      "                                                                                                  \n",
      " add_25 (Add)                (None, None, None, 1024)     0         ['bn4s_branch2c[0][0]',       \n",
      "                                                                     'res4r_out[0][0]']           \n",
      "                                                                                                  \n",
      " res4s_out (Activation)      (None, None, None, 1024)     0         ['add_25[0][0]']              \n",
      "                                                                                                  \n",
      " res4t_branch2a (Conv2D)     (None, None, None, 256)      262400    ['res4s_out[0][0]']           \n",
      "                                                                                                  \n",
      " bn4t_branch2a (BatchNorm)   (None, None, None, 256)      1024      ['res4t_branch2a[0][0]']      \n",
      "                                                                                                  \n",
      " activation_53 (Activation)  (None, None, None, 256)      0         ['bn4t_branch2a[0][0]']       \n",
      "                                                                                                  \n",
      " res4t_branch2b (Conv2D)     (None, None, None, 256)      590080    ['activation_53[0][0]']       \n",
      "                                                                                                  \n",
      " bn4t_branch2b (BatchNorm)   (None, None, None, 256)      1024      ['res4t_branch2b[0][0]']      \n",
      "                                                                                                  \n",
      " activation_54 (Activation)  (None, None, None, 256)      0         ['bn4t_branch2b[0][0]']       \n",
      "                                                                                                  \n",
      " res4t_branch2c (Conv2D)     (None, None, None, 1024)     263168    ['activation_54[0][0]']       \n",
      "                                                                                                  \n",
      " bn4t_branch2c (BatchNorm)   (None, None, None, 1024)     4096      ['res4t_branch2c[0][0]']      \n",
      "                                                                                                  \n",
      " add_26 (Add)                (None, None, None, 1024)     0         ['bn4t_branch2c[0][0]',       \n",
      "                                                                     'res4s_out[0][0]']           \n",
      "                                                                                                  \n",
      " res4t_out (Activation)      (None, None, None, 1024)     0         ['add_26[0][0]']              \n",
      "                                                                                                  \n",
      " res4u_branch2a (Conv2D)     (None, None, None, 256)      262400    ['res4t_out[0][0]']           \n",
      "                                                                                                  \n",
      " bn4u_branch2a (BatchNorm)   (None, None, None, 256)      1024      ['res4u_branch2a[0][0]']      \n",
      "                                                                                                  \n",
      " activation_55 (Activation)  (None, None, None, 256)      0         ['bn4u_branch2a[0][0]']       \n",
      "                                                                                                  \n",
      " res4u_branch2b (Conv2D)     (None, None, None, 256)      590080    ['activation_55[0][0]']       \n",
      "                                                                                                  \n",
      " bn4u_branch2b (BatchNorm)   (None, None, None, 256)      1024      ['res4u_branch2b[0][0]']      \n",
      "                                                                                                  \n",
      " activation_56 (Activation)  (None, None, None, 256)      0         ['bn4u_branch2b[0][0]']       \n",
      "                                                                                                  \n",
      " res4u_branch2c (Conv2D)     (None, None, None, 1024)     263168    ['activation_56[0][0]']       \n",
      "                                                                                                  \n",
      " bn4u_branch2c (BatchNorm)   (None, None, None, 1024)     4096      ['res4u_branch2c[0][0]']      \n",
      "                                                                                                  \n",
      " add_27 (Add)                (None, None, None, 1024)     0         ['bn4u_branch2c[0][0]',       \n",
      "                                                                     'res4t_out[0][0]']           \n",
      "                                                                                                  \n",
      " res4u_out (Activation)      (None, None, None, 1024)     0         ['add_27[0][0]']              \n",
      "                                                                                                  \n",
      " res4v_branch2a (Conv2D)     (None, None, None, 256)      262400    ['res4u_out[0][0]']           \n",
      "                                                                                                  \n",
      " bn4v_branch2a (BatchNorm)   (None, None, None, 256)      1024      ['res4v_branch2a[0][0]']      \n",
      "                                                                                                  \n",
      " activation_57 (Activation)  (None, None, None, 256)      0         ['bn4v_branch2a[0][0]']       \n",
      "                                                                                                  \n",
      " res4v_branch2b (Conv2D)     (None, None, None, 256)      590080    ['activation_57[0][0]']       \n",
      "                                                                                                  \n",
      " bn4v_branch2b (BatchNorm)   (None, None, None, 256)      1024      ['res4v_branch2b[0][0]']      \n",
      "                                                                                                  \n",
      " activation_58 (Activation)  (None, None, None, 256)      0         ['bn4v_branch2b[0][0]']       \n",
      "                                                                                                  \n",
      " res4v_branch2c (Conv2D)     (None, None, None, 1024)     263168    ['activation_58[0][0]']       \n",
      "                                                                                                  \n",
      " bn4v_branch2c (BatchNorm)   (None, None, None, 1024)     4096      ['res4v_branch2c[0][0]']      \n",
      "                                                                                                  \n",
      " add_28 (Add)                (None, None, None, 1024)     0         ['bn4v_branch2c[0][0]',       \n",
      "                                                                     'res4u_out[0][0]']           \n",
      "                                                                                                  \n",
      " res4v_out (Activation)      (None, None, None, 1024)     0         ['add_28[0][0]']              \n",
      "                                                                                                  \n",
      " res4w_branch2a (Conv2D)     (None, None, None, 256)      262400    ['res4v_out[0][0]']           \n",
      "                                                                                                  \n",
      " bn4w_branch2a (BatchNorm)   (None, None, None, 256)      1024      ['res4w_branch2a[0][0]']      \n",
      "                                                                                                  \n",
      " activation_59 (Activation)  (None, None, None, 256)      0         ['bn4w_branch2a[0][0]']       \n",
      "                                                                                                  \n",
      " res4w_branch2b (Conv2D)     (None, None, None, 256)      590080    ['activation_59[0][0]']       \n",
      "                                                                                                  \n",
      " bn4w_branch2b (BatchNorm)   (None, None, None, 256)      1024      ['res4w_branch2b[0][0]']      \n",
      "                                                                                                  \n",
      " activation_60 (Activation)  (None, None, None, 256)      0         ['bn4w_branch2b[0][0]']       \n",
      "                                                                                                  \n",
      " res4w_branch2c (Conv2D)     (None, None, None, 1024)     263168    ['activation_60[0][0]']       \n",
      "                                                                                                  \n",
      " bn4w_branch2c (BatchNorm)   (None, None, None, 1024)     4096      ['res4w_branch2c[0][0]']      \n",
      "                                                                                                  \n",
      " add_29 (Add)                (None, None, None, 1024)     0         ['bn4w_branch2c[0][0]',       \n",
      "                                                                     'res4v_out[0][0]']           \n",
      "                                                                                                  \n",
      " res4w_out (Activation)      (None, None, None, 1024)     0         ['add_29[0][0]']              \n",
      "                                                                                                  \n",
      " res5a_branch2a (Conv2D)     (None, None, None, 512)      524800    ['res4w_out[0][0]']           \n",
      "                                                                                                  \n",
      " bn5a_branch2a (BatchNorm)   (None, None, None, 512)      2048      ['res5a_branch2a[0][0]']      \n",
      "                                                                                                  \n",
      " activation_61 (Activation)  (None, None, None, 512)      0         ['bn5a_branch2a[0][0]']       \n",
      "                                                                                                  \n",
      " res5a_branch2b (Conv2D)     (None, None, None, 512)      2359808   ['activation_61[0][0]']       \n",
      "                                                                                                  \n",
      " bn5a_branch2b (BatchNorm)   (None, None, None, 512)      2048      ['res5a_branch2b[0][0]']      \n",
      "                                                                                                  \n",
      " activation_62 (Activation)  (None, None, None, 512)      0         ['bn5a_branch2b[0][0]']       \n",
      "                                                                                                  \n",
      " res5a_branch2c (Conv2D)     (None, None, None, 2048)     1050624   ['activation_62[0][0]']       \n",
      "                                                                                                  \n",
      " res5a_branch1 (Conv2D)      (None, None, None, 2048)     2099200   ['res4w_out[0][0]']           \n",
      "                                                                                                  \n",
      " bn5a_branch2c (BatchNorm)   (None, None, None, 2048)     8192      ['res5a_branch2c[0][0]']      \n",
      "                                                                                                  \n",
      " bn5a_branch1 (BatchNorm)    (None, None, None, 2048)     8192      ['res5a_branch1[0][0]']       \n",
      "                                                                                                  \n",
      " add_30 (Add)                (None, None, None, 2048)     0         ['bn5a_branch2c[0][0]',       \n",
      "                                                                     'bn5a_branch1[0][0]']        \n",
      "                                                                                                  \n",
      " res5a_out (Activation)      (None, None, None, 2048)     0         ['add_30[0][0]']              \n",
      "                                                                                                  \n",
      " res5b_branch2a (Conv2D)     (None, None, None, 512)      1049088   ['res5a_out[0][0]']           \n",
      "                                                                                                  \n",
      " bn5b_branch2a (BatchNorm)   (None, None, None, 512)      2048      ['res5b_branch2a[0][0]']      \n",
      "                                                                                                  \n",
      " activation_63 (Activation)  (None, None, None, 512)      0         ['bn5b_branch2a[0][0]']       \n",
      "                                                                                                  \n",
      " res5b_branch2b (Conv2D)     (None, None, None, 512)      2359808   ['activation_63[0][0]']       \n",
      "                                                                                                  \n",
      " bn5b_branch2b (BatchNorm)   (None, None, None, 512)      2048      ['res5b_branch2b[0][0]']      \n",
      "                                                                                                  \n",
      " activation_64 (Activation)  (None, None, None, 512)      0         ['bn5b_branch2b[0][0]']       \n",
      "                                                                                                  \n",
      " res5b_branch2c (Conv2D)     (None, None, None, 2048)     1050624   ['activation_64[0][0]']       \n",
      "                                                                                                  \n",
      " bn5b_branch2c (BatchNorm)   (None, None, None, 2048)     8192      ['res5b_branch2c[0][0]']      \n",
      "                                                                                                  \n",
      " add_31 (Add)                (None, None, None, 2048)     0         ['bn5b_branch2c[0][0]',       \n",
      "                                                                     'res5a_out[0][0]']           \n",
      "                                                                                                  \n",
      " res5b_out (Activation)      (None, None, None, 2048)     0         ['add_31[0][0]']              \n",
      "                                                                                                  \n",
      " res5c_branch2a (Conv2D)     (None, None, None, 512)      1049088   ['res5b_out[0][0]']           \n",
      "                                                                                                  \n",
      " bn5c_branch2a (BatchNorm)   (None, None, None, 512)      2048      ['res5c_branch2a[0][0]']      \n",
      "                                                                                                  \n",
      " activation_65 (Activation)  (None, None, None, 512)      0         ['bn5c_branch2a[0][0]']       \n",
      "                                                                                                  \n",
      " res5c_branch2b (Conv2D)     (None, None, None, 512)      2359808   ['activation_65[0][0]']       \n",
      "                                                                                                  \n",
      " bn5c_branch2b (BatchNorm)   (None, None, None, 512)      2048      ['res5c_branch2b[0][0]']      \n",
      "                                                                                                  \n",
      " activation_66 (Activation)  (None, None, None, 512)      0         ['bn5c_branch2b[0][0]']       \n",
      "                                                                                                  \n",
      " res5c_branch2c (Conv2D)     (None, None, None, 2048)     1050624   ['activation_66[0][0]']       \n",
      "                                                                                                  \n",
      " bn5c_branch2c (BatchNorm)   (None, None, None, 2048)     8192      ['res5c_branch2c[0][0]']      \n",
      "                                                                                                  \n",
      " add_32 (Add)                (None, None, None, 2048)     0         ['bn5c_branch2c[0][0]',       \n",
      "                                                                     'res5b_out[0][0]']           \n",
      "                                                                                                  \n",
      " res5c_out (Activation)      (None, None, None, 2048)     0         ['add_32[0][0]']              \n",
      "                                                                                                  \n",
      " fpn_c5p5 (Conv2D)           (None, None, None, 256)      524544    ['res5c_out[0][0]']           \n",
      "                                                                                                  \n",
      " fpn_p5upsampled (UpSamplin  (None, None, None, 256)      0         ['fpn_c5p5[0][0]']            \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " fpn_c4p4 (Conv2D)           (None, None, None, 256)      262400    ['res4w_out[0][0]']           \n",
      "                                                                                                  \n",
      " fpn_p4add (Add)             (None, None, None, 256)      0         ['fpn_p5upsampled[0][0]',     \n",
      "                                                                     'fpn_c4p4[0][0]']            \n",
      "                                                                                                  \n",
      " fpn_p4upsampled (UpSamplin  (None, None, None, 256)      0         ['fpn_p4add[0][0]']           \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " fpn_c3p3 (Conv2D)           (None, None, None, 256)      131328    ['res3d_out[0][0]']           \n",
      "                                                                                                  \n",
      " fpn_p3add (Add)             (None, None, None, 256)      0         ['fpn_p4upsampled[0][0]',     \n",
      "                                                                     'fpn_c3p3[0][0]']            \n",
      "                                                                                                  \n",
      " fpn_p3upsampled (UpSamplin  (None, None, None, 256)      0         ['fpn_p3add[0][0]']           \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " fpn_c2p2 (Conv2D)           (None, None, None, 256)      65792     ['res2c_out[0][0]']           \n",
      "                                                                                                  \n",
      " fpn_p2add (Add)             (None, None, None, 256)      0         ['fpn_p3upsampled[0][0]',     \n",
      "                                                                     'fpn_c2p2[0][0]']            \n",
      "                                                                                                  \n",
      " fpn_p5 (Conv2D)             (None, None, None, 256)      590080    ['fpn_c5p5[0][0]']            \n",
      "                                                                                                  \n",
      " fpn_p2 (Conv2D)             (None, None, None, 256)      590080    ['fpn_p2add[0][0]']           \n",
      "                                                                                                  \n",
      " fpn_p3 (Conv2D)             (None, None, None, 256)      590080    ['fpn_p3add[0][0]']           \n",
      "                                                                                                  \n",
      " fpn_p4 (Conv2D)             (None, None, None, 256)      590080    ['fpn_p4add[0][0]']           \n",
      "                                                                                                  \n",
      " fpn_p6 (MaxPooling2D)       (None, None, None, 256)      0         ['fpn_p5[0][0]']              \n",
      "                                                                                                  \n",
      " rpn_model (Functional)      [(None, None, 2),            1189394   ['fpn_p2[0][0]',              \n",
      "                              (None, None, 2),                       'fpn_p3[0][0]',              \n",
      "                              (None, None, 4)]                       'fpn_p4[0][0]',              \n",
      "                                                                     'fpn_p5[0][0]',              \n",
      "                                                                     'fpn_p6[0][0]']              \n",
      "                                                                                                  \n",
      " rpn_bbox (Concatenate)      (None, None, 4)              0         ['rpn_model[0][2]',           \n",
      "                                                                     'rpn_model[1][2]',           \n",
      "                                                                     'rpn_model[2][2]',           \n",
      "                                                                     'rpn_model[3][2]',           \n",
      "                                                                     'rpn_model[4][2]']           \n",
      "                                                                                                  \n",
      " rpn_class (Concatenate)     (None, None, 2)              0         ['rpn_model[0][1]',           \n",
      "                                                                     'rpn_model[1][1]',           \n",
      "                                                                     'rpn_model[2][1]',           \n",
      "                                                                     'rpn_model[3][1]',           \n",
      "                                                                     'rpn_model[4][1]']           \n",
      "                                                                                                  \n",
      " anchors (ConstLayer)        (4, 65472, 4)                1047552   ['input_image[0][0]']         \n",
      "                                                                                                  \n",
      " input_gt_boxes (InputLayer  [(None, None, 4)]            0         []                            \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " ROI (ProposalLayer)         (4, 2000, 4)                 0         ['rpn_class[0][0]',           \n",
      "                                                                     'rpn_bbox[0][0]',            \n",
      "                                                                     'anchors[0][0]']             \n",
      "                                                                                                  \n",
      " input_gt_class_ids (InputL  [(None, None)]               0         []                            \n",
      " ayer)                                                                                            \n",
      "                                                                                                  \n",
      " lambda (Lambda)             (None, None, 4)              0         ['input_gt_boxes[0][0]',      \n",
      "                                                                     'input_image[0][0]']         \n",
      "                                                                                                  \n",
      " input_gt_masks (InputLayer  [(None, 512, 512, None)]     0         []                            \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " proposal_targets (Detectio  [(4, None, 4),               0         ['ROI[0][0]',                 \n",
      " nTargetLayer)                (4, None),                             'input_gt_class_ids[0][0]',  \n",
      "                              (4, None, 4),                          'lambda[0][0]',              \n",
      "                              (4, None, 28, 28)]                     'input_gt_masks[0][0]']      \n",
      "                                                                                                  \n",
      " input_image_meta (InputLay  [(None, 16)]                 0         []                            \n",
      " er)                                                                                              \n",
      "                                                                                                  \n",
      " roi_align_mask (PyramidROI  (4, None, 14, 14, 256)       0         ['proposal_targets[0][0]',    \n",
      " Align)                                                              'input_image_meta[0][0]',    \n",
      "                                                                     'fpn_p2[0][0]',              \n",
      "                                                                     'fpn_p3[0][0]',              \n",
      "                                                                     'fpn_p4[0][0]',              \n",
      "                                                                     'fpn_p5[0][0]']              \n",
      "                                                                                                  \n",
      " mrcnn_mask_conv1 (TimeDist  (4, None, 14, 14, 256)       590080    ['roi_align_mask[0][0]']      \n",
      " ributed)                                                                                         \n",
      "                                                                                                  \n",
      " mrcnn_mask_bn1 (TimeDistri  (4, None, 14, 14, 256)       1024      ['mrcnn_mask_conv1[0][0]']    \n",
      " buted)                                                                                           \n",
      "                                                                                                  \n",
      " activation_70 (Activation)  (4, None, 14, 14, 256)       0         ['mrcnn_mask_bn1[0][0]']      \n",
      "                                                                                                  \n",
      " mrcnn_mask_conv2 (TimeDist  (4, None, 14, 14, 256)       590080    ['activation_70[0][0]']       \n",
      " ributed)                                                                                         \n",
      "                                                                                                  \n",
      " roi_align_classifier (Pyra  (4, None, 7, 7, 256)         0         ['proposal_targets[0][0]',    \n",
      " midROIAlign)                                                        'input_image_meta[0][0]',    \n",
      "                                                                     'fpn_p2[0][0]',              \n",
      "                                                                     'fpn_p3[0][0]',              \n",
      "                                                                     'fpn_p4[0][0]',              \n",
      "                                                                     'fpn_p5[0][0]']              \n",
      "                                                                                                  \n",
      " mrcnn_mask_bn2 (TimeDistri  (4, None, 14, 14, 256)       1024      ['mrcnn_mask_conv2[0][0]']    \n",
      " buted)                                                                                           \n",
      "                                                                                                  \n",
      " mrcnn_class_conv1 (TimeDis  (4, None, 1, 1, 1024)        1284608   ['roi_align_classifier[0][0]']\n",
      " tributed)                                                0                                       \n",
      "                                                                                                  \n",
      " activation_71 (Activation)  (4, None, 14, 14, 256)       0         ['mrcnn_mask_bn2[0][0]']      \n",
      "                                                                                                  \n",
      " mrcnn_class_bn1 (TimeDistr  (4, None, 1, 1, 1024)        4096      ['mrcnn_class_conv1[0][0]']   \n",
      " ibuted)                                                                                          \n",
      "                                                                                                  \n",
      " mrcnn_mask_conv3 (TimeDist  (4, None, 14, 14, 256)       590080    ['activation_71[0][0]']       \n",
      " ributed)                                                                                         \n",
      "                                                                                                  \n",
      " activation_67 (Activation)  (4, None, 1, 1, 1024)        0         ['mrcnn_class_bn1[0][0]']     \n",
      "                                                                                                  \n",
      " mrcnn_mask_bn3 (TimeDistri  (4, None, 14, 14, 256)       1024      ['mrcnn_mask_conv3[0][0]']    \n",
      " buted)                                                                                           \n",
      "                                                                                                  \n",
      " mrcnn_class_conv2 (TimeDis  (4, None, 1, 1, 1024)        1049600   ['activation_67[0][0]']       \n",
      " tributed)                                                                                        \n",
      "                                                                                                  \n",
      " activation_72 (Activation)  (4, None, 14, 14, 256)       0         ['mrcnn_mask_bn3[0][0]']      \n",
      "                                                                                                  \n",
      " mrcnn_class_bn2 (TimeDistr  (4, None, 1, 1, 1024)        4096      ['mrcnn_class_conv2[0][0]']   \n",
      " ibuted)                                                                                          \n",
      "                                                                                                  \n",
      " mrcnn_mask_conv4 (TimeDist  (4, None, 14, 14, 256)       590080    ['activation_72[0][0]']       \n",
      " ributed)                                                                                         \n",
      "                                                                                                  \n",
      " activation_68 (Activation)  (4, None, 1, 1, 1024)        0         ['mrcnn_class_bn2[0][0]']     \n",
      "                                                                                                  \n",
      " mrcnn_mask_bn4 (TimeDistri  (4, None, 14, 14, 256)       1024      ['mrcnn_mask_conv4[0][0]']    \n",
      " buted)                                                                                           \n",
      "                                                                                                  \n",
      " pool_squeeze (Lambda)       (4, None, 1024)              0         ['activation_68[0][0]']       \n",
      "                                                                                                  \n",
      " activation_73 (Activation)  (4, None, 14, 14, 256)       0         ['mrcnn_mask_bn4[0][0]']      \n",
      "                                                                                                  \n",
      " mrcnn_bbox_fc (TimeDistrib  (4, None, 16)                16400     ['pool_squeeze[0][0]']        \n",
      " uted)                                                                                            \n",
      "                                                                                                  \n",
      " mrcnn_mask_deconv (TimeDis  (4, None, 28, 28, 256)       262400    ['activation_73[0][0]']       \n",
      " tributed)                                                                                        \n",
      "                                                                                                  \n",
      " input_rpn_match (InputLaye  [(None, None, 1)]            0         []                            \n",
      " r)                                                                                               \n",
      "                                                                                                  \n",
      " input_rpn_bbox (InputLayer  [(None, None, 4)]            0         []                            \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " rpn_class_logits (Concaten  (None, None, 2)              0         ['rpn_model[0][0]',           \n",
      " ate)                                                                'rpn_model[1][0]',           \n",
      "                                                                     'rpn_model[2][0]',           \n",
      "                                                                     'rpn_model[3][0]',           \n",
      "                                                                     'rpn_model[4][0]']           \n",
      "                                                                                                  \n",
      " mrcnn_class_logits (TimeDi  (4, None, 4)                 4100      ['pool_squeeze[0][0]']        \n",
      " stributed)                                                                                       \n",
      "                                                                                                  \n",
      " mrcnn_bbox (Reshape)        (4, None, 4, 4)              0         ['mrcnn_bbox_fc[0][0]']       \n",
      "                                                                                                  \n",
      " mrcnn_mask (TimeDistribute  (4, None, 28, 28, 4)         1028      ['mrcnn_mask_deconv[0][0]']   \n",
      " d)                                                                                               \n",
      "                                                                                                  \n",
      " lambda_3 (Lambda)           (None, 4)                    0         ['input_image_meta[0][0]']    \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 64791722 (247.16 MB)\n",
      "Trainable params: 63632682 (242.74 MB)\n",
      "Non-trainable params: 1159040 (4.42 MB)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.compile(layers=\"all\")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting at epoch 1.\n",
      "\n",
      "Checkpoint Path: /mnt/c/Users/ChangGeng/Desktop/FAU/Semester 07/Bachelorarbeit/VisionTransformers/shoes/logs/55_shapes_resnet20241208T1756/mask_rcnn_55_shapes_resnet_{epoch:04d}.h5\n",
      "n workers used: 32\n",
      "Epoch 2/500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1733677085.042785   52374 op_level_cost_estimator.cc:699] Error in PredictCost() for the op: op: \"CropAndResize\" attr { key: \"T\" value { type: DT_FLOAT } } attr { key: \"extrapolation_value\" value { f: 0 } } attr { key: \"method\" value { s: \"bilinear\" } } inputs { dtype: DT_FLOAT shape { dim { size: -1086 } dim { size: -613 } dim { size: -614 } dim { size: 1 } } } inputs { dtype: DT_FLOAT shape { dim { size: -38 } dim { size: 4 } } } inputs { dtype: DT_INT32 shape { dim { size: -38 } } } inputs { dtype: DT_INT32 shape { dim { size: 2 } } value { dtype: DT_INT32 tensor_shape { dim { size: 2 } } int_val: 28 } } device { type: \"GPU\" vendor: \"NVIDIA\" model: \"NVIDIA GeForce RTX 4090\" frequency: 2520 num_cores: 128 environment { key: \"architecture\" value: \"8.9\" } environment { key: \"cuda\" value: \"12000\" } environment { key: \"cudnn\" value: \"8800\" } num_registers: 65536 l1_cache_size: 24576 l2_cache_size: 75497472 shared_memory_size_per_multiprocessor: 102400 memory_size: 10180624384 bandwidth: 1008096000 } outputs { dtype: DT_FLOAT shape { dim { size: -38 } dim { size: 28 } dim { size: 28 } dim { size: 1 } } }\n",
      "W0000 00:00:1733677085.042989   52374 op_level_cost_estimator.cc:699] Error in PredictCost() for the op: op: \"CropAndResize\" attr { key: \"T\" value { type: DT_FLOAT } } attr { key: \"extrapolation_value\" value { f: 0 } } attr { key: \"method\" value { s: \"bilinear\" } } inputs { dtype: DT_FLOAT shape { dim { size: -1202 } dim { size: -622 } dim { size: -623 } dim { size: 1 } } } inputs { dtype: DT_FLOAT shape { dim { size: -56 } dim { size: 4 } } } inputs { dtype: DT_INT32 shape { dim { size: -56 } } } inputs { dtype: DT_INT32 shape { dim { size: 2 } } value { dtype: DT_INT32 tensor_shape { dim { size: 2 } } int_val: 28 } } device { type: \"GPU\" vendor: \"NVIDIA\" model: \"NVIDIA GeForce RTX 4090\" frequency: 2520 num_cores: 128 environment { key: \"architecture\" value: \"8.9\" } environment { key: \"cuda\" value: \"12000\" } environment { key: \"cudnn\" value: \"8800\" } num_registers: 65536 l1_cache_size: 24576 l2_cache_size: 75497472 shared_memory_size_per_multiprocessor: 102400 memory_size: 10180624384 bandwidth: 1008096000 } outputs { dtype: DT_FLOAT shape { dim { size: -56 } dim { size: 28 } dim { size: 28 } dim { size: 1 } } }\n",
      "W0000 00:00:1733677085.043081   52374 op_level_cost_estimator.cc:699] Error in PredictCost() for the op: op: \"CropAndResize\" attr { key: \"T\" value { type: DT_FLOAT } } attr { key: \"extrapolation_value\" value { f: 0 } } attr { key: \"method\" value { s: \"bilinear\" } } inputs { dtype: DT_FLOAT shape { dim { size: -1116 } dim { size: -616 } dim { size: -617 } dim { size: 1 } } } inputs { dtype: DT_FLOAT shape { dim { size: -44 } dim { size: 4 } } } inputs { dtype: DT_INT32 shape { dim { size: -44 } } } inputs { dtype: DT_INT32 shape { dim { size: 2 } } value { dtype: DT_INT32 tensor_shape { dim { size: 2 } } int_val: 28 } } device { type: \"GPU\" vendor: \"NVIDIA\" model: \"NVIDIA GeForce RTX 4090\" frequency: 2520 num_cores: 128 environment { key: \"architecture\" value: \"8.9\" } environment { key: \"cuda\" value: \"12000\" } environment { key: \"cudnn\" value: \"8800\" } num_registers: 65536 l1_cache_size: 24576 l2_cache_size: 75497472 shared_memory_size_per_multiprocessor: 102400 memory_size: 10180624384 bandwidth: 1008096000 } outputs { dtype: DT_FLOAT shape { dim { size: -44 } dim { size: 28 } dim { size: 28 } dim { size: 1 } } }\n",
      "W0000 00:00:1733677085.043167   52374 op_level_cost_estimator.cc:699] Error in PredictCost() for the op: op: \"CropAndResize\" attr { key: \"T\" value { type: DT_FLOAT } } attr { key: \"extrapolation_value\" value { f: 0 } } attr { key: \"method\" value { s: \"bilinear\" } } inputs { dtype: DT_FLOAT shape { dim { size: -1163 } dim { size: -619 } dim { size: -620 } dim { size: 1 } } } inputs { dtype: DT_FLOAT shape { dim { size: -50 } dim { size: 4 } } } inputs { dtype: DT_INT32 shape { dim { size: -50 } } } inputs { dtype: DT_INT32 shape { dim { size: 2 } } value { dtype: DT_INT32 tensor_shape { dim { size: 2 } } int_val: 28 } } device { type: \"GPU\" vendor: \"NVIDIA\" model: \"NVIDIA GeForce RTX 4090\" frequency: 2520 num_cores: 128 environment { key: \"architecture\" value: \"8.9\" } environment { key: \"cuda\" value: \"12000\" } environment { key: \"cudnn\" value: \"8800\" } num_registers: 65536 l1_cache_size: 24576 l2_cache_size: 75497472 shared_memory_size_per_multiprocessor: 102400 memory_size: 10180624384 bandwidth: 1008096000 } outputs { dtype: DT_FLOAT shape { dim { size: -50 } dim { size: 28 } dim { size: 28 } dim { size: 1 } } }\n",
      "W0000 00:00:1733677085.044917   52374 op_level_cost_estimator.cc:699] Error in PredictCost() for the op: op: \"CropAndResize\" attr { key: \"T\" value { type: DT_FLOAT } } attr { key: \"extrapolation_value\" value { f: 0 } } attr { key: \"method\" value { s: \"bilinear\" } } inputs { dtype: DT_FLOAT shape { dim { size: -18 } dim { size: -231 } dim { size: -232 } dim { size: 256 } } } inputs { dtype: DT_FLOAT shape { dim { size: -95 } dim { size: 4 } } } inputs { dtype: DT_INT32 shape { dim { size: -95 } } } inputs { dtype: DT_INT32 shape { dim { size: 2 } } value { dtype: DT_INT32 tensor_shape { dim { size: 2 } } int_val: 7 } } device { type: \"GPU\" vendor: \"NVIDIA\" model: \"NVIDIA GeForce RTX 4090\" frequency: 2520 num_cores: 128 environment { key: \"architecture\" value: \"8.9\" } environment { key: \"cuda\" value: \"12000\" } environment { key: \"cudnn\" value: \"8800\" } num_registers: 65536 l1_cache_size: 24576 l2_cache_size: 75497472 shared_memory_size_per_multiprocessor: 102400 memory_size: 10180624384 bandwidth: 1008096000 } outputs { dtype: DT_FLOAT shape { dim { size: -95 } dim { size: 7 } dim { size: 7 } dim { size: 256 } } }\n",
      "W0000 00:00:1733677085.044984   52374 op_level_cost_estimator.cc:699] Error in PredictCost() for the op: op: \"CropAndResize\" attr { key: \"T\" value { type: DT_FLOAT } } attr { key: \"extrapolation_value\" value { f: 0 } } attr { key: \"method\" value { s: \"bilinear\" } } inputs { dtype: DT_FLOAT shape { dim { size: -18 } dim { size: -231 } dim { size: -232 } dim { size: 256 } } } inputs { dtype: DT_FLOAT shape { dim { size: -95 } dim { size: 4 } } } inputs { dtype: DT_INT32 shape { dim { size: -95 } } } inputs { dtype: DT_INT32 shape { dim { size: 2 } } value { dtype: DT_INT32 tensor_shape { dim { size: 2 } } int_val: 14 } } device { type: \"GPU\" vendor: \"NVIDIA\" model: \"NVIDIA GeForce RTX 4090\" frequency: 2520 num_cores: 128 environment { key: \"architecture\" value: \"8.9\" } environment { key: \"cuda\" value: \"12000\" } environment { key: \"cudnn\" value: \"8800\" } num_registers: 65536 l1_cache_size: 24576 l2_cache_size: 75497472 shared_memory_size_per_multiprocessor: 102400 memory_size: 10180624384 bandwidth: 1008096000 } outputs { dtype: DT_FLOAT shape { dim { size: -95 } dim { size: 14 } dim { size: 14 } dim { size: 256 } } }\n",
      "W0000 00:00:1733677085.045013   52374 op_level_cost_estimator.cc:699] Error in PredictCost() for the op: op: \"CropAndResize\" attr { key: \"T\" value { type: DT_FLOAT } } attr { key: \"extrapolation_value\" value { f: 0 } } attr { key: \"method\" value { s: \"bilinear\" } } inputs { dtype: DT_FLOAT shape { dim { size: -18 } dim { size: -239 } dim { size: -240 } dim { size: 256 } } } inputs { dtype: DT_FLOAT shape { dim { size: -97 } dim { size: 4 } } } inputs { dtype: DT_INT32 shape { dim { size: -97 } } } inputs { dtype: DT_INT32 shape { dim { size: 2 } } value { dtype: DT_INT32 tensor_shape { dim { size: 2 } } int_val: 7 } } device { type: \"GPU\" vendor: \"NVIDIA\" model: \"NVIDIA GeForce RTX 4090\" frequency: 2520 num_cores: 128 environment { key: \"architecture\" value: \"8.9\" } environment { key: \"cuda\" value: \"12000\" } environment { key: \"cudnn\" value: \"8800\" } num_registers: 65536 l1_cache_size: 24576 l2_cache_size: 75497472 shared_memory_size_per_multiprocessor: 102400 memory_size: 10180624384 bandwidth: 1008096000 } outputs { dtype: DT_FLOAT shape { dim { size: -97 } dim { size: 7 } dim { size: 7 } dim { size: 256 } } }\n",
      "W0000 00:00:1733677085.045035   52374 op_level_cost_estimator.cc:699] Error in PredictCost() for the op: op: \"CropAndResize\" attr { key: \"T\" value { type: DT_FLOAT } } attr { key: \"extrapolation_value\" value { f: 0 } } attr { key: \"method\" value { s: \"bilinear\" } } inputs { dtype: DT_FLOAT shape { dim { size: -18 } dim { size: -239 } dim { size: -240 } dim { size: 256 } } } inputs { dtype: DT_FLOAT shape { dim { size: -97 } dim { size: 4 } } } inputs { dtype: DT_INT32 shape { dim { size: -97 } } } inputs { dtype: DT_INT32 shape { dim { size: 2 } } value { dtype: DT_INT32 tensor_shape { dim { size: 2 } } int_val: 14 } } device { type: \"GPU\" vendor: \"NVIDIA\" model: \"NVIDIA GeForce RTX 4090\" frequency: 2520 num_cores: 128 environment { key: \"architecture\" value: \"8.9\" } environment { key: \"cuda\" value: \"12000\" } environment { key: \"cudnn\" value: \"8800\" } num_registers: 65536 l1_cache_size: 24576 l2_cache_size: 75497472 shared_memory_size_per_multiprocessor: 102400 memory_size: 10180624384 bandwidth: 1008096000 } outputs { dtype: DT_FLOAT shape { dim { size: -97 } dim { size: 14 } dim { size: 14 } dim { size: 256 } } }\n",
      "W0000 00:00:1733677085.045070   52374 op_level_cost_estimator.cc:699] Error in PredictCost() for the op: op: \"CropAndResize\" attr { key: \"T\" value { type: DT_FLOAT } } attr { key: \"extrapolation_value\" value { f: 0 } } attr { key: \"method\" value { s: \"bilinear\" } } inputs { dtype: DT_FLOAT shape { dim { size: -18 } dim { size: -247 } dim { size: -248 } dim { size: 256 } } } inputs { dtype: DT_FLOAT shape { dim { size: -99 } dim { size: 4 } } } inputs { dtype: DT_INT32 shape { dim { size: -99 } } } inputs { dtype: DT_INT32 shape { dim { size: 2 } } value { dtype: DT_INT32 tensor_shape { dim { size: 2 } } int_val: 7 } } device { type: \"GPU\" vendor: \"NVIDIA\" model: \"NVIDIA GeForce RTX 4090\" frequency: 2520 num_cores: 128 environment { key: \"architecture\" value: \"8.9\" } environment { key: \"cuda\" value: \"12000\" } environment { key: \"cudnn\" value: \"8800\" } num_registers: 65536 l1_cache_size: 24576 l2_cache_size: 75497472 shared_memory_size_per_multiprocessor: 102400 memory_size: 10180624384 bandwidth: 1008096000 } outputs { dtype: DT_FLOAT shape { dim { size: -99 } dim { size: 7 } dim { size: 7 } dim { size: 256 } } }\n",
      "W0000 00:00:1733677085.045095   52374 op_level_cost_estimator.cc:699] Error in PredictCost() for the op: op: \"CropAndResize\" attr { key: \"T\" value { type: DT_FLOAT } } attr { key: \"extrapolation_value\" value { f: 0 } } attr { key: \"method\" value { s: \"bilinear\" } } inputs { dtype: DT_FLOAT shape { dim { size: -18 } dim { size: -247 } dim { size: -248 } dim { size: 256 } } } inputs { dtype: DT_FLOAT shape { dim { size: -99 } dim { size: 4 } } } inputs { dtype: DT_INT32 shape { dim { size: -99 } } } inputs { dtype: DT_INT32 shape { dim { size: 2 } } value { dtype: DT_INT32 tensor_shape { dim { size: 2 } } int_val: 14 } } device { type: \"GPU\" vendor: \"NVIDIA\" model: \"NVIDIA GeForce RTX 4090\" frequency: 2520 num_cores: 128 environment { key: \"architecture\" value: \"8.9\" } environment { key: \"cuda\" value: \"12000\" } environment { key: \"cudnn\" value: \"8800\" } num_registers: 65536 l1_cache_size: 24576 l2_cache_size: 75497472 shared_memory_size_per_multiprocessor: 102400 memory_size: 10180624384 bandwidth: 1008096000 } outputs { dtype: DT_FLOAT shape { dim { size: -99 } dim { size: 14 } dim { size: 14 } dim { size: 256 } } }\n",
      "W0000 00:00:1733677085.045137   52374 op_level_cost_estimator.cc:699] Error in PredictCost() for the op: op: \"CropAndResize\" attr { key: \"T\" value { type: DT_FLOAT } } attr { key: \"extrapolation_value\" value { f: 0 } } attr { key: \"method\" value { s: \"bilinear\" } } inputs { dtype: DT_FLOAT shape { dim { size: -18 } dim { size: -223 } dim { size: -224 } dim { size: 256 } } } inputs { dtype: DT_FLOAT shape { dim { size: -101 } dim { size: 4 } } } inputs { dtype: DT_INT32 shape { dim { size: -101 } } } inputs { dtype: DT_INT32 shape { dim { size: 2 } } value { dtype: DT_INT32 tensor_shape { dim { size: 2 } } int_val: 7 } } device { type: \"GPU\" vendor: \"NVIDIA\" model: \"NVIDIA GeForce RTX 4090\" frequency: 2520 num_cores: 128 environment { key: \"architecture\" value: \"8.9\" } environment { key: \"cuda\" value: \"12000\" } environment { key: \"cudnn\" value: \"8800\" } num_registers: 65536 l1_cache_size: 24576 l2_cache_size: 75497472 shared_memory_size_per_multiprocessor: 102400 memory_size: 10180624384 bandwidth: 1008096000 } outputs { dtype: DT_FLOAT shape { dim { size: -101 } dim { size: 7 } dim { size: 7 } dim { size: 256 } } }\n",
      "W0000 00:00:1733677085.045164   52374 op_level_cost_estimator.cc:699] Error in PredictCost() for the op: op: \"CropAndResize\" attr { key: \"T\" value { type: DT_FLOAT } } attr { key: \"extrapolation_value\" value { f: 0 } } attr { key: \"method\" value { s: \"bilinear\" } } inputs { dtype: DT_FLOAT shape { dim { size: -18 } dim { size: -223 } dim { size: -224 } dim { size: 256 } } } inputs { dtype: DT_FLOAT shape { dim { size: -101 } dim { size: 4 } } } inputs { dtype: DT_INT32 shape { dim { size: -101 } } } inputs { dtype: DT_INT32 shape { dim { size: 2 } } value { dtype: DT_INT32 tensor_shape { dim { size: 2 } } int_val: 14 } } device { type: \"GPU\" vendor: \"NVIDIA\" model: \"NVIDIA GeForce RTX 4090\" frequency: 2520 num_cores: 128 environment { key: \"architecture\" value: \"8.9\" } environment { key: \"cuda\" value: \"12000\" } environment { key: \"cudnn\" value: \"8800\" } num_registers: 65536 l1_cache_size: 24576 l2_cache_size: 75497472 shared_memory_size_per_multiprocessor: 102400 memory_size: 10180624384 bandwidth: 1008096000 } outputs { dtype: DT_FLOAT shape { dim { size: -101 } dim { size: 14 } dim { size: 14 } dim { size: 256 } } }\n",
      "I0000 00:00:1733677089.020773   52503 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250/250 [==============================] - ETA: 0s - loss: 2.9384 - rpn_class_loss: 0.0901 - rpn_bbox_loss: 1.1780 - mrcnn_class_loss: 0.4374 - mrcnn_bbox_loss: 1.3556 - mrcnn_mask_loss: 0.6643"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1733677157.471928   52374 op_level_cost_estimator.cc:699] Error in PredictCost() for the op: op: \"CropAndResize\" attr { key: \"T\" value { type: DT_FLOAT } } attr { key: \"extrapolation_value\" value { f: 0 } } attr { key: \"method\" value { s: \"bilinear\" } } inputs { dtype: DT_FLOAT shape { dim { size: -638 } dim { size: -121 } dim { size: -122 } dim { size: 1 } } } inputs { dtype: DT_FLOAT shape { dim { size: -24 } dim { size: 4 } } } inputs { dtype: DT_INT32 shape { dim { size: -24 } } } inputs { dtype: DT_INT32 shape { dim { size: 2 } } value { dtype: DT_INT32 tensor_shape { dim { size: 2 } } int_val: 28 } } device { type: \"GPU\" vendor: \"NVIDIA\" model: \"NVIDIA GeForce RTX 4090\" frequency: 2520 num_cores: 128 environment { key: \"architecture\" value: \"8.9\" } environment { key: \"cuda\" value: \"12000\" } environment { key: \"cudnn\" value: \"8800\" } num_registers: 65536 l1_cache_size: 24576 l2_cache_size: 75497472 shared_memory_size_per_multiprocessor: 102400 memory_size: 10180624384 bandwidth: 1008096000 } outputs { dtype: DT_FLOAT shape { dim { size: -24 } dim { size: 28 } dim { size: 28 } dim { size: 1 } } }\n",
      "W0000 00:00:1733677157.472073   52374 op_level_cost_estimator.cc:699] Error in PredictCost() for the op: op: \"CropAndResize\" attr { key: \"T\" value { type: DT_FLOAT } } attr { key: \"extrapolation_value\" value { f: 0 } } attr { key: \"method\" value { s: \"bilinear\" } } inputs { dtype: DT_FLOAT shape { dim { size: -696 } dim { size: -130 } dim { size: -131 } dim { size: 1 } } } inputs { dtype: DT_FLOAT shape { dim { size: -42 } dim { size: 4 } } } inputs { dtype: DT_INT32 shape { dim { size: -42 } } } inputs { dtype: DT_INT32 shape { dim { size: 2 } } value { dtype: DT_INT32 tensor_shape { dim { size: 2 } } int_val: 28 } } device { type: \"GPU\" vendor: \"NVIDIA\" model: \"NVIDIA GeForce RTX 4090\" frequency: 2520 num_cores: 128 environment { key: \"architecture\" value: \"8.9\" } environment { key: \"cuda\" value: \"12000\" } environment { key: \"cudnn\" value: \"8800\" } num_registers: 65536 l1_cache_size: 24576 l2_cache_size: 75497472 shared_memory_size_per_multiprocessor: 102400 memory_size: 10180624384 bandwidth: 1008096000 } outputs { dtype: DT_FLOAT shape { dim { size: -42 } dim { size: 28 } dim { size: 28 } dim { size: 1 } } }\n",
      "W0000 00:00:1733677157.472127   52374 op_level_cost_estimator.cc:699] Error in PredictCost() for the op: op: \"CropAndResize\" attr { key: \"T\" value { type: DT_FLOAT } } attr { key: \"extrapolation_value\" value { f: 0 } } attr { key: \"method\" value { s: \"bilinear\" } } inputs { dtype: DT_FLOAT shape { dim { size: -660 } dim { size: -124 } dim { size: -125 } dim { size: 1 } } } inputs { dtype: DT_FLOAT shape { dim { size: -30 } dim { size: 4 } } } inputs { dtype: DT_INT32 shape { dim { size: -30 } } } inputs { dtype: DT_INT32 shape { dim { size: 2 } } value { dtype: DT_INT32 tensor_shape { dim { size: 2 } } int_val: 28 } } device { type: \"GPU\" vendor: \"NVIDIA\" model: \"NVIDIA GeForce RTX 4090\" frequency: 2520 num_cores: 128 environment { key: \"architecture\" value: \"8.9\" } environment { key: \"cuda\" value: \"12000\" } environment { key: \"cudnn\" value: \"8800\" } num_registers: 65536 l1_cache_size: 24576 l2_cache_size: 75497472 shared_memory_size_per_multiprocessor: 102400 memory_size: 10180624384 bandwidth: 1008096000 } outputs { dtype: DT_FLOAT shape { dim { size: -30 } dim { size: 28 } dim { size: 28 } dim { size: 1 } } }\n",
      "W0000 00:00:1733677157.472174   52374 op_level_cost_estimator.cc:699] Error in PredictCost() for the op: op: \"CropAndResize\" attr { key: \"T\" value { type: DT_FLOAT } } attr { key: \"extrapolation_value\" value { f: 0 } } attr { key: \"method\" value { s: \"bilinear\" } } inputs { dtype: DT_FLOAT shape { dim { size: -681 } dim { size: -127 } dim { size: -128 } dim { size: 1 } } } inputs { dtype: DT_FLOAT shape { dim { size: -36 } dim { size: 4 } } } inputs { dtype: DT_INT32 shape { dim { size: -36 } } } inputs { dtype: DT_INT32 shape { dim { size: 2 } } value { dtype: DT_INT32 tensor_shape { dim { size: 2 } } int_val: 28 } } device { type: \"GPU\" vendor: \"NVIDIA\" model: \"NVIDIA GeForce RTX 4090\" frequency: 2520 num_cores: 128 environment { key: \"architecture\" value: \"8.9\" } environment { key: \"cuda\" value: \"12000\" } environment { key: \"cudnn\" value: \"8800\" } num_registers: 65536 l1_cache_size: 24576 l2_cache_size: 75497472 shared_memory_size_per_multiprocessor: 102400 memory_size: 10180624384 bandwidth: 1008096000 } outputs { dtype: DT_FLOAT shape { dim { size: -36 } dim { size: 28 } dim { size: 28 } dim { size: 1 } } }\n",
      "W0000 00:00:1733677157.473520   52374 op_level_cost_estimator.cc:699] Error in PredictCost() for the op: op: \"CropAndResize\" attr { key: \"T\" value { type: DT_FLOAT } } attr { key: \"extrapolation_value\" value { f: 0 } } attr { key: \"method\" value { s: \"bilinear\" } } inputs { dtype: DT_FLOAT shape { dim { size: -96 } dim { size: -440 } dim { size: -441 } dim { size: 256 } } } inputs { dtype: DT_FLOAT shape { dim { size: -81 } dim { size: 4 } } } inputs { dtype: DT_INT32 shape { dim { size: -81 } } } inputs { dtype: DT_INT32 shape { dim { size: 2 } } value { dtype: DT_INT32 tensor_shape { dim { size: 2 } } int_val: 7 } } device { type: \"GPU\" vendor: \"NVIDIA\" model: \"NVIDIA GeForce RTX 4090\" frequency: 2520 num_cores: 128 environment { key: \"architecture\" value: \"8.9\" } environment { key: \"cuda\" value: \"12000\" } environment { key: \"cudnn\" value: \"8800\" } num_registers: 65536 l1_cache_size: 24576 l2_cache_size: 75497472 shared_memory_size_per_multiprocessor: 102400 memory_size: 10180624384 bandwidth: 1008096000 } outputs { dtype: DT_FLOAT shape { dim { size: -81 } dim { size: 7 } dim { size: 7 } dim { size: 256 } } }\n",
      "W0000 00:00:1733677157.473564   52374 op_level_cost_estimator.cc:699] Error in PredictCost() for the op: op: \"CropAndResize\" attr { key: \"T\" value { type: DT_FLOAT } } attr { key: \"extrapolation_value\" value { f: 0 } } attr { key: \"method\" value { s: \"bilinear\" } } inputs { dtype: DT_FLOAT shape { dim { size: -96 } dim { size: -440 } dim { size: -441 } dim { size: 256 } } } inputs { dtype: DT_FLOAT shape { dim { size: -81 } dim { size: 4 } } } inputs { dtype: DT_INT32 shape { dim { size: -81 } } } inputs { dtype: DT_INT32 shape { dim { size: 2 } } value { dtype: DT_INT32 tensor_shape { dim { size: 2 } } int_val: 14 } } device { type: \"GPU\" vendor: \"NVIDIA\" model: \"NVIDIA GeForce RTX 4090\" frequency: 2520 num_cores: 128 environment { key: \"architecture\" value: \"8.9\" } environment { key: \"cuda\" value: \"12000\" } environment { key: \"cudnn\" value: \"8800\" } num_registers: 65536 l1_cache_size: 24576 l2_cache_size: 75497472 shared_memory_size_per_multiprocessor: 102400 memory_size: 10180624384 bandwidth: 1008096000 } outputs { dtype: DT_FLOAT shape { dim { size: -81 } dim { size: 14 } dim { size: 14 } dim { size: 256 } } }\n",
      "W0000 00:00:1733677157.473589   52374 op_level_cost_estimator.cc:699] Error in PredictCost() for the op: op: \"CropAndResize\" attr { key: \"T\" value { type: DT_FLOAT } } attr { key: \"extrapolation_value\" value { f: 0 } } attr { key: \"method\" value { s: \"bilinear\" } } inputs { dtype: DT_FLOAT shape { dim { size: -96 } dim { size: -430 } dim { size: -431 } dim { size: 256 } } } inputs { dtype: DT_FLOAT shape { dim { size: -83 } dim { size: 4 } } } inputs { dtype: DT_INT32 shape { dim { size: -83 } } } inputs { dtype: DT_INT32 shape { dim { size: 2 } } value { dtype: DT_INT32 tensor_shape { dim { size: 2 } } int_val: 7 } } device { type: \"GPU\" vendor: \"NVIDIA\" model: \"NVIDIA GeForce RTX 4090\" frequency: 2520 num_cores: 128 environment { key: \"architecture\" value: \"8.9\" } environment { key: \"cuda\" value: \"12000\" } environment { key: \"cudnn\" value: \"8800\" } num_registers: 65536 l1_cache_size: 24576 l2_cache_size: 75497472 shared_memory_size_per_multiprocessor: 102400 memory_size: 10180624384 bandwidth: 1008096000 } outputs { dtype: DT_FLOAT shape { dim { size: -83 } dim { size: 7 } dim { size: 7 } dim { size: 256 } } }\n",
      "W0000 00:00:1733677157.473608   52374 op_level_cost_estimator.cc:699] Error in PredictCost() for the op: op: \"CropAndResize\" attr { key: \"T\" value { type: DT_FLOAT } } attr { key: \"extrapolation_value\" value { f: 0 } } attr { key: \"method\" value { s: \"bilinear\" } } inputs { dtype: DT_FLOAT shape { dim { size: -96 } dim { size: -430 } dim { size: -431 } dim { size: 256 } } } inputs { dtype: DT_FLOAT shape { dim { size: -83 } dim { size: 4 } } } inputs { dtype: DT_INT32 shape { dim { size: -83 } } } inputs { dtype: DT_INT32 shape { dim { size: 2 } } value { dtype: DT_INT32 tensor_shape { dim { size: 2 } } int_val: 14 } } device { type: \"GPU\" vendor: \"NVIDIA\" model: \"NVIDIA GeForce RTX 4090\" frequency: 2520 num_cores: 128 environment { key: \"architecture\" value: \"8.9\" } environment { key: \"cuda\" value: \"12000\" } environment { key: \"cudnn\" value: \"8800\" } num_registers: 65536 l1_cache_size: 24576 l2_cache_size: 75497472 shared_memory_size_per_multiprocessor: 102400 memory_size: 10180624384 bandwidth: 1008096000 } outputs { dtype: DT_FLOAT shape { dim { size: -83 } dim { size: 14 } dim { size: 14 } dim { size: 256 } } }\n",
      "W0000 00:00:1733677157.473628   52374 op_level_cost_estimator.cc:699] Error in PredictCost() for the op: op: \"CropAndResize\" attr { key: \"T\" value { type: DT_FLOAT } } attr { key: \"extrapolation_value\" value { f: 0 } } attr { key: \"method\" value { s: \"bilinear\" } } inputs { dtype: DT_FLOAT shape { dim { size: -96 } dim { size: -418 } dim { size: -419 } dim { size: 256 } } } inputs { dtype: DT_FLOAT shape { dim { size: -85 } dim { size: 4 } } } inputs { dtype: DT_INT32 shape { dim { size: -85 } } } inputs { dtype: DT_INT32 shape { dim { size: 2 } } value { dtype: DT_INT32 tensor_shape { dim { size: 2 } } int_val: 7 } } device { type: \"GPU\" vendor: \"NVIDIA\" model: \"NVIDIA GeForce RTX 4090\" frequency: 2520 num_cores: 128 environment { key: \"architecture\" value: \"8.9\" } environment { key: \"cuda\" value: \"12000\" } environment { key: \"cudnn\" value: \"8800\" } num_registers: 65536 l1_cache_size: 24576 l2_cache_size: 75497472 shared_memory_size_per_multiprocessor: 102400 memory_size: 10180624384 bandwidth: 1008096000 } outputs { dtype: DT_FLOAT shape { dim { size: -85 } dim { size: 7 } dim { size: 7 } dim { size: 256 } } }\n",
      "W0000 00:00:1733677157.473657   52374 op_level_cost_estimator.cc:699] Error in PredictCost() for the op: op: \"CropAndResize\" attr { key: \"T\" value { type: DT_FLOAT } } attr { key: \"extrapolation_value\" value { f: 0 } } attr { key: \"method\" value { s: \"bilinear\" } } inputs { dtype: DT_FLOAT shape { dim { size: -96 } dim { size: -418 } dim { size: -419 } dim { size: 256 } } } inputs { dtype: DT_FLOAT shape { dim { size: -85 } dim { size: 4 } } } inputs { dtype: DT_INT32 shape { dim { size: -85 } } } inputs { dtype: DT_INT32 shape { dim { size: 2 } } value { dtype: DT_INT32 tensor_shape { dim { size: 2 } } int_val: 14 } } device { type: \"GPU\" vendor: \"NVIDIA\" model: \"NVIDIA GeForce RTX 4090\" frequency: 2520 num_cores: 128 environment { key: \"architecture\" value: \"8.9\" } environment { key: \"cuda\" value: \"12000\" } environment { key: \"cudnn\" value: \"8800\" } num_registers: 65536 l1_cache_size: 24576 l2_cache_size: 75497472 shared_memory_size_per_multiprocessor: 102400 memory_size: 10180624384 bandwidth: 1008096000 } outputs { dtype: DT_FLOAT shape { dim { size: -85 } dim { size: 14 } dim { size: 14 } dim { size: 256 } } }\n",
      "W0000 00:00:1733677157.473689   52374 op_level_cost_estimator.cc:699] Error in PredictCost() for the op: op: \"CropAndResize\" attr { key: \"T\" value { type: DT_FLOAT } } attr { key: \"extrapolation_value\" value { f: 0 } } attr { key: \"method\" value { s: \"bilinear\" } } inputs { dtype: DT_FLOAT shape { dim { size: -96 } dim { size: -404 } dim { size: -405 } dim { size: 256 } } } inputs { dtype: DT_FLOAT shape { dim { size: -87 } dim { size: 4 } } } inputs { dtype: DT_INT32 shape { dim { size: -87 } } } inputs { dtype: DT_INT32 shape { dim { size: 2 } } value { dtype: DT_INT32 tensor_shape { dim { size: 2 } } int_val: 7 } } device { type: \"GPU\" vendor: \"NVIDIA\" model: \"NVIDIA GeForce RTX 4090\" frequency: 2520 num_cores: 128 environment { key: \"architecture\" value: \"8.9\" } environment { key: \"cuda\" value: \"12000\" } environment { key: \"cudnn\" value: \"8800\" } num_registers: 65536 l1_cache_size: 24576 l2_cache_size: 75497472 shared_memory_size_per_multiprocessor: 102400 memory_size: 10180624384 bandwidth: 1008096000 } outputs { dtype: DT_FLOAT shape { dim { size: -87 } dim { size: 7 } dim { size: 7 } dim { size: 256 } } }\n",
      "W0000 00:00:1733677157.473719   52374 op_level_cost_estimator.cc:699] Error in PredictCost() for the op: op: \"CropAndResize\" attr { key: \"T\" value { type: DT_FLOAT } } attr { key: \"extrapolation_value\" value { f: 0 } } attr { key: \"method\" value { s: \"bilinear\" } } inputs { dtype: DT_FLOAT shape { dim { size: -96 } dim { size: -404 } dim { size: -405 } dim { size: 256 } } } inputs { dtype: DT_FLOAT shape { dim { size: -87 } dim { size: 4 } } } inputs { dtype: DT_INT32 shape { dim { size: -87 } } } inputs { dtype: DT_INT32 shape { dim { size: 2 } } value { dtype: DT_INT32 tensor_shape { dim { size: 2 } } int_val: 14 } } device { type: \"GPU\" vendor: \"NVIDIA\" model: \"NVIDIA GeForce RTX 4090\" frequency: 2520 num_cores: 128 environment { key: \"architecture\" value: \"8.9\" } environment { key: \"cuda\" value: \"12000\" } environment { key: \"cudnn\" value: \"8800\" } num_registers: 65536 l1_cache_size: 24576 l2_cache_size: 75497472 shared_memory_size_per_multiprocessor: 102400 memory_size: 10180624384 bandwidth: 1008096000 } outputs { dtype: DT_FLOAT shape { dim { size: -87 } dim { size: 14 } dim { size: 14 } dim { size: 256 } } }\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250/250 [==============================] - 101s 251ms/step - loss: 2.9384 - rpn_class_loss: 0.0901 - rpn_bbox_loss: 1.1780 - mrcnn_class_loss: 0.4367 - mrcnn_bbox_loss: 1.3534 - mrcnn_mask_loss: 0.6641 - val_loss: 2.3205 - val_rpn_class_loss: 0.0212 - val_rpn_bbox_loss: 0.9308 - val_mrcnn_class_loss: 0.1985 - val_mrcnn_bbox_loss: 0.5956 - val_mrcnn_mask_loss: 0.5744 - lr: 0.0010\n",
      "Epoch 3/500\n",
      "250/250 [==============================] - 60s 240ms/step - loss: 2.4144 - rpn_class_loss: 0.0218 - rpn_bbox_loss: 1.0107 - mrcnn_class_loss: 0.2267 - mrcnn_bbox_loss: 0.6155 - mrcnn_mask_loss: 0.5602 - val_loss: 2.2703 - val_rpn_class_loss: 0.0198 - val_rpn_bbox_loss: 0.8942 - val_mrcnn_class_loss: 0.2292 - val_mrcnn_bbox_loss: 0.5831 - val_mrcnn_mask_loss: 0.5440 - lr: 0.0010\n",
      "Epoch 4/500\n",
      "250/250 [==============================] - 59s 236ms/step - loss: 2.0021 - rpn_class_loss: 0.0234 - rpn_bbox_loss: 0.8511 - mrcnn_class_loss: 0.1906 - mrcnn_bbox_loss: 0.5012 - mrcnn_mask_loss: 0.5222 - val_loss: 1.6416 - val_rpn_class_loss: 0.0208 - val_rpn_bbox_loss: 0.6521 - val_mrcnn_class_loss: 0.1825 - val_mrcnn_bbox_loss: 0.3333 - val_mrcnn_mask_loss: 0.4530 - lr: 0.0010\n",
      "Epoch 5/500\n",
      "250/250 [==============================] - 60s 238ms/step - loss: 1.4727 - rpn_class_loss: 0.0187 - rpn_bbox_loss: 0.5984 - mrcnn_class_loss: 0.1703 - mrcnn_bbox_loss: 0.3110 - mrcnn_mask_loss: 0.4216 - val_loss: 1.2735 - val_rpn_class_loss: 0.0154 - val_rpn_bbox_loss: 0.4515 - val_mrcnn_class_loss: 0.2017 - val_mrcnn_bbox_loss: 0.2746 - val_mrcnn_mask_loss: 0.3304 - lr: 0.0010\n",
      "Epoch 6/500\n",
      "250/250 [==============================] - 60s 239ms/step - loss: 1.2171 - rpn_class_loss: 0.0135 - rpn_bbox_loss: 0.4673 - mrcnn_class_loss: 0.1961 - mrcnn_bbox_loss: 0.2416 - mrcnn_mask_loss: 0.3216 - val_loss: 1.0713 - val_rpn_class_loss: 0.0141 - val_rpn_bbox_loss: 0.3283 - val_mrcnn_class_loss: 0.2186 - val_mrcnn_bbox_loss: 0.2176 - val_mrcnn_mask_loss: 0.2927 - lr: 0.0010\n",
      "Epoch 7/500\n",
      "250/250 [==============================] - 59s 234ms/step - loss: 1.0079 - rpn_class_loss: 0.0116 - rpn_bbox_loss: 0.3784 - mrcnn_class_loss: 0.1811 - mrcnn_bbox_loss: 0.1930 - mrcnn_mask_loss: 0.2704 - val_loss: 0.8865 - val_rpn_class_loss: 0.0106 - val_rpn_bbox_loss: 0.3489 - val_mrcnn_class_loss: 0.1480 - val_mrcnn_bbox_loss: 0.1527 - val_mrcnn_mask_loss: 0.2264 - lr: 0.0010\n",
      "Epoch 8/500\n",
      "250/250 [==============================] - 59s 235ms/step - loss: 0.7715 - rpn_class_loss: 0.0094 - rpn_bbox_loss: 0.2648 - mrcnn_class_loss: 0.1350 - mrcnn_bbox_loss: 0.1478 - mrcnn_mask_loss: 0.2302 - val_loss: 0.7914 - val_rpn_class_loss: 0.0087 - val_rpn_bbox_loss: 0.3228 - val_mrcnn_class_loss: 0.1168 - val_mrcnn_bbox_loss: 0.1345 - val_mrcnn_mask_loss: 0.2085 - lr: 0.0010\n",
      "Epoch 9/500\n",
      "250/250 [==============================] - 60s 237ms/step - loss: 0.6630 - rpn_class_loss: 0.0081 - rpn_bbox_loss: 0.2194 - mrcnn_class_loss: 0.1088 - mrcnn_bbox_loss: 0.1299 - mrcnn_mask_loss: 0.2039 - val_loss: 0.7193 - val_rpn_class_loss: 0.0078 - val_rpn_bbox_loss: 0.2920 - val_mrcnn_class_loss: 0.1014 - val_mrcnn_bbox_loss: 0.1273 - val_mrcnn_mask_loss: 0.1908 - lr: 0.0010\n",
      "Epoch 10/500\n",
      "250/250 [==============================] - 59s 234ms/step - loss: 0.5785 - rpn_class_loss: 0.0073 - rpn_bbox_loss: 0.1857 - mrcnn_class_loss: 0.0934 - mrcnn_bbox_loss: 0.1145 - mrcnn_mask_loss: 0.1887 - val_loss: 0.6238 - val_rpn_class_loss: 0.0068 - val_rpn_bbox_loss: 0.2446 - val_mrcnn_class_loss: 0.0815 - val_mrcnn_bbox_loss: 0.1121 - val_mrcnn_mask_loss: 0.1789 - lr: 0.0010\n",
      "Epoch 11/500\n",
      "250/250 [==============================] - 57s 229ms/step - loss: 0.5154 - rpn_class_loss: 0.0064 - rpn_bbox_loss: 0.1585 - mrcnn_class_loss: 0.0765 - mrcnn_bbox_loss: 0.1003 - mrcnn_mask_loss: 0.1730 - val_loss: 0.6762 - val_rpn_class_loss: 0.0075 - val_rpn_bbox_loss: 0.2477 - val_mrcnn_class_loss: 0.1073 - val_mrcnn_bbox_loss: 0.1263 - val_mrcnn_mask_loss: 0.1874 - lr: 0.0010\n",
      "Epoch 12/500\n",
      "250/250 [==============================] - 59s 236ms/step - loss: 0.4476 - rpn_class_loss: 0.0055 - rpn_bbox_loss: 0.1252 - mrcnn_class_loss: 0.0715 - mrcnn_bbox_loss: 0.0888 - mrcnn_mask_loss: 0.1617 - val_loss: 0.5682 - val_rpn_class_loss: 0.0058 - val_rpn_bbox_loss: 0.2333 - val_mrcnn_class_loss: 0.0686 - val_mrcnn_bbox_loss: 0.0953 - val_mrcnn_mask_loss: 0.1652 - lr: 0.0010\n",
      "Epoch 13/500\n",
      "250/250 [==============================] - 58s 230ms/step - loss: 0.4334 - rpn_class_loss: 0.0055 - rpn_bbox_loss: 0.1242 - mrcnn_class_loss: 0.0666 - mrcnn_bbox_loss: 0.0825 - mrcnn_mask_loss: 0.1609 - val_loss: 0.5791 - val_rpn_class_loss: 0.0067 - val_rpn_bbox_loss: 0.2451 - val_mrcnn_class_loss: 0.0611 - val_mrcnn_bbox_loss: 0.0965 - val_mrcnn_mask_loss: 0.1697 - lr: 0.0010\n",
      "Epoch 14/500\n",
      "250/250 [==============================] - 59s 237ms/step - loss: 0.3897 - rpn_class_loss: 0.0050 - rpn_bbox_loss: 0.1017 - mrcnn_class_loss: 0.0569 - mrcnn_bbox_loss: 0.0777 - mrcnn_mask_loss: 0.1585 - val_loss: 0.5010 - val_rpn_class_loss: 0.0052 - val_rpn_bbox_loss: 0.2124 - val_mrcnn_class_loss: 0.0513 - val_mrcnn_bbox_loss: 0.0823 - val_mrcnn_mask_loss: 0.1498 - lr: 0.0010\n",
      "Epoch 15/500\n",
      "250/250 [==============================] - 59s 233ms/step - loss: 0.3507 - rpn_class_loss: 0.0044 - rpn_bbox_loss: 0.0851 - mrcnn_class_loss: 0.0475 - mrcnn_bbox_loss: 0.0694 - mrcnn_mask_loss: 0.1517 - val_loss: 0.5029 - val_rpn_class_loss: 0.0048 - val_rpn_bbox_loss: 0.2073 - val_mrcnn_class_loss: 0.0574 - val_mrcnn_bbox_loss: 0.0815 - val_mrcnn_mask_loss: 0.1520 - lr: 0.0010\n",
      "Epoch 16/500\n",
      "250/250 [==============================] - 60s 238ms/step - loss: 0.3198 - rpn_class_loss: 0.0041 - rpn_bbox_loss: 0.0740 - mrcnn_class_loss: 0.0420 - mrcnn_bbox_loss: 0.0601 - mrcnn_mask_loss: 0.1400 - val_loss: 0.5014 - val_rpn_class_loss: 0.0046 - val_rpn_bbox_loss: 0.2177 - val_mrcnn_class_loss: 0.0486 - val_mrcnn_bbox_loss: 0.0847 - val_mrcnn_mask_loss: 0.1458 - lr: 0.0010\n",
      "Epoch 17/500\n",
      "250/250 [==============================] - 59s 235ms/step - loss: 0.3012 - rpn_class_loss: 0.0038 - rpn_bbox_loss: 0.0629 - mrcnn_class_loss: 0.0384 - mrcnn_bbox_loss: 0.0550 - mrcnn_mask_loss: 0.1330 - val_loss: 0.5034 - val_rpn_class_loss: 0.0048 - val_rpn_bbox_loss: 0.2238 - val_mrcnn_class_loss: 0.0445 - val_mrcnn_bbox_loss: 0.0806 - val_mrcnn_mask_loss: 0.1497 - lr: 0.0010\n",
      "Epoch 18/500\n",
      "250/250 [==============================] - 61s 243ms/step - loss: 0.2828 - rpn_class_loss: 0.0033 - rpn_bbox_loss: 0.0579 - mrcnn_class_loss: 0.0385 - mrcnn_bbox_loss: 0.0546 - mrcnn_mask_loss: 0.1301 - val_loss: 0.4609 - val_rpn_class_loss: 0.0045 - val_rpn_bbox_loss: 0.2200 - val_mrcnn_class_loss: 0.0379 - val_mrcnn_bbox_loss: 0.0681 - val_mrcnn_mask_loss: 0.1305 - lr: 0.0010\n",
      "Epoch 19/500\n",
      "250/250 [==============================] - 59s 235ms/step - loss: 0.2735 - rpn_class_loss: 0.0033 - rpn_bbox_loss: 0.0573 - mrcnn_class_loss: 0.0353 - mrcnn_bbox_loss: 0.0498 - mrcnn_mask_loss: 0.1279 - val_loss: 0.4787 - val_rpn_class_loss: 0.0043 - val_rpn_bbox_loss: 0.2188 - val_mrcnn_class_loss: 0.0458 - val_mrcnn_bbox_loss: 0.0721 - val_mrcnn_mask_loss: 0.1377 - lr: 0.0010\n",
      "Epoch 20/500\n",
      "250/250 [==============================] - 59s 235ms/step - loss: 0.2656 - rpn_class_loss: 0.0031 - rpn_bbox_loss: 0.0529 - mrcnn_class_loss: 0.0305 - mrcnn_bbox_loss: 0.0465 - mrcnn_mask_loss: 0.1210 - val_loss: 0.4716 - val_rpn_class_loss: 0.0044 - val_rpn_bbox_loss: 0.2228 - val_mrcnn_class_loss: 0.0401 - val_mrcnn_bbox_loss: 0.0695 - val_mrcnn_mask_loss: 0.1348 - lr: 0.0010\n",
      "Epoch 21/500\n",
      "250/250 [==============================] - 59s 234ms/step - loss: 0.2635 - rpn_class_loss: 0.0032 - rpn_bbox_loss: 0.0539 - mrcnn_class_loss: 0.0327 - mrcnn_bbox_loss: 0.0491 - mrcnn_mask_loss: 0.1312 - val_loss: 0.4777 - val_rpn_class_loss: 0.0043 - val_rpn_bbox_loss: 0.2378 - val_mrcnn_class_loss: 0.0428 - val_mrcnn_bbox_loss: 0.0635 - val_mrcnn_mask_loss: 0.1293 - lr: 0.0010\n",
      "Epoch 22/500\n",
      "250/250 [==============================] - 58s 231ms/step - loss: 0.2433 - rpn_class_loss: 0.0030 - rpn_bbox_loss: 0.0474 - mrcnn_class_loss: 0.0293 - mrcnn_bbox_loss: 0.0440 - mrcnn_mask_loss: 0.1193 - val_loss: 0.4689 - val_rpn_class_loss: 0.0041 - val_rpn_bbox_loss: 0.2113 - val_mrcnn_class_loss: 0.0483 - val_mrcnn_bbox_loss: 0.0704 - val_mrcnn_mask_loss: 0.1348 - lr: 0.0010\n",
      "Epoch 23/500\n",
      "250/250 [==============================] - 59s 236ms/step - loss: 0.2337 - rpn_class_loss: 0.0027 - rpn_bbox_loss: 0.0428 - mrcnn_class_loss: 0.0318 - mrcnn_bbox_loss: 0.0418 - mrcnn_mask_loss: 0.1198 - val_loss: 0.4527 - val_rpn_class_loss: 0.0041 - val_rpn_bbox_loss: 0.2262 - val_mrcnn_class_loss: 0.0328 - val_mrcnn_bbox_loss: 0.0628 - val_mrcnn_mask_loss: 0.1268 - lr: 0.0010\n",
      "Epoch 24/500\n",
      "250/250 [==============================] - 58s 230ms/step - loss: 0.2192 - rpn_class_loss: 0.0026 - rpn_bbox_loss: 0.0399 - mrcnn_class_loss: 0.0237 - mrcnn_bbox_loss: 0.0414 - mrcnn_mask_loss: 0.1218 - val_loss: 0.4615 - val_rpn_class_loss: 0.0040 - val_rpn_bbox_loss: 0.2326 - val_mrcnn_class_loss: 0.0328 - val_mrcnn_bbox_loss: 0.0645 - val_mrcnn_mask_loss: 0.1277 - lr: 0.0010\n",
      "Epoch 25/500\n",
      "250/250 [==============================] - 58s 230ms/step - loss: 0.2129 - rpn_class_loss: 0.0025 - rpn_bbox_loss: 0.0371 - mrcnn_class_loss: 0.0219 - mrcnn_bbox_loss: 0.0387 - mrcnn_mask_loss: 0.1114 - val_loss: 0.4589 - val_rpn_class_loss: 0.0038 - val_rpn_bbox_loss: 0.2127 - val_mrcnn_class_loss: 0.0436 - val_mrcnn_bbox_loss: 0.0609 - val_mrcnn_mask_loss: 0.1379 - lr: 0.0010\n",
      "Epoch 26/500\n",
      "250/250 [==============================] - 58s 231ms/step - loss: 0.2087 - rpn_class_loss: 0.0025 - rpn_bbox_loss: 0.0327 - mrcnn_class_loss: 0.0276 - mrcnn_bbox_loss: 0.0359 - mrcnn_mask_loss: 0.1117 - val_loss: 0.4623 - val_rpn_class_loss: 0.0039 - val_rpn_bbox_loss: 0.2245 - val_mrcnn_class_loss: 0.0416 - val_mrcnn_bbox_loss: 0.0608 - val_mrcnn_mask_loss: 0.1315 - lr: 0.0010\n",
      "Epoch 27/500\n",
      "250/250 [==============================] - 58s 233ms/step - loss: 0.2158 - rpn_class_loss: 0.0024 - rpn_bbox_loss: 0.0345 - mrcnn_class_loss: 0.0285 - mrcnn_bbox_loss: 0.0363 - mrcnn_mask_loss: 0.1104 - val_loss: 0.4735 - val_rpn_class_loss: 0.0043 - val_rpn_bbox_loss: 0.2494 - val_mrcnn_class_loss: 0.0427 - val_mrcnn_bbox_loss: 0.0563 - val_mrcnn_mask_loss: 0.1208 - lr: 0.0010\n",
      "Epoch 28/500\n",
      "250/250 [==============================] - 58s 232ms/step - loss: 0.2007 - rpn_class_loss: 0.0024 - rpn_bbox_loss: 0.0315 - mrcnn_class_loss: 0.0272 - mrcnn_bbox_loss: 0.0330 - mrcnn_mask_loss: 0.1074 - val_loss: 0.4614 - val_rpn_class_loss: 0.0037 - val_rpn_bbox_loss: 0.2310 - val_mrcnn_class_loss: 0.0349 - val_mrcnn_bbox_loss: 0.0628 - val_mrcnn_mask_loss: 0.1289 - lr: 0.0010\n",
      "Epoch 29/500\n",
      "250/250 [==============================] - 60s 238ms/step - loss: 0.1910 - rpn_class_loss: 0.0022 - rpn_bbox_loss: 0.0299 - mrcnn_class_loss: 0.0209 - mrcnn_bbox_loss: 0.0335 - mrcnn_mask_loss: 0.1043 - val_loss: 0.4259 - val_rpn_class_loss: 0.0037 - val_rpn_bbox_loss: 0.2128 - val_mrcnn_class_loss: 0.0304 - val_mrcnn_bbox_loss: 0.0573 - val_mrcnn_mask_loss: 0.1216 - lr: 0.0010\n",
      "Epoch 30/500\n",
      "250/250 [==============================] - 60s 239ms/step - loss: 0.1940 - rpn_class_loss: 0.0022 - rpn_bbox_loss: 0.0322 - mrcnn_class_loss: 0.0209 - mrcnn_bbox_loss: 0.0300 - mrcnn_mask_loss: 0.1053 - val_loss: 0.4498 - val_rpn_class_loss: 0.0039 - val_rpn_bbox_loss: 0.2233 - val_mrcnn_class_loss: 0.0355 - val_mrcnn_bbox_loss: 0.0598 - val_mrcnn_mask_loss: 0.1273 - lr: 0.0010\n",
      "Epoch 31/500\n",
      "250/250 [==============================] - 60s 238ms/step - loss: 0.1940 - rpn_class_loss: 0.0021 - rpn_bbox_loss: 0.0298 - mrcnn_class_loss: 0.0201 - mrcnn_bbox_loss: 0.0280 - mrcnn_mask_loss: 0.1026 - val_loss: 0.4369 - val_rpn_class_loss: 0.0036 - val_rpn_bbox_loss: 0.2144 - val_mrcnn_class_loss: 0.0383 - val_mrcnn_bbox_loss: 0.0592 - val_mrcnn_mask_loss: 0.1214 - lr: 0.0010\n",
      "Epoch 32/500\n",
      "250/250 [==============================] - 58s 232ms/step - loss: 0.1879 - rpn_class_loss: 0.0019 - rpn_bbox_loss: 0.0288 - mrcnn_class_loss: 0.0226 - mrcnn_bbox_loss: 0.0300 - mrcnn_mask_loss: 0.1079 - val_loss: 0.4642 - val_rpn_class_loss: 0.0038 - val_rpn_bbox_loss: 0.2381 - val_mrcnn_class_loss: 0.0367 - val_mrcnn_bbox_loss: 0.0602 - val_mrcnn_mask_loss: 0.1255 - lr: 0.0010\n",
      "Epoch 33/500\n",
      "250/250 [==============================] - 58s 232ms/step - loss: 0.1875 - rpn_class_loss: 0.0021 - rpn_bbox_loss: 0.0317 - mrcnn_class_loss: 0.0199 - mrcnn_bbox_loss: 0.0276 - mrcnn_mask_loss: 0.0982 - val_loss: 0.4340 - val_rpn_class_loss: 0.0038 - val_rpn_bbox_loss: 0.2226 - val_mrcnn_class_loss: 0.0310 - val_mrcnn_bbox_loss: 0.0573 - val_mrcnn_mask_loss: 0.1194 - lr: 0.0010\n",
      "Epoch 34/500\n",
      "250/250 [==============================] - 60s 236ms/step - loss: 0.1735 - rpn_class_loss: 0.0019 - rpn_bbox_loss: 0.0256 - mrcnn_class_loss: 0.0195 - mrcnn_bbox_loss: 0.0273 - mrcnn_mask_loss: 0.1001 - val_loss: 0.4492 - val_rpn_class_loss: 0.0037 - val_rpn_bbox_loss: 0.2299 - val_mrcnn_class_loss: 0.0341 - val_mrcnn_bbox_loss: 0.0581 - val_mrcnn_mask_loss: 0.1234 - lr: 0.0010\n",
      "Epoch 35/500\n",
      "250/250 [==============================] - 62s 246ms/step - loss: 0.1767 - rpn_class_loss: 0.0019 - rpn_bbox_loss: 0.0289 - mrcnn_class_loss: 0.0174 - mrcnn_bbox_loss: 0.0272 - mrcnn_mask_loss: 0.1015 - val_loss: 0.4514 - val_rpn_class_loss: 0.0035 - val_rpn_bbox_loss: 0.2393 - val_mrcnn_class_loss: 0.0334 - val_mrcnn_bbox_loss: 0.0545 - val_mrcnn_mask_loss: 0.1208 - lr: 0.0010\n",
      "Epoch 36/500\n",
      "250/250 [==============================] - 60s 239ms/step - loss: 0.1764 - rpn_class_loss: 0.0018 - rpn_bbox_loss: 0.0273 - mrcnn_class_loss: 0.0182 - mrcnn_bbox_loss: 0.0262 - mrcnn_mask_loss: 0.1024 - val_loss: 0.4335 - val_rpn_class_loss: 0.0030 - val_rpn_bbox_loss: 0.2199 - val_mrcnn_class_loss: 0.0376 - val_mrcnn_bbox_loss: 0.0562 - val_mrcnn_mask_loss: 0.1168 - lr: 0.0010\n",
      "Epoch 37/500\n",
      "250/250 [==============================] - 60s 238ms/step - loss: 0.1734 - rpn_class_loss: 0.0018 - rpn_bbox_loss: 0.0294 - mrcnn_class_loss: 0.0184 - mrcnn_bbox_loss: 0.0254 - mrcnn_mask_loss: 0.0966 - val_loss: 0.4490 - val_rpn_class_loss: 0.0033 - val_rpn_bbox_loss: 0.2267 - val_mrcnn_class_loss: 0.0308 - val_mrcnn_bbox_loss: 0.0553 - val_mrcnn_mask_loss: 0.1329 - lr: 0.0010\n",
      "Epoch 38/500\n",
      "250/250 [==============================] - 59s 236ms/step - loss: 0.1613 - rpn_class_loss: 0.0017 - rpn_bbox_loss: 0.0209 - mrcnn_class_loss: 0.0180 - mrcnn_bbox_loss: 0.0229 - mrcnn_mask_loss: 0.0974 - val_loss: 0.4632 - val_rpn_class_loss: 0.0039 - val_rpn_bbox_loss: 0.2565 - val_mrcnn_class_loss: 0.0281 - val_mrcnn_bbox_loss: 0.0522 - val_mrcnn_mask_loss: 0.1226 - lr: 0.0010\n",
      "Epoch 39/500\n",
      "250/250 [==============================] - 63s 249ms/step - loss: 0.1658 - rpn_class_loss: 0.0017 - rpn_bbox_loss: 0.0237 - mrcnn_class_loss: 0.0182 - mrcnn_bbox_loss: 0.0251 - mrcnn_mask_loss: 0.1015 - val_loss: 0.4093 - val_rpn_class_loss: 0.0031 - val_rpn_bbox_loss: 0.1993 - val_mrcnn_class_loss: 0.0344 - val_mrcnn_bbox_loss: 0.0540 - val_mrcnn_mask_loss: 0.1185 - lr: 0.0010\n",
      "Epoch 40/500\n",
      "201/250 [=======================>......] - ETA: 10s - loss: 0.1549 - rpn_class_loss: 0.0017 - rpn_bbox_loss: 0.0224 - mrcnn_class_loss: 0.0162 - mrcnn_bbox_loss: 0.0231 - mrcnn_mask_loss: 0.0919"
     ]
    }
   ],
   "source": [
    "model.train(dataset_train, dataset_val, \n",
    "            epochs=EPOCHS[1], \n",
    "            augmentations=None, #augmentation, \n",
    "            custom_callbacks=[stop_early, reduce_lr, csv_logger_all])\n",
    "new_history = model.keras_model.history.history\n",
    "for k in new_history: \n",
    "    history[k] = history[k] + new_history[k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = range(len(list(history[\"loss\"])))\n",
    "epochs = tuple(e + 1 for e in epochs)\n",
    "\n",
    "\n",
    "plt.figure(figsize=(18, 6))\n",
    "\n",
    "plt.subplot(131, title=\"losses\")\n",
    "plt.plot(epochs, history[\"loss\"], label=\"train loss\")\n",
    "plt.plot(epochs, history[\"val_loss\"], label=\"valid loss\")\n",
    "plt.xticks(range(0, epochs[-1]+1, 20))\n",
    "plt.yscale(\"log\")\n",
    "for xpos in (epochs[0], epochs[-1]):\n",
    "    plt.axvline(x=xpos, color=\"gray\", linestyle=\"--\", linewidth=1)\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(132)\n",
    "plt.plot(epochs, history[\"mrcnn_class_loss\"], label=\"train class loss\")\n",
    "plt.plot(epochs, history[\"val_mrcnn_class_loss\"], label=\"valid class loss\")\n",
    "plt.xticks(range(0, epochs[-1]+1, 20))\n",
    "plt.yscale(\"log\")\n",
    "for xpos in (epochs[0], epochs[-1]):\n",
    "    plt.axvline(x=xpos, color=\"gray\", linestyle=\"--\", linewidth=1)\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(133)\n",
    "plt.plot(epochs, history[\"mrcnn_mask_loss\"], label=\"train mask loss\")\n",
    "plt.plot(epochs, history[\"val_mrcnn_mask_loss\"], label=\"valid mask loss\")\n",
    "plt.xticks(range(0, epochs[-1]+1, 20))\n",
    "plt.yscale(\"log\")\n",
    "for xpos in (epochs[0], epochs[-1]):\n",
    "    plt.axvline(x=xpos, color=\"gray\", linestyle=\"--\", linewidth=1)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InferenceConfig(ShapesConfig):\n",
    "    GPU_COUNT = 1\n",
    "    IMAGES_PER_GPU = 1\n",
    "\n",
    "inference_config = InferenceConfig()\n",
    "\n",
    "# Recreate the model in inference mode\n",
    "model = modellib.MaskRCNN(mode=\"inference\", \n",
    "                          config=inference_config,\n",
    "                          model_dir=dir_model)\n",
    "\n",
    "# Get path to saved weights\n",
    "# Either set a specific path or find last trained weights\n",
    "# model_path = os.path.join(ROOT_DIR, \".h5 file name here\")\n",
    "model_path = model.find_last()\n",
    "\n",
    "# Load trained weights\n",
    "print(\"Loading weights from \", model_path)\n",
    "model.load_weights(model_path, by_name=True)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image = cv2.imread(\"./shape_test_images/shape_test_image_653.png\") # check if image in folder exists - otherwise change name, if necessary\n",
    "image = cv2.imread(\"./shape_test_images/shape_test_image_102.png\") # check if image in folder exists - otherwise change name, if necessary\n",
    "\n",
    "# Run detection\n",
    "results = model.detect([image], verbose=1)\n",
    "res = results[0]\n",
    "print(res[\"rois\"])\n",
    "print(res[\"class_ids\"])\n",
    "print(res[\"scores\"])\n",
    "print(dataset_train.class_names)\n",
    "\n",
    "# Visualize results\n",
    "visualize.display_instances(image, res[\"rois\"], res[\"masks\"], res[\"class_ids\"], dataset_train.class_names, res[\"scores\"], figsize=(8, 8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test on a random image, \n",
    "image_id = random.choice(dataset_val.image_ids)\n",
    "original_image, image_meta, gt_class_id, gt_bbox, gt_mask =\\\n",
    "    modellib.load_image_gt(dataset_val, inference_config, \n",
    "                           image_id, use_mini_mask=False)\n",
    "\n",
    "log(\"original_image\", original_image)\n",
    "log(\"image_meta\", image_meta)\n",
    "log(\"gt_class_id\", gt_class_id) # ground truth\n",
    "log(\"gt_bbox\", gt_bbox) # ground truth\n",
    "log(\"gt_mask\", gt_mask) # ground truth\n",
    "\n",
    "# visualize.display_instances(original_image, gt_bbox, gt_mask, gt_class_id, \n",
    "#                             dataset_val.class_names, figsize=(8, 8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf215",
   "language": "python",
   "name": "tf215"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
