{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/maxw1489/Mask_RCNN (tensorflow 2.9.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.15.0\n",
      "Num GPUs Available:  1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[name: \"/device:CPU:0\"\n",
       " device_type: \"CPU\"\n",
       " memory_limit: 268435456\n",
       " locality {\n",
       " }\n",
       " incarnation: 14258072379458261196\n",
       " xla_global_id: -1,\n",
       " name: \"/device:GPU:0\"\n",
       " device_type: \"GPU\"\n",
       " memory_limit: 22500343808\n",
       " locality {\n",
       "   bus_id: 1\n",
       "   links {\n",
       "   }\n",
       " }\n",
       " incarnation: 10276191469000574473\n",
       " physical_device_desc: \"device: 0, name: NVIDIA GeForce RTX 4090, pci bus id: 0000:01:00.0, compute capability: 8.9\"\n",
       " xla_global_id: 416903419]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\" # https://stackoverflow.com/questions/35911252/disable-tensorflow-debugging-information\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.client import device_lib\n",
    "\n",
    "print(tf.__version__)\n",
    "print(\"Num GPUs Available: \",\n",
    "len(tf.config.list_physical_devices('GPU')))\n",
    "device_lib.list_local_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import os\n",
    "import json\n",
    "import cv2\n",
    "import sys\n",
    "import math\n",
    "import random\n",
    "import warnings\n",
    "\n",
    "import cv2\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "dir_root = os.path.abspath(\"./\")\n",
    "\n",
    "# sys.path.append(os.path.join(dir_root, \"maskrcnn/Mask_RCNN-master/\"))  # To find local version\n",
    "# sys.path.append(os.path.join(dir_root, \"maskrcnn/Mask_RCNN-master_tf2p9/\"))  # To find local version\n",
    "# sys.path.append(os.path.join(dir_root, \"maskrcnn/mask-rcnn-tf2-us-main/\"))  # To find local version\n",
    "\n",
    "# sys.path.append(os.path.join(dir_root, \"maskrcnn/mask-rcnn-tf2-us-main/samples/coco/\"))  # To find local version\n",
    "\n",
    "\n",
    "from mrcnn import utils\n",
    "from mrcnn import visualize\n",
    "from mrcnn.visualize import display_images\n",
    "import mrcnn.model as modellib\n",
    "from mrcnn.model import log\n",
    "from mrcnn.config import Config\n",
    "\n",
    "import imgaug as ia\n",
    "import imgaug.augmenters as iaa\n",
    "\n",
    "\n",
    "\n",
    "logging.disable(logging.WARNING)\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' \n",
    "    # 0 = all messages are logged (default behavior)\n",
    "    # 1 = INFO messages are not printed\n",
    "    # 2 = INFO and WARNING messages are not printed\n",
    "    # 3 = INFO, WARNING, and ERROR messages are not printed\n",
    "\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.tensorflow.org/api_docs/python/tf/config/experimental/set_memory_growth\n",
    "physical_devices = tf.config.list_physical_devices(\"GPU\") \n",
    "for device in physical_devices:\n",
    "    tf.config.experimental.set_memory_growth(device=device, enable=True)\n",
    "\n",
    "tf.config.threading.set_intra_op_parallelism_threads(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_OF_IMAGES = 1000\n",
    "NUM_OF_VAL_IMAGES = int(NUM_OF_IMAGES*0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Configurations:\n",
      "BACKBONE                       resnet101\n",
      "BACKBONE_STRIDES               [4, 8, 16, 32, 64]\n",
      "BATCH_SIZE                     4\n",
      "BBOX_STD_DEV                   [0.1 0.1 0.2 0.2]\n",
      "COMPUTE_BACKBONE_SHAPE         None\n",
      "DETECTION_MAX_INSTANCES        100\n",
      "DETECTION_MIN_CONFIDENCE       0.7\n",
      "DETECTION_NMS_THRESHOLD        0.3\n",
      "FPN_CLASSIF_FC_LAYERS_SIZE     1024\n",
      "GPU_COUNT                      1\n",
      "GRADIENT_CLIP_NORM             5.0\n",
      "IMAGES_PER_GPU                 4\n",
      "IMAGE_CHANNEL_COUNT            3\n",
      "IMAGE_MAX_DIM                  512\n",
      "IMAGE_META_SIZE                16\n",
      "IMAGE_MIN_DIM                  512\n",
      "IMAGE_MIN_SCALE                0\n",
      "IMAGE_RESIZE_MODE              square\n",
      "IMAGE_SHAPE                    [512 512   3]\n",
      "LEARNING_MOMENTUM              0.9\n",
      "LEARNING_RATE                  0.001\n",
      "LOSS_WEIGHTS                   {'rpn_class_loss': 1.0, 'rpn_bbox_loss': 1.0, 'mrcnn_class_loss': 1.0, 'mrcnn_bbox_loss': 1.0, 'mrcnn_mask_loss': 1.0}\n",
      "MASK_POOL_SIZE                 14\n",
      "MASK_SHAPE                     [28, 28]\n",
      "MAX_GT_INSTANCES               100\n",
      "MEAN_PIXEL                     [123.7 116.8 103.9]\n",
      "MINI_MASK_SHAPE                (56, 56)\n",
      "NAME                           60_shapes_resnet\n",
      "NUM_CLASSES                    4\n",
      "POOL_SIZE                      7\n",
      "POST_NMS_ROIS_INFERENCE        1000\n",
      "POST_NMS_ROIS_TRAINING         2000\n",
      "PRE_NMS_LIMIT                  6000\n",
      "ROI_POSITIVE_RATIO             0.33\n",
      "RPN_ANCHOR_RATIOS              [0.5, 1, 2]\n",
      "RPN_ANCHOR_SCALES              (8, 16, 32, 64, 128)\n",
      "RPN_ANCHOR_STRIDE              1\n",
      "RPN_BBOX_STD_DEV               [0.1 0.1 0.2 0.2]\n",
      "RPN_NMS_THRESHOLD              0.7\n",
      "RPN_TRAIN_ANCHORS_PER_IMAGE    256\n",
      "RUN_EAGERLY                    False\n",
      "STEPS_PER_EPOCH                250\n",
      "TOP_DOWN_PYRAMID_SIZE          256\n",
      "TRAIN_BN                       False\n",
      "TRAIN_ROIS_PER_IMAGE           128\n",
      "USE_MINI_MASK                  False\n",
      "USE_RPN_ROIS                   True\n",
      "VALIDATION_STEPS               25\n",
      "WEIGHT_DECAY                   0.0001\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "class ShapesConfig(Config):\n",
    "    \"\"\"Configuration for training on the toy shapes dataset.\n",
    "    Derives from the base Config class and overrides values specific\n",
    "    to the toy shapes dataset.\n",
    "    \"\"\"\n",
    "    # Give the configuration a recognizable name\n",
    "    NAME = \"60_shapes_resnet\"\n",
    "    BACKBONE = \"resnet101\" # \"resnet101\"\n",
    "\n",
    "    # The strides of each layer of the FPN Pyramid. These values\n",
    "    # are based on a SHViT  backbone.\n",
    "    # BACKBONE_STRIDES = [8, 16, 32, 64, 128] # 128 added as they add 64 in the paper (original strides were [4,8,16,32] -> [4,8,16,32,64], maybe because P5 was upsampled by factor 2??)\n",
    "    BACKBONE_STRIDES= [4, 8, 16, 32, 64] # resnet\n",
    "\n",
    "\n",
    "    # Train on 1 GPU and 8 images per GPU. We can put multiple images on each\n",
    "    # GPU because the images are small. Batch size is 8 (GPUs * images/GPU).\n",
    "    GPU_COUNT = 1\n",
    "    IMAGES_PER_GPU = 4\n",
    "\n",
    "    # Number of classes (including background)\n",
    "    NUM_CLASSES = 1 + 3  # background + 3 shapes\n",
    "\n",
    "    # Use small images for faster training. Set the limits of the small side\n",
    "    # the large side, and that determines the image shape.\n",
    "    IMAGE_MIN_DIM = 512 # 128\n",
    "    IMAGE_MAX_DIM = 512 # 128\n",
    "\n",
    "    # Use smaller anchors because our image and objects are small\n",
    "    RPN_ANCHOR_SCALES = (8, 16, 32, 64, 128)  # anchor side in pixels resnet\n",
    "    #RPN_ANCHOR_SCALES = (16, 32, 64, 128, 256) # anchor side in pixels shvit\n",
    "\n",
    "    # Reduce training ROIs per image because the images are small and have\n",
    "    # few objects. Aim to allow ROI sampling to pick 33% positive ROIs.\n",
    "    TRAIN_ROIS_PER_IMAGE = 128 # 32\n",
    "\n",
    "    # Use a small epoch since the data is simple\n",
    "    STEPS_PER_EPOCH = int(NUM_OF_IMAGES / IMAGES_PER_GPU)\n",
    "\n",
    "    # use small validation steps since the epoch is small\n",
    "    VALIDATION_STEPS = int(NUM_OF_VAL_IMAGES / IMAGES_PER_GPU)\n",
    "\n",
    "    RUN_EAGERLY = False    \n",
    "\n",
    "\n",
    "\n",
    "config = ShapesConfig()\n",
    "config.display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ShapesDataset(utils.Dataset):\n",
    "    \"\"\"Generates the shapes synthetic dataset. The dataset consists of simple\n",
    "    shapes (triangles, squares, circles) placed randomly on a blank surface.\n",
    "    The images are generated on the fly. No file access required.\n",
    "    \"\"\"\n",
    "\n",
    "    def load_shapes(self, count, height, width):\n",
    "        \"\"\"Generate the requested number of synthetic images.\n",
    "        count: number of images to generate.\n",
    "        height, width: the size of the generated images.\n",
    "        \"\"\"\n",
    "        # Add classes\n",
    "        self.add_class(\"shapes\", 1, \"square\")\n",
    "        self.add_class(\"shapes\", 2, \"circle\")\n",
    "        self.add_class(\"shapes\", 3, \"triangle\")\n",
    "\n",
    "        # Add images\n",
    "        # Generate random specifications of images (i.e. color and\n",
    "        # list of shapes sizes and locations). This is more compact than\n",
    "        # actual images. Images are generated on the fly in load_image().\n",
    "        for i in range(count):\n",
    "            bg_color, shapes = self.random_image(height, width)\n",
    "            #print(\"bg_color\", bg_color)\n",
    "            #print(\"shapes\", shapes)\n",
    "            self.add_image(\"shapes\", image_id=i, path=None,\n",
    "                           width=width, height=height,\n",
    "                           bg_color=bg_color, shapes=shapes)\n",
    "\n",
    "    def load_image(self, image_id):\n",
    "        \"\"\"Generate an image from the specs of the given image ID.\n",
    "        Typically this function loads the image from a file, but\n",
    "        in this case it generates the image on the fly from the\n",
    "        specs in image_info.\n",
    "        \"\"\"\n",
    "        info = self.image_info[image_id]\n",
    "        bg_color = np.array(info['bg_color']).reshape([1, 1, 3])\n",
    "        image = np.ones([info['height'], info['width'], 3], dtype=np.uint8)\n",
    "        image = image * bg_color.astype(np.uint8)\n",
    "        for shape, color, dims in info['shapes']:\n",
    "            image = self.draw_shape(image, shape, dims, color)\n",
    "        return image\n",
    "\n",
    "    def image_reference(self, image_id):\n",
    "        \"\"\"Return the shapes data of the image.\"\"\"\n",
    "        info = self.image_info[image_id]\n",
    "        if info[\"source\"] == \"shapes\":\n",
    "            return info[\"shapes\"]\n",
    "        else:\n",
    "            super(self.__class__).image_reference(self, image_id)\n",
    "\n",
    "    def load_mask(self, image_id):\n",
    "        \"\"\"Generate instance masks for shapes of the given image ID.\n",
    "        \"\"\"\n",
    "        info = self.image_info[image_id]\n",
    "        shapes = info['shapes']\n",
    "        count = len(shapes)\n",
    "        mask = np.zeros([info['height'], info['width'], count], dtype=np.uint8)\n",
    "        for i, (shape, _, dims) in enumerate(info['shapes']):\n",
    "            mask[:, :, i:i + 1] = self.draw_shape(mask[:, :, i:i + 1].copy(),\n",
    "                                                  shape, dims, 1)\n",
    "        # Handle occlusions\n",
    "        occlusion = np.logical_not(mask[:, :, -1]).astype(np.uint8)\n",
    "        for i in range(count - 2, -1, -1):\n",
    "            mask[:, :, i] = mask[:, :, i] * occlusion\n",
    "            occlusion = np.logical_and(\n",
    "                occlusion, np.logical_not(mask[:, :, i]))\n",
    "        # Map class names to class IDs.\n",
    "        class_ids = np.array([self.class_names.index(s[0]) for s in shapes])\n",
    "        return mask, class_ids.astype(np.int32)\n",
    "\n",
    "    def draw_shape(self, image, shape, dims, color):\n",
    "        \"\"\"Draws a shape from the given specs.\"\"\"\n",
    "        # Get the center x, y and the size s\n",
    "        x, y, s = dims\n",
    "        if shape == 'square':\n",
    "            image = cv2.rectangle(image, (x - s, y - s),\n",
    "                                  (x + s, y + s), color, -1)\n",
    "        elif shape == \"circle\":\n",
    "            image = cv2.circle(image, (x, y), s, color, -1)\n",
    "        elif shape == \"triangle\":\n",
    "            points = np.array([[(x, y - s),\n",
    "                                (x - s / math.sin(math.radians(60)), y + s),\n",
    "                                (x + s / math.sin(math.radians(60)), y + s),\n",
    "                                ]], dtype=np.int32)\n",
    "            image = cv2.fillPoly(image, points, color)\n",
    "        return image\n",
    "\n",
    "    def random_shape(self, height, width):\n",
    "        \"\"\"Generates specifications of a random shape that lies within\n",
    "        the given height and width boundaries.\n",
    "        Returns a tuple of three valus:\n",
    "        * The shape name (square, circle, ...)\n",
    "        * Shape color: a tuple of 3 values, RGB.\n",
    "        * Shape dimensions: A tuple of values that define the shape size\n",
    "                            and location. Differs per shape type.\n",
    "        \"\"\"\n",
    "        # Shape\n",
    "        shape = random.choice([\"square\", \"circle\", \"triangle\"])\n",
    "        # Color\n",
    "        color = tuple([random.randint(0, 255) for _ in range(3)])\n",
    "        # Center x, y\n",
    "        buffer = 20\n",
    "        y = random.randint(buffer, height - buffer - 1)\n",
    "        x = random.randint(buffer, width - buffer - 1)\n",
    "        # Size\n",
    "        s = random.randint(buffer, height // 4)\n",
    "        return shape, color, (x, y, s)\n",
    "\n",
    "    def random_image(self, height, width):\n",
    "        \"\"\"Creates random specifications of an image with multiple shapes.\n",
    "        Returns the background color of the image and a list of shape\n",
    "        specifications that can be used to draw the image.\n",
    "        \"\"\"\n",
    "        # Pick random background color\n",
    "        bg_color = np.array([random.randint(0, 255) for _ in range(3)])\n",
    "        # Generate a few random shapes and record their\n",
    "        # bounding boxes\n",
    "        shapes = []\n",
    "        boxes = []\n",
    "        N = random.randint(1, 4)\n",
    "        for _ in range(N):\n",
    "            shape, color, dims = self.random_shape(height, width)\n",
    "            shapes.append((shape, color, dims))\n",
    "            x, y, s = dims\n",
    "            boxes.append([y - s, x - s, y + s, x + s])\n",
    "        # Apply non-max suppression wit 0.3 threshold to avoid\n",
    "        # shapes covering each other\n",
    "        keep_ixs = utils.non_max_suppression(\n",
    "            np.array(boxes), np.arange(N), 0.3)\n",
    "        shapes = [s for i, s in enumerate(shapes) if i in keep_ixs]\n",
    "        return bg_color, shapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training dataset\n",
    "dataset_train = ShapesDataset()\n",
    "dataset_train.load_shapes(NUM_OF_IMAGES, config.IMAGE_SHAPE[0], config.IMAGE_SHAPE[1])\n",
    "dataset_train.prepare()\n",
    "\n",
    "# Validation dataset\n",
    "dataset_val = ShapesDataset()\n",
    "dataset_val.load_shapes(NUM_OF_VAL_IMAGES, config.IMAGE_SHAPE[0], config.IMAGE_SHAPE[1])\n",
    "dataset_val.prepare()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask, idx = dataset_val.load_mask(2)\n",
    "np.max(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1400x700 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1400x700 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1400x700 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1400x700 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABFEAAAESCAYAAAA17UrCAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/TGe4hAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAvOElEQVR4nO3deXQUZaL38V9V9ZaFbBBAElbFQICAsoOyqCgKCoMCLoDLyCIgAkO8F9ydRe+o484Vdd7R6xVGlFc9enXGUUTEZXBBBPVVdGTREREhhIQkdNL1/uGQC7JVQrqf7s73c07OkXR11a8TU93966eex3Jd1xUAAAAAAACOyDYdAAAAAAAAIBFQogAAAAAAAHhAiQIAAAAAAOABJQoAAAAAAIAHlCgAAAAAAAAeUKIAAAAAAAB4QIkCAAAAAADgASUKAAAAAACAB5QoAAAAAAAAHlCiAACOSZcuXfTiiy/W674333yzRo8e3bCBACS8Yzmv1NWQIUN0zz33xORYAIDER4lSD4d7srUsSx999NEx73/kyJGaP3/+Ad/Lz8/X0KFDD/je+eefr1mzZtV5/+3atVNKSorS09OVnp6urKysA26fMmWKCgoKZNv2QY/ziy++0C9+8Qu1bNlSWVlZGjhwoN566y3Px7755pvl8/lqj52enq6nnnqq9valS5dqwIABSk1NVY8ePQ66f3FxsQoKCtSkSRO1b99et912W10eOoAo+OSTTzRy5EjTMQAkiHbt2um555474jacVwAA8YoSJQ4NHTpUr7/+eu2/N2zYIL/fr7Vr16qyslKS5LquVq5ceVCx4tWSJUtUVlamsrIylZSUHHBb9+7dtXDhQvXp0+eg+5WUlOjss8/WunXr9OOPP+qyyy7TOeeco+3bt3s+9siRI2uPXVZWpvHjx9felpOTo9mzZ+u666475H1DoZCWLVumkpISvfzyy1q0aJEefvhhz8cGEFvV1dWmIwBIIDU1NXJd13QMAAAOixIlRsaOHasJEybU/vuOO+5Qly5dVFFRcdC2Q4cO1QcffKDdu3dLklasWKHTTz9dJ510kt555x1J0vr167Vjxw4NHjy4wbPOmDFDp59+ukKh0EG39enTR1OmTFFubq4cx9HkyZPlOI4+/vhjSdKLL76oFi1a6LvvvpMk/eMf/1B2dvYBpdCRnHHGGRo3bpzy8vIOefuvf/1rde3aVY7jqFOnThozZoxWrVpVz0cKoC5KS0s1c+ZMtWnTRhkZGerdu7e2bNlywKfKjz32mHr06KGbbrpJLVu2rC1JlyxZou7duysjI0Nt27bVY489dshjbNu2TZdccolatWqlVq1aafbs2aqqqorRIwQQbWPHjtXmzZt10UUXKT09XdOmTZNlWXrggQfUtWtXpaamqqys7IDzyubNmzVs2DDl5uYqOztbI0aM0MaNG2v3edlll2ny5Mm68MIL1aRJExUUFGjFihW1t5eUlGjs2LHKyspSp06ddP/998uyrMNm/PDDDzV06FDl5OTohBNO0COPPBKlnwYAIBFRosTII488ojfffFP/9V//pffff1+/+c1v9Oc//1kpKSkHbdujRw81adKkthxYsWKFhgwZosGDB9e+KFixYoW6d++unJwcSdLtt9+urKysw34tXrz4gGNMnTpVzZo1U//+/fXSSy/V+3GtW7dOu3fvVmFhoaSfRpmMHz9ekyZNUlVVlS666CJNnz79gBEzy5cvV9OmTXXiiSfquuuuqx1dU1f7RuMUFRXVOz8A7y677DJ9+eWXevfdd1VSUqKHH374kOew9evXy+fzafPmzXriiSf0wgsvaObMmbr77rtVUlKi9957T927dz/ofq7r6rzzzlPLli315Zdfat26dVq7dq1+85vfxOLhAYiBp59+Wm3atKkdEfvQQw9JkhYvXqxXXnlFpaWlSktLO+A+kUhEc+fO1ZYtW7Rp0yalpqZq8uTJB2zz5z//WVOmTFFJSYkmTpyoyy67rPa2q6++WuXl5dq0aZNef/11PfHEE4fNt3XrVg0bNkxXXXWVfvjhBz333HO66aab9NprrzXcDwEAkNhc1NngwYPdUCjkZmZmHvAlyV2zZs1h7/fmm2+6WVlZbvv27d0HHnjgiMcYNWqUW1xc7Lqu6+bl5bmbN292V6xY4Z566qmu67rumDFj3Llz59Yr/8qVK93y8nK3srLSffLJJ91QKOSuXr36kI/z7rvvPux+duzY4RYWFro33njjAd+vrKx0i4qK3KKiIrdfv35uOByuvW39+vXuli1b3JqaGnfdunVu9+7d3VmzZh207z/96U9u9+7dj/g45s+f73bu3NktKys78gMGcMy2bt3qSnI3bdp00G1t27Z1n332Wdd1f/rbzcnJcWtqampvHz58uHvLLbcccr833XSTO2rUKNd1XXf16tUH3feVV15xO3To0HAPBIBx+58zXNd1JR3w70Nts781a9a4gUCg9lxx6aWXuuPHj6+9/ZtvvnEludu3b3erq6tdv9/vvvfee7W3L1261N3/JfD+r3d+//vfu6NHjz7geAsWLHCvuOKKejxSAEAyYiRKPd12220qKSk54OtoBg4cqA4dOqi0tFRXXnnlEbfdNy/Khg0bFAwG1bp1a/Xt21dr165VeXn5Mc2Hcuqppyo1NVXBYFAXX3yxzj33XC1btqxO+9i1a5eGDx+uU045RTfffPMBtwWDQV1xxRX6+OOPNW/ePPl8vtrbunTpovz8fNm2ra5du+p3v/vdARPLenXbbbfpqaee0iuvvHLQJ1YAGt6mTZsUDAbVpk2bo26bl5cn2/7fp5dNmzapY8eOR73fxo0bVVJSopycnNpRdBdccIG+//77Y8oOIP4d6dzyww8/6OKLL1br1q2VkZGhQYMGae/evbWXPUtSy5Yta/973+uC3bt3a/v27QqHw2rdurWnY23cuFEvvfTSAaN577vvvtrLlAE0bk8++WTt4hhdunQxHQeGUKLE0F133aWqqip17txZCxYsOOK2Q4cO1Zo1a/T888/XznsSCoXUo0cPPfLII9q5c6cGDRpUu/3vfve7A1a8+fnXk08+edhj7f9mx4vS0lKdddZZ6tKlix566KGDriv++uuvdcstt2jy5MkqLi5WaWlpgx1b+unSpUWLFmn58uXKz8+v8/0B1F3btm1VVVWlLVu2HHXbn/9dt23bVl9++eVR79e6dWs1b978gHJ6165dKisrq3duAPHnUM/9R3o9MH/+fO3Zs0cffvihSktLtXLlSknyNAFts2bN5Pf7Dzh3bd68+bDbt27dWr/4xS8OOA/t3r37mC59BpA8LrnkktrFMT755BPTcWAIJUqMfPDBB/r1r3+tJUuWaPHixXr88cf117/+9bDbd+vWTdnZ2brrrrs0ZMiQ2u8PHjxY//Ef/6GePXsqIyOj9vsLFiw4YMWbn39dcsklkn564bBy5UpVVVUpHA5r6dKlev755zV69Ojafe3du1eVlZWKRCKqrq5WZWVl7Qob+wqUE088UY8++uhBBUp1dXXtPCgPP/ywevbsqWnTptXe/uyzz+rHH3+UJH3++edasGCBzj///Nrba2pqVFlZqXA4LNd1VVlZecCkkr///e/14IMPavny5Wrbtm0dfgMAjkWLFi00atQoTZs2Td99950ikYjWrFlT+/d8JFOnTtW9996rN954Q5FIRNu2bdOaNWsO2q53795q06aNrr/+eu3evVuu62rTpk16+eWXo/GQABjSokULffXVV563Ly0tVWpqqrKysvTjjz/qlltu8Xxfx3E0btw43XzzzSotLdXWrVt11113HXb7iRMnavny5Vq2bJnC4bDC4bA++ugjvffee56PCQBIbpQoMVBWVqaLLrpIv/3tb9WtWze1bt1aDz/8sC699FJt27btkPexLEuDBw/W1q1bD1iBZ9/36nspT1lZmWbNmqWmTZsqNzdXd955p5YuXap+/frVbnPmmWcqJSVFb775poqLi5WSklI7seOzzz6rd999V8uWLVNGRsZBI11uuOEGSaq9xOeRRx7R22+/rccff1zSTxPKFRQUKC0tTWeffbbOOuss3XnnnbXHfuKJJ5SSkqIpU6bo448/VkpKigoKCmpv/7d/+zd9//33Kioqqj322WefXa+fBYC6efzxx9W6dWv16tVLWVlZmjZt2iFXGPu50aNH6w9/+INmzJihzMxM9e7dW+vWrTtoO8dx9MILL+jbb79V586dlZmZqREjRngaxQIgcSxYsEAPPPCAsrOzNX369KNuf8stt+jLL79Udna2Bg4cWOfn/fvvv7/20ughQ4Zo3LhxCgQCh9w2Ly9Pf/3rX7Vo0SIdd9xxatGihWbMmHHEUbUAgMbFcr2MhQQAAACSwOLFi3XjjTdS0AIA6oWRKAAAAEhaGzZs0Pvvvy/XdbVhwwb99re/1dixY03HAgAkKN/RNwEAAAASU3l5uSZMmKAtW7YoMzNTo0eP1vXXX286FgAgQXE5DwAAAAAAgAdczgMAAAAAAOABJQoAAAAAAIAHlCgAAAAAAAAeUKIAAAAAAAB44Hl1nv94MyeaORJe62BL5fqzZVmW6SiAzuixynQERMn06dP1n//5n6ZjAJKkRJ6bnudrIHFwrgEQC17PNYxEaSDf7f1Bu2vKE/okDyD+3XzzzTr99NNNxwAAAAAaJUqUBlLt1ujrym8pUgBEVfPmzbVkyRKKFAAAAMAASpQGRJECIBZyc3MpUgAAAAADKFEaWLVbo42V/1TYrTYdBUASy83N1WOPPaa8vDzTUQAAAIBGgxIlCsJutb6p+l7Vbo3pKACSWF5enu666y5lZmaajgIAAAA0CpQoUbKzulTbwzu5rAdA1FiWpXHjxmnKlCnM/g8AAADEACVKFG2t2q6S6t0UKQCixrIszZ8/X6NGjTIdBQAAAEh6lChRVKOIvq3aphpxWQ+A6MnOztbtt9+upk2bmo4CAAAAJDVKlCircvdqS+X3jEYBEFUFBQW65557uKwHAAAAiCJKlBgoqS7VjupS0zEAJLnRo0fr4osvNh0DAAAASFqUKDEQkavv925XNcseA4ii9PR0FRcXKycnx3QUAAAAIClRosRIRaRKO8O7TccAkOS6deum888/33QMAAAAIClRosTQtvAOVUb2mo4BIInZtq1Zs2bphBNOMB0FAAAASDqUKDFUGanS93u3M8ksgKjq2rWriouL5TiO6SgAAABAUqFEibGd4VJVRKpMxwCQ5MaNG6fOnTubjgEAAAAkFUqUGKtRRD+EdzAaBUBUZWVlaebMmbJtTvMAAABAQ+HVtQGl1eWKKGI6BoAkN2zYMKWnp5uOAQAAACQNShQD9rph7QyXMhoFQFS1a9eOlXoAAACABkSJYsi28A5GowCIKtu2NWfOHGVkZJiOAgAAACQFShRDKiJVKq+pMB0DQJLr1q2b+vTpYzoGAAAAkBQoUQz6MbyLS3oARN2kSZNMRwAAAACSAiWKQXsiFap2a0zHAJDkevfurdzcXNMxAAAAgIRHiWJQZWSvKiNVpmMASHIFBQUqLCw0HQMAAABIeJQohm0Pl5iOACDJWZalK664wnQMAAAAIOFRohhWVrNH4UjYdAwASe6UU05Ry5YtTccAAAAAEholimFht1o1LHUMIMry8/NZ6hgAAAA4RpQohrlytSNcajoGgCTn9/s1fvx40zEAAACAhEaJEgfCbpiljgFElWVZys/Pl2VZpqMAAAAACYsSJQ6UVO9mqWMAUXfeeeex1DEAAABwDChR4sBPo1AYiQIgulJSUmTbnPYBAACA+uLVdByIKKLSmnLTMQAkudTUVJ1xxhmmYwAAAAAJixIlDriSqljmGECU+f1+dejQwXQMAAAAIGFRogAAAAAAAHhAiRInKiKVirgR0zEAJLlu3bopEAiYjgEAAAAkJEqUOFFeUyGXyWUBRNmAAQMUCoVMxwAAAAASEiUKAAAAAACAB5QoAAAAAAAAHlCiAAAAAAAAeECJAgAAAAAA4AElCgAAAAAAgAeUKHEi4kZUGdlrOgaAJJeWlqaOHTuajgEAAAAkJEqUOGFZtoK233QMAEmuoqJCX3/9tekYAAAAQEKiRIkTliRLlukYAJJcJBJRdXW16RgAAABAQqJEAQAAAAAA8IASBQAAAAAAwANKFAAAAAAAAA8oUQAAAAAAADygRIkTjuVITCwLIMp27Nihmpoa0zEAAACAhESJEieyfU1kU6IAiLJly5apvLzcdAwAAAAgIVGixA1LlkWJAiC6IpGI6QgAAABAwqJEiRPUJwBiIRwOm44AAAAAJCxKlDhgy1a2P8N0DABJbvfu3Xr66adNxwAAAAASFiVKHLAkOfwqAERZJBJRWVmZ6RgAAABAwuKdexxIc1L+tToPAETPO++8o127dpmOAQAAACQsSpQ4ELQDsi1+FQCi68svv1RFRYXpGAAAAEDC4p27YZakbB/zoQCIrnA4rGeeecZ0DAAAACChUaIYZsmS3/abjgEgyYXDYX377bemYwAAAAAJjRLFsCZOmoIWJQqA6Hrttde0ceNG0zEAAACAhEaJYlimL12WZZmOASDJvfTSS6qurjYdAwAAAEholCgG2bKV7qSZjgEgye3evVsrV640HQMAAABIeJQoBqU5KQrZAdMxACS51atX69NPPzUdAwAAAEh4lCgG5fgzuZQHQNQ98cQTpiMAAAAASYESxRCf5SjNTjEdA0CS2759u9577z3TMQAAAICkQIliSLYvg0t5AETd0qVLuZQHAAAAaCCUKAb4LEe5/mwu5QEQVdu3b9eDDz5oOgYAAACQNChRDAhaAQXtoOkYAJLcF198oQ0bNpiOAQAAACQNSpQYs2SpeSBHjEEBEE179+7Vvffeq3A4bDoKAAAAkDQoUWIs1Q4p09eES3kARNUHH3ygF1980XQMAAAAIKlQosSQ/a9RKI7Fjx1A9OzZs0f33HOP9uzZYzoKAAAAkFR4Nx9DOf4sZfsyTMcAkOQef/xxPfPMM6ZjAAAAAEmHEiVGHNlq7s/hMh4AUVVSUqL77rtPkUjEdBQAAAAg6VCixEi2P1MhO2A6BoAkt2TJEn3++eemYwAAAABJiRIlBlLskPKCzRmFAiCqPvroIy1YsECu65qOAgAAACQlSpQoc2QrL5grhx81gCgqKSnRggULVFJSYjoKAAAAkLR4Zx9l2f4MZTjpjEIBEDWu6+rpp5/WX/7yF9NRAAAAgKRGiRJF2b4M5QdbUKAAiKpnnnlGc+fO5TIeAAAAIMooUaLEb/nUItBUjuWYjgIgiX3zzTe68847VVZWZjoKAAAAkPQoUaLAkqV2oTyl2iHTUQAkscrKSk2aNEmrV682HQUAAABoFChRoqCZP0vpTgqX8QCIGtd19eijj+rtt982HQUAAABoNChRGliuP1v5wRayLX60AKLDdV09+OCDKi4uVlVVlek4AAAAQKPhMx0gmVCgAIi2SCSihQsXqri4WJWVlabjAAAAAI0K7/YbSDN/FgUKgKj74x//SIECAAAAGMJIlAaQYofU3N+UAgVA1NTU1Gjt2rW65557KFAAAAAAQ3jXf4xy/dkqSG2nkB0wHQVAktp3Cc+gQYP06aefmo4DAAAANFqMRDkGzIECINpc19XChQt17bXXMgIFAAAAMIx3//VEgQIg2vZfhYcCBQAAADCPkSh15Ld8yvXnqEUghwIFQNT885//1AMPPKC7776bAgUAAACIE5QodRC0AmobOk7pTqosyzIdB0ASikQi+uqrr3TFFVdo1apVpuMAAAAA2A9DKTzK8WWqU1o7ChQAUeO6rv77v/9b/fr1o0ABAAAA4hAjUY7CkaO8YHPl+DPkWI7pOACS1I4dO/Tv//7vWrJkicrKykzHAQAAAHAIlChHkOmkq1WwuVLsIKNPAESF67p64YUXdMMNN+jjjz82HQcAAADAEXi+nCfTly5LjaNISLVDahdqpfYpeUp1QhQoQAw9//zzqqioMB0j6mpqavT+++/r0ksv1cSJEylQAAAAgATgeSTK8aHW2hOp1KbKf6oiUhXNTMY4stUq2Fw5/kz5uHQHMOKCCy7QySefrEcffVSFhYVynOT7W9y5c6euu+46LVmyRCUlJabjAAAAAPDI80gUy7KU5qToxNR2ahNsqZAdjGaumHLkKNefrYLU9sr1Z1OgAAZVV1dr9erVGjRokGbMmKH169erpqbGdKwG8eOPP+qBBx7QgAEDtGjRIgoUAAAAIMFYruu6XjZ89aNTav/bdV3VKKJd1bu1q7pMu6rLFFEkaiGjJdUOqak/S02cNIXsAJftIGmc0SNxV3b5+d9hZmamzjvvPA0fPlwjR45URkaGoWT1U1NTo7Vr1+pPf/qTXn31VW3YsCFpSiHA40uIuMRzPpA4ONcAiAWv55p6lSg/P9CeSIW+37tDe2oqVeXu9Z7SAEe2Qk5Quf5sZfkyZMvi5Iakk0wlyj6O46hXr16aPXu2evbsqY4dO8Y4Wd2UlJRo/fr1WrRokZ599lmVl5ebjgQ0ON7YAIgFzjUAYiFmJcr+B6x2a7QnUqkfwyUqr6nQXjfsKUS02bKU5qQq25ehNCdFKf+6FImTGpJVMpYo+8vNzdVJJ52kK6+8Ur169VLbtm1l256vTowK13VVUVGht956S08//bT+/ve/a926dQn9wg84mkT+/5vXAEDi4FwDIBZiXqL83N5IWBWRKu0I79JeN6zymgq5is0J0JIlv+VTupOiVCdFGU6aQixTjEYk2UuU/eXl5alr166aMGGC8vPz1a9fP/l8Pvl80V3B3XVdVVVVaevWrVq1apU+/PBDvfLKK/rss88UiSTe5Y1AffDGBkAscK4BEAvGS5T91bgRVbvVKq+pUHlNhardGu2q3v2/t9dzPhVbVu2yyyE7qDQnRY7lKMefIUe2/La/3pmBRNaYSpT9paWlqUWLFurTp4/69u2rpk2bauTIkbX7zczMrNf+y8rKFA7/NLLus88+0+rVq7Vz504tXrxYZWVl2rp1a70zA4mMNzYAYoFzDYBYiKsS5ef2XfojSa5c7awuVcQ9uEiJyFU4ElbQDhxyP018aQpaP91mW5YcVtUBJDXeEuXnfD6fcnJyJEmBQEAXXHCBUlJSDtouPT1deXl5+vzzzw+5n+XLl+vrr7+WJO3Zs0dlZWUNlhFIZLyxARALnGsAxEJclyhe7YvGyQeoG0qUuh/TcRxVV1fH/NhAIuONDYBY4FwDIBa8nmuiO2nAMeKkAyAWXNelQAEAAABwVGaXswAAAAAAAEgQlCgAAAAAAAAeUKIAAAAAAAB4QIkCAAAAAADgASUKAAAAAACAB5QoAAAAAAAAHlCiAAAAAAAAeECJAgAAAAAA4AElCgAAAAAAgAeUKAAAAAAAAB5QogAAAAAAAHhAiQIAAAAAAOABJQoAAAAAAIAHlCgAAAAAAAAeUKIAAAAAAAB4QIkCAAAAAADgASUKAAAAAACAB5QoAAAAAAAAHlCiAAAAAAAAeECJAgAAAAAA4AElCgAAAAAAgAeUKAAAAAAAAB5QogAAAAAAAHhAiQIAAAAAAOABJQoAAAAAAIAHlCgAAAAAAAAeUKIAAAAAAAB4QIkCAAAAAADgASUKAAAAAACAB5QoAAAAAAAAHlCiAAAAAAAAeECJAgAAAAAA4AElCgAAAAAAgAeUKAAAAAAAAB5QogAAAAAAAHhAiQIAAAAAAOABJQoAAAAAAIAHlCgJxpX0jd1CFQqajgIAAHDMioqKlJGRYToGAACeUKIkmAoF9X9CF2hFoK9c02EAAACOQWZmpp588knNmDFDlmWZjgMAwFFRoiQQV9L7/m76zs7Vm/5eKrXSTUcCAACotwsvvFCFhYWaNm2aWrRoYToOAABHRYmSQCoU0uv+fnItWzusTL3tP4nRKAAAICFlZWVp1qxZsm1bbdq00eWXX85oFABA3KNESRCupKdDw/WdnfvTNyxLfwkM0pdOW4oUAACQcO6++24VFhbW/nvBggUaOHCgwUQAABwdJUqC+NZuoTW+Qmm/T2iqrKD+5h8gV3xqAwAAEkf37t01ZsyYA76Xnp6u4uJi2TYvTwEA8YtnqQRQrpCeCQ5X5SFW5PnMd4K+ctoYSAUAAFB32dnZuvPOOw+5Is+ZZ56pAQMGGEgFAIA3lCgJYK2vsz532h8wCmWfsHxaGjxbu5hkFgAAJIBRo0bptNNOO+RtoVBI9913H5PMAgDiFiVKnNuj0E/LGVuH+VVZlrbYx2m1ryi2wQAAAOooKytLV1999REv2enRo4cmTJgQw1QAAHhHiRLHamRplb+nvrGP8mmMZenNQG+VWmmxCQYAAFBHjuNo8uTJKio68gc/lmVp6tSpat68eYySAQDgHSVKHNtmN9NfgqcqYjlH3fYHK1uvBE5RNb9SAAAQhzp27Kj58+fL5/Mdddvjjz9excXF8vv9MUgGAIB3vOOOUxFZWuHvoz1WqqftXcvWm/5e2my3inIyAACAurFtWzNmzFB2drbn7adNm6aePXtGORkAAHVDiRKHXEnf2C31ga9rne5XZQX1eqCfavi1AgCAONKjRw9deOGFdbpPenq6rr76ak8jVwAAiBXebcehsHxaEhqpMrvuc5ys852oL5x2cqOQCwAAoK5SUlK0cOFCNWvWrM73HTlypIYMGdLwoQAAqCdKlDjjSlrnK9BGO69e96+0QloaPEcVCjVsMAAAgHoYOXKkevfuXa/7ZmRk6N5771VWVlbDhgIAoJ4oUeLMXvn1t8CAwy9p7MF3dq7e93dlNAoAADAqLS1Nv/rVr464pPHRFBYWavz48Q2YCgCA+qNEiSOupBeCp2mjnX9sO7Isve7vp3KlNEguAACA+rj11lvVt2/fY97PrFmzlJOT0wCJAAA4NpQocWS7la13fT0kyzrmfX1n52pZaDijUQAAgBHHH3+8Jk6c2CD7Kiws1F133SWrAV4jAQBwLChR4kSV/FoWPEtlHpc0PirL0oe+Qn1jt2yY/QEAAHiUlpamO++8U7m5uQ22z/PPP19FRUUNtj8AAOqDEiVOfOY7Xut9JzbIKJR9qhTQ8kB/1YhPbQAAQOycccYZOueccxp0n02aNNHs2bPlOE6D7hcAgLqgRIkDe+XTcn8/VVu+ht2xZek9X1et9nVv2P0CAAAcRkpKiq655hoFAoEG3/eFF16oCRMmNPh+AQDwihLFMFfS3/099A+ndVT2X235tTzQTxUKRmX/AAAA+1iWpYkTJ2rAgAFR2X8oFNKsWbPUpEmTqOwfAICjoUQxbKeVqf8JDFG15Y/aMb61W+gjX2cmmQUAAFHVunVr3XDDDQoGo/fhTVFRkcaMGRO1/QMAcCSUKAa5klb5e6rEzojqcSKWo78ETtX3drOoHgcAADRuV155pfLz86N6DJ/Pp/nz56tTp05RPQ4AAIdCiWLQ93YzveM/KTbHcnL1ur+vIjE5GgAAaGw6deqkyy+/PCbHKigo0IwZM1jyGAAQc5QohlTL0dLgOdppZ8bsmB/4umqr3XBLDQIAAEhSIBDQvffeG/VRKPsbP368CgsLY3Y8AAAkShRjvnDa6f857WN6zDI7Ta8ETlGVojf/CgAAaHwGDx6s0047LabHzM3NVXFxsVJTU2N6XABA40aJYkCJ1USLQ+cqYuDH/66vh9b7Toz5cQEAQHJq1aqVHnroIfl8vpgfe9KkSRoxYkTMjwsAaLwoUWLMlfSO/yRtt7IlE9fxWpZeDQxQpQKxPzYAAEg6l156qdq3j+3o2n0sy9LcuXNZ8hgAEDOUKDFWaqXrTX8vMwXKv2y08/Sxr4AljwEAwDFp2bKlpk6danSC1z59+mjkyJFMMgsAiAlKlBiqlqNng8O004rdZLKH4lq2lgbP+Wk0DAAAQD0EAgHdfvvtatOmjdEctm3rvvvuU4cOHYzmAAA0DpQoMfQPp7XW+ArlxsEnJWVWqt4I9FFE5rMAAIDE079/f51//vlxMQKkWbNmmj59umybl7YAgOjimSZGamRpub+fqqyg6Sg/sSy96+uh7VaW6SQAACDBOI6ja665Runp6aaj1Jo0aZKxuVkAAI0HJUoMuJI+9HXVZ77jTUc5QJmVqidDoxSWYzoKAABIIGPHjtWwYcNMxzhAs2bN9PDDDysYjJMPrAAASYkSJQbKrFS9EDwtfkah7GNZ+sppo8+cE5hkFgAAeJKbm6tbb701rkah7DNw4ECdeeaZpmMAAJIYJUoMrPYVaZuVYzrGIVVbPr0aGKAaRqMAAAAPLrnkEnXs2NF0jEMKBoOaO3eu/H6/6SgAgCRFiRJl260svRHoY3RJ46P5ymmjvwUGMBoFAAAcUbt27XTVVVeZjnFEAwcO1Lx580zHAAAkKUqUKKqRreeCw7TNamo6yhHVWI7e8PfRDiaZBQAAh+Hz+XT77bfrxBNPNB3liPx+v6ZPn662bduajgIASEKUKFG02T5Oa32d4noUyj4lVoZW+XuajgEAAOLUySefrPPOO890DE/y8/N15ZVXmo4BAEhClChRUq6QngiNUlg+01G8sSy97T9JX9mtTScBAABxJisrS48++qhSUlJMR/Hsl7/8pfr162c6BgAgyVCiRIEr6QN/V221myfEKJR9dllN9D/BIdqbKMUPAACIifHjx6uwsNB0jDo57rjjdNNNNyVU8QMAiH+UKFFQoaBe9/dVxEqwH69l6QunvTY4XEMMAAB+kpmZqZkzZ8pxEm8lv6FDh+rUU081HQMAkEQS7F1+/IvI0gvB07XVzjUdpV6qLZ9eCwzQHoVMRwEAAIbZtq1bb71VnTt3Nh2lXoLBoObMmaOsrCzTUQAASYISpYF9Y7fQ3/1FchNtFMp+PnVO0BuB3ix5DABAI1dUVKSJEycm5CiUfc466yxdddVVshLoEmsAQPxK3Hf6cciVtCLQT3usVNNRjo1l6U1/b5Va6aaTAAAAg2bNmqXs7GzTMY6JZVmaOnWqWrRoYToKACAJUKI0oHXOiVrjS8zhrj+3w8rUkuBIRcSnNgAANEYjRozQmDFjTMdoEG3bttXChQtl27z0BQAcG55JGsgeBfVC8DRVWEkyA7xl6VPfCfrKac1lPQAANDKZmZm69dZblZmZaTpKgznrrLM0YMAA0zEAAAmOEqUBRCSt8XfRFvs401Ea1F4roFf9A+UyGgUAgEbDsiyNGTNGJ510kukoDSo1NVXz5s1jNAoA4JjwLNIAvrebaVnwLCkJJyz7xNdRK/29TccAAAAxUlBQoD/84Q9JORHr8OHDNXXqVNMxAAAJjBLlGEVkaYW/b9IuCVxt+bQ80E+lVprpKAAAIMocx9HVV1+dtEsCB4NBzZ49m0lmAQD1RolyjL63m+o9f1FSjkLZ5werqVb7ikzHAAAAUdaxY0dddNFFpmNEVceOHXXxxRebjgEASFCUKMdgr3x6IjQ6aUeh7ONallYE+uobm09tAABIVikpKfrjH/+Y8EsaH41lWZo5c6a6d+9uOgoAIAFRotSTK2mdr0Cb7FZJPQpln+1Wtv4aOFXV/C8DAEBSGjFihHr16mU6Rkx06NBB1157rfx+v+koAIAEwzvieqqWT68F+qvG8pmOEhuWpY99BdpstzKdBAAANLBQKKS5c+cqEAiYjhIz5557rk4++WTTMQAACYYSpR5cSS8HBmmjnWc6SkxVWUEtD/RXlfjUBgCAZLJgwQL17t24VuNr0qSJ5syZo7Q0Js8HAHhHiVIPP1g5WuXvqYjlmI4Scx/4umi1v7tc00EAAECDOOGEEzR58mT5fI1kdO1+xo4dq0suucR0DABAAqFEqYeVgd4qtdJNxzDCtWwt9/dTRZJPpgsAQGMxbdo0tWzZ0nQMI2zb1jXXXJO0SzoDABoeJUodfe6007u+7o1iMtnD+c7O1fv+roxGAQAgwQ0ZMkSTJk0yHcOowsJCjRs3znQMAECCoESpgyr59T+BISqzG+colFqWpf8bPFPfsuQxAAAJKy0tTTfeeKNyc3NNRzHujjvuUFFRkekYAIAEQInikSvpE19HfeW0NR0lLlQqqNcC/RVR4x2RAwBAorIsS8OHD9cpp5xiOkpcyMjI0OzZs2XbvDQGABwZzxQe7bQy9FTwHNU0wslkD8my9KGvi/5pNzedBAAA1FFeXp7uu+8++f2suLfPBRdcoG7dupmOAQCIc5QoHkQkrfL30i6riekocaVKAS0Onas9TDILAEDCsCxLU6ZM0XHHHWc6Slxp0qSJFi5cqMzMTNNRAABxjBLFgxIrQ2/5T27Uk8kekmVpo52ntb5OppMAAACP8vPz9ctf/lIWr2sO0qdPH40ePdp0DABAHKNEOYoaWXoydB6jUA4jYjl6PdBPlQqYjgIAAI7CcRwtWrRIrVq1Mh0lLvl8Ps2aNUvp6Y18EQEAwGFRohyBK+kLp72+cNozCuUIvrFb6G+BgUwyCwBAnBsyZIiGDh1qOkZcKyoq0rx585hkFgBwSDw7HEFEtv4WGKiwxaRrRxKxHL3h76OtdjPTUQAAwGH4fD7NmzdPoRBzmR2Jz+fTjBkz1KkTlysDAA5GiXIEy/399LnTwXSMhFBmp2mlv49c00EAAMAhXXPNNTr99NNNx0gIzZo101VXXcW8MQCAg1CiHMZOq4lWBPqypHEdvO/rqq+cNhQpAADEmby8PM2YMYMljevgwgsv1MCBA03HAADEGUqUQwjL0WuBAfrRyjIdJaGU2WlaFjxLe8ULNAAA4kUgENCcOXPUrl0701ESSrNmzXTHHXcoLS3NdBQAQByhRDmEjU6+Vvj7MplsPXxt52u970TTMQAAwL/06dNHM2fO5NKUeujbt6/OOecc0zEAAHGEEuVnwnL0mr+/qi2f6SiJybL0WqC/ysWkdQAAmBYMBjVnzhwFg0HTURKSZVmaM2eOsrKyTEcBAMQJSpT9uJI2OO30qe8E01ES2j/s1no5OJi5UQAAMGzQoEEaPny46RgJrX///rr++usZyQMAkESJcoBypejPoRHaawVMR0lslqV3fT203co2nQQAgEYrJydHDz74oFJTU01HSXiTJk1S+/btTccAAMQBSpR/cSWt9nfXNqup6ShJocxK1RuB3oqIT20AADBhwoQJOuEERtc2hNzcXF111VWybV46A0BjxzPBv5RbqVoR6MNksg3FsrTS30frnRO5rAcAgBhr2rQpk8k2sOnTp2vEiBGmYwAADKNE0U+jUJ4KnsMolAa21wro1UB/1cgxHQUAgEbl/vvvV8eOHU3HSCqpqamaM2eOAgEu+waAxowSRdImu5U+9nViFEoU/MNpo0+d4xmNAgBAjPTq1Uvnnnuu6RhJacCAARo2bJjpGAAAgxp9iRKRpVcDA1Qlv+koSana8um54DDtsDJNRwEAIOnZtq1f/epXSk9PNx0lKQWDQd12221q06aN6SgAAEMafYnytv8kfeTrzCiUKPqn00Jv+XsyGgUAgCi74oorNHr0aNMxklq3bt105ZVXmo4BADCkUZcoZUrRcn9/VVuMQom2t/0nMRoFAIAoysnJ0axZsxQKhUxHSXqXX3652rZtazoGAMCARlui1MjWG4E+2mrnmo7SKJRYGXolcIrC8pmOAgBA0vH5fJoxY4YKCwtNR2kU8vPzde2111JYAUAj1GhLlH/aufpbYKAiVqP9EcSWZWmVv5c2OHxqAwBAQ+vSpYvmzZsnx2FFvFiZPHmyTj31VNMxAAAx1igbhBpZWuHvq0qLTw9iqcZy9Fqgv/YyGgUAgAbjOI5mzpypjIwM01EaFb/fr9mzZyslJcV0FABADDXKd7Pb7Kb6wtdeqe4e01EanW/sltrk5KljzSbTUQAASAodO3bUkCFDtGPHDtNRGp0ePXqoZ8+eWrVqlekoAIAYsVzX9bRoyqsfnRLtLDETlk+VVsB0jEYr4IYVVNh0jKR2Ro/EfTFnsVIWkDA8voSIS8l0rgkGg4xCMai8vFx79vDBXDRxrgEQC17PNY1yJIpf1fK71aZjAAAAHLOqqir98MMPpmMAANAoNMo5UQAAAAAAAOqKEgUAAAAAAMADShQAAAAAAAAPKFEAAAAAAAA8oEQBAAAAAADwgBIFAAAAAADAA0oUAAAAAAAADyhRAAAAAAAAPKBEAQAAAAAA8IASBQAAAAAAwAPLdV3XdAgAAAAAAIB4x0gUAAAAAAAADyhRAAAAAAAAPKBEAQAAAAAA8IASBQAAAAAAwANKFAAAAAAAAA8oUQAAAAAAADygRAEAAAAAAPCAEgUAAAAAAMADShQAAAAAAAAP/j+fmH6NM4EOPAAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 1400x700 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load and display random samples\n",
    "image_ids = np.random.choice(dataset_train.image_ids, 5)\n",
    "for image_id in image_ids:\n",
    "    image = dataset_train.load_image(image_id)\n",
    "    cv2.imwrite(f\"./shape_test_images/shape_test_image_{image_id}.png\", image)\n",
    "    mask, class_ids = dataset_train.load_mask(image_id)\n",
    "    visualize.display_top_masks(image, mask, class_ids, dataset_train.class_names, limit=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Model and Load Trained Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "sometimes = lambda aug: iaa.Sometimes(0.5, aug)\n",
    "\n",
    "augmentation = iaa.Sequential([\n",
    "                                iaa.Fliplr(0.5), \n",
    "                                iaa.Flipud(0.5),\n",
    "                                #sometimes(iaa.Crop(percent=(0, 0.1))),\n",
    "                                sometimes(iaa.Affine(\n",
    "                                            #scale={\"x\": (0.8, 1.2), \"y\": (0.8, 1.2)},\n",
    "                                            #translate_percent={\"x\": (-0.2, 0.2), \"y\": (-0.2, 0.2)},\n",
    "                                            rotate=(-45, 45),\n",
    "                                            #shear=(-16, 16),\n",
    "                                            #order=[0, 1],\n",
    "                                            #cval=(0, 255),\n",
    "                                            #mode=ia.ALL\n",
    "                                            )\n",
    "                                        ),\n",
    "                            ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "dir_model = os.path.join(dir_root, \"logs/\")\n",
    "\n",
    "#COCO_MODEL_PATH = os.path.join(dir_root, \"shoes/mask_rcnn_coco.h5\")    \n",
    "#if not os.path.exists(COCO_MODEL_PATH):\n",
    "#    utils.download_trained_weights(COCO_MODEL_PATH)\n",
    "    \n",
    "# Create model object in inference mode.\n",
    "model = modellib.MaskRCNN(mode=\"training\", config=config, model_dir=dir_model)\n",
    "\n",
    "# Load weights trained on MS-COCO\n",
    "#model.load_weights(COCO_MOD\n",
    "# EL_PATH, by_name=True, exclude=[\"mrcnn_class_logits\", \"mrcnn_bbox_fc\", \"mrcnn_bbox\", \"mrcnn_mask\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "EPOCHS = [1,100,500]\n",
    "initial_learning_rate = 1e-3\n",
    "warmup_epochs = 10\n",
    "\n",
    "\n",
    "def lr_warmup(epoch, initial_learning_rate, warmup_epochs):\n",
    "    if epoch < warmup_epochs:\n",
    "        warmup_lr = initial_learning_rate * (epoch + 1) / (warmup_epochs)\n",
    "        return warmup_lr\n",
    "    return None  # Use None to indicate that the reduced learning rate should be used\n",
    "\n",
    "\n",
    "class WarmupSchedulerWithReduceLROnPlateau(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, initial_learning_rate, warmup_epochs, reduce_lr_on_plateau):\n",
    "        super(WarmupSchedulerWithReduceLROnPlateau, self).__init__()\n",
    "        self.initial_learning_rate = initial_learning_rate\n",
    "        self.warmup_epochs = warmup_epochs\n",
    "        self.reduce_lr_on_plateau = reduce_lr_on_plateau\n",
    "\n",
    "    def on_epoch_begin(self, epoch, logs=None):\n",
    "        new_lr = lr_warmup(epoch, self.initial_learning_rate, self.warmup_epochs)\n",
    "        if new_lr is not None:\n",
    "            tf.keras.backend.set_value(self.model.optimizer.lr, new_lr)\n",
    "            print(f\"Epoch {epoch+1}: Learning rate is {new_lr:.6f} (warmup phase).\")\n",
    "        else:\n",
    "            # Delegate to ReduceLROnPlateau's functionality\n",
    "            self.reduce_lr_on_plateau.on_epoch_begin(epoch, logs)\n",
    "\n",
    "\n",
    "reduce_lr_on_plateau  = tf.keras.callbacks.ReduceLROnPlateau(monitor=\"val_loss\", factor=0.1, patience=10, min_lr=1e-8)\n",
    "warmup_with_reduce_lr_callback = WarmupSchedulerWithReduceLROnPlateau(initial_learning_rate, warmup_epochs, reduce_lr_on_plateau)\n",
    "stop_early = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=50)\n",
    "\n",
    "csv_logger_head = tf.keras.callbacks.CSVLogger(filename=config.NAME + \"_training.log\", append=False)\n",
    "csv_logger_all = tf.keras.callbacks.CSVLogger(filename=config.NAME + \"_training.log\", append=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'60_shapes_resnet_training.log'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename=config.NAME + \"_training.log\"\n",
    "filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selecting layers to train\n",
      "Model: \"mask_rcnn\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_image (InputLayer)    [(None, None, None, 3)]      0         []                            \n",
      "                                                                                                  \n",
      " zero_padding2d_1 (ZeroPadd  (None, None, None, 3)        0         ['input_image[0][0]']         \n",
      " ing2D)                                                                                           \n",
      "                                                                                                  \n",
      " conv1 (Conv2D)              (None, None, None, 64)       9472      ['zero_padding2d_1[0][0]']    \n",
      "                                                                                                  \n",
      " bn_conv1 (BatchNorm)        (None, None, None, 64)       256       ['conv1[0][0]']               \n",
      "                                                                                                  \n",
      " activation_17 (Activation)  (None, None, None, 64)       0         ['bn_conv1[0][0]']            \n",
      "                                                                                                  \n",
      " max_pooling2d_1 (MaxPoolin  (None, None, None, 64)       0         ['activation_17[0][0]']       \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " res2a_branch2a (Conv2D)     (None, None, None, 64)       4160      ['max_pooling2d_1[0][0]']     \n",
      "                                                                                                  \n",
      " bn2a_branch2a (BatchNorm)   (None, None, None, 64)       256       ['res2a_branch2a[0][0]']      \n",
      "                                                                                                  \n",
      " activation_18 (Activation)  (None, None, None, 64)       0         ['bn2a_branch2a[0][0]']       \n",
      "                                                                                                  \n",
      " res2a_branch2b (Conv2D)     (None, None, None, 64)       36928     ['activation_18[0][0]']       \n",
      "                                                                                                  \n",
      " bn2a_branch2b (BatchNorm)   (None, None, None, 64)       256       ['res2a_branch2b[0][0]']      \n",
      "                                                                                                  \n",
      " activation_19 (Activation)  (None, None, None, 64)       0         ['bn2a_branch2b[0][0]']       \n",
      "                                                                                                  \n",
      " res2a_branch2c (Conv2D)     (None, None, None, 256)      16640     ['activation_19[0][0]']       \n",
      "                                                                                                  \n",
      " res2a_branch1 (Conv2D)      (None, None, None, 256)      16640     ['max_pooling2d_1[0][0]']     \n",
      "                                                                                                  \n",
      " bn2a_branch2c (BatchNorm)   (None, None, None, 256)      1024      ['res2a_branch2c[0][0]']      \n",
      "                                                                                                  \n",
      " bn2a_branch1 (BatchNorm)    (None, None, None, 256)      1024      ['res2a_branch1[0][0]']       \n",
      "                                                                                                  \n",
      " add_7 (Add)                 (None, None, None, 256)      0         ['bn2a_branch2c[0][0]',       \n",
      "                                                                     'bn2a_branch1[0][0]']        \n",
      "                                                                                                  \n",
      " res2a_out (Activation)      (None, None, None, 256)      0         ['add_7[0][0]']               \n",
      "                                                                                                  \n",
      " res2b_branch2a (Conv2D)     (None, None, None, 64)       16448     ['res2a_out[0][0]']           \n",
      "                                                                                                  \n",
      " bn2b_branch2a (BatchNorm)   (None, None, None, 64)       256       ['res2b_branch2a[0][0]']      \n",
      "                                                                                                  \n",
      " activation_20 (Activation)  (None, None, None, 64)       0         ['bn2b_branch2a[0][0]']       \n",
      "                                                                                                  \n",
      " res2b_branch2b (Conv2D)     (None, None, None, 64)       36928     ['activation_20[0][0]']       \n",
      "                                                                                                  \n",
      " bn2b_branch2b (BatchNorm)   (None, None, None, 64)       256       ['res2b_branch2b[0][0]']      \n",
      "                                                                                                  \n",
      " activation_21 (Activation)  (None, None, None, 64)       0         ['bn2b_branch2b[0][0]']       \n",
      "                                                                                                  \n",
      " res2b_branch2c (Conv2D)     (None, None, None, 256)      16640     ['activation_21[0][0]']       \n",
      "                                                                                                  \n",
      " bn2b_branch2c (BatchNorm)   (None, None, None, 256)      1024      ['res2b_branch2c[0][0]']      \n",
      "                                                                                                  \n",
      " add_8 (Add)                 (None, None, None, 256)      0         ['bn2b_branch2c[0][0]',       \n",
      "                                                                     'res2a_out[0][0]']           \n",
      "                                                                                                  \n",
      " res2b_out (Activation)      (None, None, None, 256)      0         ['add_8[0][0]']               \n",
      "                                                                                                  \n",
      " res2c_branch2a (Conv2D)     (None, None, None, 64)       16448     ['res2b_out[0][0]']           \n",
      "                                                                                                  \n",
      " bn2c_branch2a (BatchNorm)   (None, None, None, 64)       256       ['res2c_branch2a[0][0]']      \n",
      "                                                                                                  \n",
      " activation_22 (Activation)  (None, None, None, 64)       0         ['bn2c_branch2a[0][0]']       \n",
      "                                                                                                  \n",
      " res2c_branch2b (Conv2D)     (None, None, None, 64)       36928     ['activation_22[0][0]']       \n",
      "                                                                                                  \n",
      " bn2c_branch2b (BatchNorm)   (None, None, None, 64)       256       ['res2c_branch2b[0][0]']      \n",
      "                                                                                                  \n",
      " activation_23 (Activation)  (None, None, None, 64)       0         ['bn2c_branch2b[0][0]']       \n",
      "                                                                                                  \n",
      " res2c_branch2c (Conv2D)     (None, None, None, 256)      16640     ['activation_23[0][0]']       \n",
      "                                                                                                  \n",
      " bn2c_branch2c (BatchNorm)   (None, None, None, 256)      1024      ['res2c_branch2c[0][0]']      \n",
      "                                                                                                  \n",
      " add_9 (Add)                 (None, None, None, 256)      0         ['bn2c_branch2c[0][0]',       \n",
      "                                                                     'res2b_out[0][0]']           \n",
      "                                                                                                  \n",
      " res2c_out (Activation)      (None, None, None, 256)      0         ['add_9[0][0]']               \n",
      "                                                                                                  \n",
      " res3a_branch2a (Conv2D)     (None, None, None, 128)      32896     ['res2c_out[0][0]']           \n",
      "                                                                                                  \n",
      " bn3a_branch2a (BatchNorm)   (None, None, None, 128)      512       ['res3a_branch2a[0][0]']      \n",
      "                                                                                                  \n",
      " activation_24 (Activation)  (None, None, None, 128)      0         ['bn3a_branch2a[0][0]']       \n",
      "                                                                                                  \n",
      " res3a_branch2b (Conv2D)     (None, None, None, 128)      147584    ['activation_24[0][0]']       \n",
      "                                                                                                  \n",
      " bn3a_branch2b (BatchNorm)   (None, None, None, 128)      512       ['res3a_branch2b[0][0]']      \n",
      "                                                                                                  \n",
      " activation_25 (Activation)  (None, None, None, 128)      0         ['bn3a_branch2b[0][0]']       \n",
      "                                                                                                  \n",
      " res3a_branch2c (Conv2D)     (None, None, None, 512)      66048     ['activation_25[0][0]']       \n",
      "                                                                                                  \n",
      " res3a_branch1 (Conv2D)      (None, None, None, 512)      131584    ['res2c_out[0][0]']           \n",
      "                                                                                                  \n",
      " bn3a_branch2c (BatchNorm)   (None, None, None, 512)      2048      ['res3a_branch2c[0][0]']      \n",
      "                                                                                                  \n",
      " bn3a_branch1 (BatchNorm)    (None, None, None, 512)      2048      ['res3a_branch1[0][0]']       \n",
      "                                                                                                  \n",
      " add_10 (Add)                (None, None, None, 512)      0         ['bn3a_branch2c[0][0]',       \n",
      "                                                                     'bn3a_branch1[0][0]']        \n",
      "                                                                                                  \n",
      " res3a_out (Activation)      (None, None, None, 512)      0         ['add_10[0][0]']              \n",
      "                                                                                                  \n",
      " res3b_branch2a (Conv2D)     (None, None, None, 128)      65664     ['res3a_out[0][0]']           \n",
      "                                                                                                  \n",
      " bn3b_branch2a (BatchNorm)   (None, None, None, 128)      512       ['res3b_branch2a[0][0]']      \n",
      "                                                                                                  \n",
      " activation_26 (Activation)  (None, None, None, 128)      0         ['bn3b_branch2a[0][0]']       \n",
      "                                                                                                  \n",
      " res3b_branch2b (Conv2D)     (None, None, None, 128)      147584    ['activation_26[0][0]']       \n",
      "                                                                                                  \n",
      " bn3b_branch2b (BatchNorm)   (None, None, None, 128)      512       ['res3b_branch2b[0][0]']      \n",
      "                                                                                                  \n",
      " activation_27 (Activation)  (None, None, None, 128)      0         ['bn3b_branch2b[0][0]']       \n",
      "                                                                                                  \n",
      " res3b_branch2c (Conv2D)     (None, None, None, 512)      66048     ['activation_27[0][0]']       \n",
      "                                                                                                  \n",
      " bn3b_branch2c (BatchNorm)   (None, None, None, 512)      2048      ['res3b_branch2c[0][0]']      \n",
      "                                                                                                  \n",
      " add_11 (Add)                (None, None, None, 512)      0         ['bn3b_branch2c[0][0]',       \n",
      "                                                                     'res3a_out[0][0]']           \n",
      "                                                                                                  \n",
      " res3b_out (Activation)      (None, None, None, 512)      0         ['add_11[0][0]']              \n",
      "                                                                                                  \n",
      " res3c_branch2a (Conv2D)     (None, None, None, 128)      65664     ['res3b_out[0][0]']           \n",
      "                                                                                                  \n",
      " bn3c_branch2a (BatchNorm)   (None, None, None, 128)      512       ['res3c_branch2a[0][0]']      \n",
      "                                                                                                  \n",
      " activation_28 (Activation)  (None, None, None, 128)      0         ['bn3c_branch2a[0][0]']       \n",
      "                                                                                                  \n",
      " res3c_branch2b (Conv2D)     (None, None, None, 128)      147584    ['activation_28[0][0]']       \n",
      "                                                                                                  \n",
      " bn3c_branch2b (BatchNorm)   (None, None, None, 128)      512       ['res3c_branch2b[0][0]']      \n",
      "                                                                                                  \n",
      " activation_29 (Activation)  (None, None, None, 128)      0         ['bn3c_branch2b[0][0]']       \n",
      "                                                                                                  \n",
      " res3c_branch2c (Conv2D)     (None, None, None, 512)      66048     ['activation_29[0][0]']       \n",
      "                                                                                                  \n",
      " bn3c_branch2c (BatchNorm)   (None, None, None, 512)      2048      ['res3c_branch2c[0][0]']      \n",
      "                                                                                                  \n",
      " add_12 (Add)                (None, None, None, 512)      0         ['bn3c_branch2c[0][0]',       \n",
      "                                                                     'res3b_out[0][0]']           \n",
      "                                                                                                  \n",
      " res3c_out (Activation)      (None, None, None, 512)      0         ['add_12[0][0]']              \n",
      "                                                                                                  \n",
      " res3d_branch2a (Conv2D)     (None, None, None, 128)      65664     ['res3c_out[0][0]']           \n",
      "                                                                                                  \n",
      " bn3d_branch2a (BatchNorm)   (None, None, None, 128)      512       ['res3d_branch2a[0][0]']      \n",
      "                                                                                                  \n",
      " activation_30 (Activation)  (None, None, None, 128)      0         ['bn3d_branch2a[0][0]']       \n",
      "                                                                                                  \n",
      " res3d_branch2b (Conv2D)     (None, None, None, 128)      147584    ['activation_30[0][0]']       \n",
      "                                                                                                  \n",
      " bn3d_branch2b (BatchNorm)   (None, None, None, 128)      512       ['res3d_branch2b[0][0]']      \n",
      "                                                                                                  \n",
      " activation_31 (Activation)  (None, None, None, 128)      0         ['bn3d_branch2b[0][0]']       \n",
      "                                                                                                  \n",
      " res3d_branch2c (Conv2D)     (None, None, None, 512)      66048     ['activation_31[0][0]']       \n",
      "                                                                                                  \n",
      " bn3d_branch2c (BatchNorm)   (None, None, None, 512)      2048      ['res3d_branch2c[0][0]']      \n",
      "                                                                                                  \n",
      " add_13 (Add)                (None, None, None, 512)      0         ['bn3d_branch2c[0][0]',       \n",
      "                                                                     'res3c_out[0][0]']           \n",
      "                                                                                                  \n",
      " res3d_out (Activation)      (None, None, None, 512)      0         ['add_13[0][0]']              \n",
      "                                                                                                  \n",
      " res4a_branch2a (Conv2D)     (None, None, None, 256)      131328    ['res3d_out[0][0]']           \n",
      "                                                                                                  \n",
      " bn4a_branch2a (BatchNorm)   (None, None, None, 256)      1024      ['res4a_branch2a[0][0]']      \n",
      "                                                                                                  \n",
      " activation_32 (Activation)  (None, None, None, 256)      0         ['bn4a_branch2a[0][0]']       \n",
      "                                                                                                  \n",
      " res4a_branch2b (Conv2D)     (None, None, None, 256)      590080    ['activation_32[0][0]']       \n",
      "                                                                                                  \n",
      " bn4a_branch2b (BatchNorm)   (None, None, None, 256)      1024      ['res4a_branch2b[0][0]']      \n",
      "                                                                                                  \n",
      " activation_33 (Activation)  (None, None, None, 256)      0         ['bn4a_branch2b[0][0]']       \n",
      "                                                                                                  \n",
      " res4a_branch2c (Conv2D)     (None, None, None, 1024)     263168    ['activation_33[0][0]']       \n",
      "                                                                                                  \n",
      " res4a_branch1 (Conv2D)      (None, None, None, 1024)     525312    ['res3d_out[0][0]']           \n",
      "                                                                                                  \n",
      " bn4a_branch2c (BatchNorm)   (None, None, None, 1024)     4096      ['res4a_branch2c[0][0]']      \n",
      "                                                                                                  \n",
      " bn4a_branch1 (BatchNorm)    (None, None, None, 1024)     4096      ['res4a_branch1[0][0]']       \n",
      "                                                                                                  \n",
      " add_14 (Add)                (None, None, None, 1024)     0         ['bn4a_branch2c[0][0]',       \n",
      "                                                                     'bn4a_branch1[0][0]']        \n",
      "                                                                                                  \n",
      " res4a_out (Activation)      (None, None, None, 1024)     0         ['add_14[0][0]']              \n",
      "                                                                                                  \n",
      " res4b_branch2a (Conv2D)     (None, None, None, 256)      262400    ['res4a_out[0][0]']           \n",
      "                                                                                                  \n",
      " bn4b_branch2a (BatchNorm)   (None, None, None, 256)      1024      ['res4b_branch2a[0][0]']      \n",
      "                                                                                                  \n",
      " activation_34 (Activation)  (None, None, None, 256)      0         ['bn4b_branch2a[0][0]']       \n",
      "                                                                                                  \n",
      " res4b_branch2b (Conv2D)     (None, None, None, 256)      590080    ['activation_34[0][0]']       \n",
      "                                                                                                  \n",
      " bn4b_branch2b (BatchNorm)   (None, None, None, 256)      1024      ['res4b_branch2b[0][0]']      \n",
      "                                                                                                  \n",
      " activation_35 (Activation)  (None, None, None, 256)      0         ['bn4b_branch2b[0][0]']       \n",
      "                                                                                                  \n",
      " res4b_branch2c (Conv2D)     (None, None, None, 1024)     263168    ['activation_35[0][0]']       \n",
      "                                                                                                  \n",
      " bn4b_branch2c (BatchNorm)   (None, None, None, 1024)     4096      ['res4b_branch2c[0][0]']      \n",
      "                                                                                                  \n",
      " add_15 (Add)                (None, None, None, 1024)     0         ['bn4b_branch2c[0][0]',       \n",
      "                                                                     'res4a_out[0][0]']           \n",
      "                                                                                                  \n",
      " res4b_out (Activation)      (None, None, None, 1024)     0         ['add_15[0][0]']              \n",
      "                                                                                                  \n",
      " res4c_branch2a (Conv2D)     (None, None, None, 256)      262400    ['res4b_out[0][0]']           \n",
      "                                                                                                  \n",
      " bn4c_branch2a (BatchNorm)   (None, None, None, 256)      1024      ['res4c_branch2a[0][0]']      \n",
      "                                                                                                  \n",
      " activation_36 (Activation)  (None, None, None, 256)      0         ['bn4c_branch2a[0][0]']       \n",
      "                                                                                                  \n",
      " res4c_branch2b (Conv2D)     (None, None, None, 256)      590080    ['activation_36[0][0]']       \n",
      "                                                                                                  \n",
      " bn4c_branch2b (BatchNorm)   (None, None, None, 256)      1024      ['res4c_branch2b[0][0]']      \n",
      "                                                                                                  \n",
      " activation_37 (Activation)  (None, None, None, 256)      0         ['bn4c_branch2b[0][0]']       \n",
      "                                                                                                  \n",
      " res4c_branch2c (Conv2D)     (None, None, None, 1024)     263168    ['activation_37[0][0]']       \n",
      "                                                                                                  \n",
      " bn4c_branch2c (BatchNorm)   (None, None, None, 1024)     4096      ['res4c_branch2c[0][0]']      \n",
      "                                                                                                  \n",
      " add_16 (Add)                (None, None, None, 1024)     0         ['bn4c_branch2c[0][0]',       \n",
      "                                                                     'res4b_out[0][0]']           \n",
      "                                                                                                  \n",
      " res4c_out (Activation)      (None, None, None, 1024)     0         ['add_16[0][0]']              \n",
      "                                                                                                  \n",
      " res4d_branch2a (Conv2D)     (None, None, None, 256)      262400    ['res4c_out[0][0]']           \n",
      "                                                                                                  \n",
      " bn4d_branch2a (BatchNorm)   (None, None, None, 256)      1024      ['res4d_branch2a[0][0]']      \n",
      "                                                                                                  \n",
      " activation_38 (Activation)  (None, None, None, 256)      0         ['bn4d_branch2a[0][0]']       \n",
      "                                                                                                  \n",
      " res4d_branch2b (Conv2D)     (None, None, None, 256)      590080    ['activation_38[0][0]']       \n",
      "                                                                                                  \n",
      " bn4d_branch2b (BatchNorm)   (None, None, None, 256)      1024      ['res4d_branch2b[0][0]']      \n",
      "                                                                                                  \n",
      " activation_39 (Activation)  (None, None, None, 256)      0         ['bn4d_branch2b[0][0]']       \n",
      "                                                                                                  \n",
      " res4d_branch2c (Conv2D)     (None, None, None, 1024)     263168    ['activation_39[0][0]']       \n",
      "                                                                                                  \n",
      " bn4d_branch2c (BatchNorm)   (None, None, None, 1024)     4096      ['res4d_branch2c[0][0]']      \n",
      "                                                                                                  \n",
      " add_17 (Add)                (None, None, None, 1024)     0         ['bn4d_branch2c[0][0]',       \n",
      "                                                                     'res4c_out[0][0]']           \n",
      "                                                                                                  \n",
      " res4d_out (Activation)      (None, None, None, 1024)     0         ['add_17[0][0]']              \n",
      "                                                                                                  \n",
      " res4e_branch2a (Conv2D)     (None, None, None, 256)      262400    ['res4d_out[0][0]']           \n",
      "                                                                                                  \n",
      " bn4e_branch2a (BatchNorm)   (None, None, None, 256)      1024      ['res4e_branch2a[0][0]']      \n",
      "                                                                                                  \n",
      " activation_40 (Activation)  (None, None, None, 256)      0         ['bn4e_branch2a[0][0]']       \n",
      "                                                                                                  \n",
      " res4e_branch2b (Conv2D)     (None, None, None, 256)      590080    ['activation_40[0][0]']       \n",
      "                                                                                                  \n",
      " bn4e_branch2b (BatchNorm)   (None, None, None, 256)      1024      ['res4e_branch2b[0][0]']      \n",
      "                                                                                                  \n",
      " activation_41 (Activation)  (None, None, None, 256)      0         ['bn4e_branch2b[0][0]']       \n",
      "                                                                                                  \n",
      " res4e_branch2c (Conv2D)     (None, None, None, 1024)     263168    ['activation_41[0][0]']       \n",
      "                                                                                                  \n",
      " bn4e_branch2c (BatchNorm)   (None, None, None, 1024)     4096      ['res4e_branch2c[0][0]']      \n",
      "                                                                                                  \n",
      " add_18 (Add)                (None, None, None, 1024)     0         ['bn4e_branch2c[0][0]',       \n",
      "                                                                     'res4d_out[0][0]']           \n",
      "                                                                                                  \n",
      " res4e_out (Activation)      (None, None, None, 1024)     0         ['add_18[0][0]']              \n",
      "                                                                                                  \n",
      " res4f_branch2a (Conv2D)     (None, None, None, 256)      262400    ['res4e_out[0][0]']           \n",
      "                                                                                                  \n",
      " bn4f_branch2a (BatchNorm)   (None, None, None, 256)      1024      ['res4f_branch2a[0][0]']      \n",
      "                                                                                                  \n",
      " activation_42 (Activation)  (None, None, None, 256)      0         ['bn4f_branch2a[0][0]']       \n",
      "                                                                                                  \n",
      " res4f_branch2b (Conv2D)     (None, None, None, 256)      590080    ['activation_42[0][0]']       \n",
      "                                                                                                  \n",
      " bn4f_branch2b (BatchNorm)   (None, None, None, 256)      1024      ['res4f_branch2b[0][0]']      \n",
      "                                                                                                  \n",
      " activation_43 (Activation)  (None, None, None, 256)      0         ['bn4f_branch2b[0][0]']       \n",
      "                                                                                                  \n",
      " res4f_branch2c (Conv2D)     (None, None, None, 1024)     263168    ['activation_43[0][0]']       \n",
      "                                                                                                  \n",
      " bn4f_branch2c (BatchNorm)   (None, None, None, 1024)     4096      ['res4f_branch2c[0][0]']      \n",
      "                                                                                                  \n",
      " add_19 (Add)                (None, None, None, 1024)     0         ['bn4f_branch2c[0][0]',       \n",
      "                                                                     'res4e_out[0][0]']           \n",
      "                                                                                                  \n",
      " res4f_out (Activation)      (None, None, None, 1024)     0         ['add_19[0][0]']              \n",
      "                                                                                                  \n",
      " res4g_branch2a (Conv2D)     (None, None, None, 256)      262400    ['res4f_out[0][0]']           \n",
      "                                                                                                  \n",
      " bn4g_branch2a (BatchNorm)   (None, None, None, 256)      1024      ['res4g_branch2a[0][0]']      \n",
      "                                                                                                  \n",
      " activation_44 (Activation)  (None, None, None, 256)      0         ['bn4g_branch2a[0][0]']       \n",
      "                                                                                                  \n",
      " res4g_branch2b (Conv2D)     (None, None, None, 256)      590080    ['activation_44[0][0]']       \n",
      "                                                                                                  \n",
      " bn4g_branch2b (BatchNorm)   (None, None, None, 256)      1024      ['res4g_branch2b[0][0]']      \n",
      "                                                                                                  \n",
      " activation_45 (Activation)  (None, None, None, 256)      0         ['bn4g_branch2b[0][0]']       \n",
      "                                                                                                  \n",
      " res4g_branch2c (Conv2D)     (None, None, None, 1024)     263168    ['activation_45[0][0]']       \n",
      "                                                                                                  \n",
      " bn4g_branch2c (BatchNorm)   (None, None, None, 1024)     4096      ['res4g_branch2c[0][0]']      \n",
      "                                                                                                  \n",
      " add_20 (Add)                (None, None, None, 1024)     0         ['bn4g_branch2c[0][0]',       \n",
      "                                                                     'res4f_out[0][0]']           \n",
      "                                                                                                  \n",
      " res4g_out (Activation)      (None, None, None, 1024)     0         ['add_20[0][0]']              \n",
      "                                                                                                  \n",
      " res4h_branch2a (Conv2D)     (None, None, None, 256)      262400    ['res4g_out[0][0]']           \n",
      "                                                                                                  \n",
      " bn4h_branch2a (BatchNorm)   (None, None, None, 256)      1024      ['res4h_branch2a[0][0]']      \n",
      "                                                                                                  \n",
      " activation_46 (Activation)  (None, None, None, 256)      0         ['bn4h_branch2a[0][0]']       \n",
      "                                                                                                  \n",
      " res4h_branch2b (Conv2D)     (None, None, None, 256)      590080    ['activation_46[0][0]']       \n",
      "                                                                                                  \n",
      " bn4h_branch2b (BatchNorm)   (None, None, None, 256)      1024      ['res4h_branch2b[0][0]']      \n",
      "                                                                                                  \n",
      " activation_47 (Activation)  (None, None, None, 256)      0         ['bn4h_branch2b[0][0]']       \n",
      "                                                                                                  \n",
      " res4h_branch2c (Conv2D)     (None, None, None, 1024)     263168    ['activation_47[0][0]']       \n",
      "                                                                                                  \n",
      " bn4h_branch2c (BatchNorm)   (None, None, None, 1024)     4096      ['res4h_branch2c[0][0]']      \n",
      "                                                                                                  \n",
      " add_21 (Add)                (None, None, None, 1024)     0         ['bn4h_branch2c[0][0]',       \n",
      "                                                                     'res4g_out[0][0]']           \n",
      "                                                                                                  \n",
      " res4h_out (Activation)      (None, None, None, 1024)     0         ['add_21[0][0]']              \n",
      "                                                                                                  \n",
      " res4i_branch2a (Conv2D)     (None, None, None, 256)      262400    ['res4h_out[0][0]']           \n",
      "                                                                                                  \n",
      " bn4i_branch2a (BatchNorm)   (None, None, None, 256)      1024      ['res4i_branch2a[0][0]']      \n",
      "                                                                                                  \n",
      " activation_48 (Activation)  (None, None, None, 256)      0         ['bn4i_branch2a[0][0]']       \n",
      "                                                                                                  \n",
      " res4i_branch2b (Conv2D)     (None, None, None, 256)      590080    ['activation_48[0][0]']       \n",
      "                                                                                                  \n",
      " bn4i_branch2b (BatchNorm)   (None, None, None, 256)      1024      ['res4i_branch2b[0][0]']      \n",
      "                                                                                                  \n",
      " activation_49 (Activation)  (None, None, None, 256)      0         ['bn4i_branch2b[0][0]']       \n",
      "                                                                                                  \n",
      " res4i_branch2c (Conv2D)     (None, None, None, 1024)     263168    ['activation_49[0][0]']       \n",
      "                                                                                                  \n",
      " bn4i_branch2c (BatchNorm)   (None, None, None, 1024)     4096      ['res4i_branch2c[0][0]']      \n",
      "                                                                                                  \n",
      " add_22 (Add)                (None, None, None, 1024)     0         ['bn4i_branch2c[0][0]',       \n",
      "                                                                     'res4h_out[0][0]']           \n",
      "                                                                                                  \n",
      " res4i_out (Activation)      (None, None, None, 1024)     0         ['add_22[0][0]']              \n",
      "                                                                                                  \n",
      " res4j_branch2a (Conv2D)     (None, None, None, 256)      262400    ['res4i_out[0][0]']           \n",
      "                                                                                                  \n",
      " bn4j_branch2a (BatchNorm)   (None, None, None, 256)      1024      ['res4j_branch2a[0][0]']      \n",
      "                                                                                                  \n",
      " activation_50 (Activation)  (None, None, None, 256)      0         ['bn4j_branch2a[0][0]']       \n",
      "                                                                                                  \n",
      " res4j_branch2b (Conv2D)     (None, None, None, 256)      590080    ['activation_50[0][0]']       \n",
      "                                                                                                  \n",
      " bn4j_branch2b (BatchNorm)   (None, None, None, 256)      1024      ['res4j_branch2b[0][0]']      \n",
      "                                                                                                  \n",
      " activation_51 (Activation)  (None, None, None, 256)      0         ['bn4j_branch2b[0][0]']       \n",
      "                                                                                                  \n",
      " res4j_branch2c (Conv2D)     (None, None, None, 1024)     263168    ['activation_51[0][0]']       \n",
      "                                                                                                  \n",
      " bn4j_branch2c (BatchNorm)   (None, None, None, 1024)     4096      ['res4j_branch2c[0][0]']      \n",
      "                                                                                                  \n",
      " add_23 (Add)                (None, None, None, 1024)     0         ['bn4j_branch2c[0][0]',       \n",
      "                                                                     'res4i_out[0][0]']           \n",
      "                                                                                                  \n",
      " res4j_out (Activation)      (None, None, None, 1024)     0         ['add_23[0][0]']              \n",
      "                                                                                                  \n",
      " res4k_branch2a (Conv2D)     (None, None, None, 256)      262400    ['res4j_out[0][0]']           \n",
      "                                                                                                  \n",
      " bn4k_branch2a (BatchNorm)   (None, None, None, 256)      1024      ['res4k_branch2a[0][0]']      \n",
      "                                                                                                  \n",
      " activation_52 (Activation)  (None, None, None, 256)      0         ['bn4k_branch2a[0][0]']       \n",
      "                                                                                                  \n",
      " res4k_branch2b (Conv2D)     (None, None, None, 256)      590080    ['activation_52[0][0]']       \n",
      "                                                                                                  \n",
      " bn4k_branch2b (BatchNorm)   (None, None, None, 256)      1024      ['res4k_branch2b[0][0]']      \n",
      "                                                                                                  \n",
      " activation_53 (Activation)  (None, None, None, 256)      0         ['bn4k_branch2b[0][0]']       \n",
      "                                                                                                  \n",
      " res4k_branch2c (Conv2D)     (None, None, None, 1024)     263168    ['activation_53[0][0]']       \n",
      "                                                                                                  \n",
      " bn4k_branch2c (BatchNorm)   (None, None, None, 1024)     4096      ['res4k_branch2c[0][0]']      \n",
      "                                                                                                  \n",
      " add_24 (Add)                (None, None, None, 1024)     0         ['bn4k_branch2c[0][0]',       \n",
      "                                                                     'res4j_out[0][0]']           \n",
      "                                                                                                  \n",
      " res4k_out (Activation)      (None, None, None, 1024)     0         ['add_24[0][0]']              \n",
      "                                                                                                  \n",
      " res4l_branch2a (Conv2D)     (None, None, None, 256)      262400    ['res4k_out[0][0]']           \n",
      "                                                                                                  \n",
      " bn4l_branch2a (BatchNorm)   (None, None, None, 256)      1024      ['res4l_branch2a[0][0]']      \n",
      "                                                                                                  \n",
      " activation_54 (Activation)  (None, None, None, 256)      0         ['bn4l_branch2a[0][0]']       \n",
      "                                                                                                  \n",
      " res4l_branch2b (Conv2D)     (None, None, None, 256)      590080    ['activation_54[0][0]']       \n",
      "                                                                                                  \n",
      " bn4l_branch2b (BatchNorm)   (None, None, None, 256)      1024      ['res4l_branch2b[0][0]']      \n",
      "                                                                                                  \n",
      " activation_55 (Activation)  (None, None, None, 256)      0         ['bn4l_branch2b[0][0]']       \n",
      "                                                                                                  \n",
      " res4l_branch2c (Conv2D)     (None, None, None, 1024)     263168    ['activation_55[0][0]']       \n",
      "                                                                                                  \n",
      " bn4l_branch2c (BatchNorm)   (None, None, None, 1024)     4096      ['res4l_branch2c[0][0]']      \n",
      "                                                                                                  \n",
      " add_25 (Add)                (None, None, None, 1024)     0         ['bn4l_branch2c[0][0]',       \n",
      "                                                                     'res4k_out[0][0]']           \n",
      "                                                                                                  \n",
      " res4l_out (Activation)      (None, None, None, 1024)     0         ['add_25[0][0]']              \n",
      "                                                                                                  \n",
      " res4m_branch2a (Conv2D)     (None, None, None, 256)      262400    ['res4l_out[0][0]']           \n",
      "                                                                                                  \n",
      " bn4m_branch2a (BatchNorm)   (None, None, None, 256)      1024      ['res4m_branch2a[0][0]']      \n",
      "                                                                                                  \n",
      " activation_56 (Activation)  (None, None, None, 256)      0         ['bn4m_branch2a[0][0]']       \n",
      "                                                                                                  \n",
      " res4m_branch2b (Conv2D)     (None, None, None, 256)      590080    ['activation_56[0][0]']       \n",
      "                                                                                                  \n",
      " bn4m_branch2b (BatchNorm)   (None, None, None, 256)      1024      ['res4m_branch2b[0][0]']      \n",
      "                                                                                                  \n",
      " activation_57 (Activation)  (None, None, None, 256)      0         ['bn4m_branch2b[0][0]']       \n",
      "                                                                                                  \n",
      " res4m_branch2c (Conv2D)     (None, None, None, 1024)     263168    ['activation_57[0][0]']       \n",
      "                                                                                                  \n",
      " bn4m_branch2c (BatchNorm)   (None, None, None, 1024)     4096      ['res4m_branch2c[0][0]']      \n",
      "                                                                                                  \n",
      " add_26 (Add)                (None, None, None, 1024)     0         ['bn4m_branch2c[0][0]',       \n",
      "                                                                     'res4l_out[0][0]']           \n",
      "                                                                                                  \n",
      " res4m_out (Activation)      (None, None, None, 1024)     0         ['add_26[0][0]']              \n",
      "                                                                                                  \n",
      " res4n_branch2a (Conv2D)     (None, None, None, 256)      262400    ['res4m_out[0][0]']           \n",
      "                                                                                                  \n",
      " bn4n_branch2a (BatchNorm)   (None, None, None, 256)      1024      ['res4n_branch2a[0][0]']      \n",
      "                                                                                                  \n",
      " activation_58 (Activation)  (None, None, None, 256)      0         ['bn4n_branch2a[0][0]']       \n",
      "                                                                                                  \n",
      " res4n_branch2b (Conv2D)     (None, None, None, 256)      590080    ['activation_58[0][0]']       \n",
      "                                                                                                  \n",
      " bn4n_branch2b (BatchNorm)   (None, None, None, 256)      1024      ['res4n_branch2b[0][0]']      \n",
      "                                                                                                  \n",
      " activation_59 (Activation)  (None, None, None, 256)      0         ['bn4n_branch2b[0][0]']       \n",
      "                                                                                                  \n",
      " res4n_branch2c (Conv2D)     (None, None, None, 1024)     263168    ['activation_59[0][0]']       \n",
      "                                                                                                  \n",
      " bn4n_branch2c (BatchNorm)   (None, None, None, 1024)     4096      ['res4n_branch2c[0][0]']      \n",
      "                                                                                                  \n",
      " add_27 (Add)                (None, None, None, 1024)     0         ['bn4n_branch2c[0][0]',       \n",
      "                                                                     'res4m_out[0][0]']           \n",
      "                                                                                                  \n",
      " res4n_out (Activation)      (None, None, None, 1024)     0         ['add_27[0][0]']              \n",
      "                                                                                                  \n",
      " res4o_branch2a (Conv2D)     (None, None, None, 256)      262400    ['res4n_out[0][0]']           \n",
      "                                                                                                  \n",
      " bn4o_branch2a (BatchNorm)   (None, None, None, 256)      1024      ['res4o_branch2a[0][0]']      \n",
      "                                                                                                  \n",
      " activation_60 (Activation)  (None, None, None, 256)      0         ['bn4o_branch2a[0][0]']       \n",
      "                                                                                                  \n",
      " res4o_branch2b (Conv2D)     (None, None, None, 256)      590080    ['activation_60[0][0]']       \n",
      "                                                                                                  \n",
      " bn4o_branch2b (BatchNorm)   (None, None, None, 256)      1024      ['res4o_branch2b[0][0]']      \n",
      "                                                                                                  \n",
      " activation_61 (Activation)  (None, None, None, 256)      0         ['bn4o_branch2b[0][0]']       \n",
      "                                                                                                  \n",
      " res4o_branch2c (Conv2D)     (None, None, None, 1024)     263168    ['activation_61[0][0]']       \n",
      "                                                                                                  \n",
      " bn4o_branch2c (BatchNorm)   (None, None, None, 1024)     4096      ['res4o_branch2c[0][0]']      \n",
      "                                                                                                  \n",
      " add_28 (Add)                (None, None, None, 1024)     0         ['bn4o_branch2c[0][0]',       \n",
      "                                                                     'res4n_out[0][0]']           \n",
      "                                                                                                  \n",
      " res4o_out (Activation)      (None, None, None, 1024)     0         ['add_28[0][0]']              \n",
      "                                                                                                  \n",
      " res4p_branch2a (Conv2D)     (None, None, None, 256)      262400    ['res4o_out[0][0]']           \n",
      "                                                                                                  \n",
      " bn4p_branch2a (BatchNorm)   (None, None, None, 256)      1024      ['res4p_branch2a[0][0]']      \n",
      "                                                                                                  \n",
      " activation_62 (Activation)  (None, None, None, 256)      0         ['bn4p_branch2a[0][0]']       \n",
      "                                                                                                  \n",
      " res4p_branch2b (Conv2D)     (None, None, None, 256)      590080    ['activation_62[0][0]']       \n",
      "                                                                                                  \n",
      " bn4p_branch2b (BatchNorm)   (None, None, None, 256)      1024      ['res4p_branch2b[0][0]']      \n",
      "                                                                                                  \n",
      " activation_63 (Activation)  (None, None, None, 256)      0         ['bn4p_branch2b[0][0]']       \n",
      "                                                                                                  \n",
      " res4p_branch2c (Conv2D)     (None, None, None, 1024)     263168    ['activation_63[0][0]']       \n",
      "                                                                                                  \n",
      " bn4p_branch2c (BatchNorm)   (None, None, None, 1024)     4096      ['res4p_branch2c[0][0]']      \n",
      "                                                                                                  \n",
      " add_29 (Add)                (None, None, None, 1024)     0         ['bn4p_branch2c[0][0]',       \n",
      "                                                                     'res4o_out[0][0]']           \n",
      "                                                                                                  \n",
      " res4p_out (Activation)      (None, None, None, 1024)     0         ['add_29[0][0]']              \n",
      "                                                                                                  \n",
      " res4q_branch2a (Conv2D)     (None, None, None, 256)      262400    ['res4p_out[0][0]']           \n",
      "                                                                                                  \n",
      " bn4q_branch2a (BatchNorm)   (None, None, None, 256)      1024      ['res4q_branch2a[0][0]']      \n",
      "                                                                                                  \n",
      " activation_64 (Activation)  (None, None, None, 256)      0         ['bn4q_branch2a[0][0]']       \n",
      "                                                                                                  \n",
      " res4q_branch2b (Conv2D)     (None, None, None, 256)      590080    ['activation_64[0][0]']       \n",
      "                                                                                                  \n",
      " bn4q_branch2b (BatchNorm)   (None, None, None, 256)      1024      ['res4q_branch2b[0][0]']      \n",
      "                                                                                                  \n",
      " activation_65 (Activation)  (None, None, None, 256)      0         ['bn4q_branch2b[0][0]']       \n",
      "                                                                                                  \n",
      " res4q_branch2c (Conv2D)     (None, None, None, 1024)     263168    ['activation_65[0][0]']       \n",
      "                                                                                                  \n",
      " bn4q_branch2c (BatchNorm)   (None, None, None, 1024)     4096      ['res4q_branch2c[0][0]']      \n",
      "                                                                                                  \n",
      " add_30 (Add)                (None, None, None, 1024)     0         ['bn4q_branch2c[0][0]',       \n",
      "                                                                     'res4p_out[0][0]']           \n",
      "                                                                                                  \n",
      " res4q_out (Activation)      (None, None, None, 1024)     0         ['add_30[0][0]']              \n",
      "                                                                                                  \n",
      " res4r_branch2a (Conv2D)     (None, None, None, 256)      262400    ['res4q_out[0][0]']           \n",
      "                                                                                                  \n",
      " bn4r_branch2a (BatchNorm)   (None, None, None, 256)      1024      ['res4r_branch2a[0][0]']      \n",
      "                                                                                                  \n",
      " activation_66 (Activation)  (None, None, None, 256)      0         ['bn4r_branch2a[0][0]']       \n",
      "                                                                                                  \n",
      " res4r_branch2b (Conv2D)     (None, None, None, 256)      590080    ['activation_66[0][0]']       \n",
      "                                                                                                  \n",
      " bn4r_branch2b (BatchNorm)   (None, None, None, 256)      1024      ['res4r_branch2b[0][0]']      \n",
      "                                                                                                  \n",
      " activation_67 (Activation)  (None, None, None, 256)      0         ['bn4r_branch2b[0][0]']       \n",
      "                                                                                                  \n",
      " res4r_branch2c (Conv2D)     (None, None, None, 1024)     263168    ['activation_67[0][0]']       \n",
      "                                                                                                  \n",
      " bn4r_branch2c (BatchNorm)   (None, None, None, 1024)     4096      ['res4r_branch2c[0][0]']      \n",
      "                                                                                                  \n",
      " add_31 (Add)                (None, None, None, 1024)     0         ['bn4r_branch2c[0][0]',       \n",
      "                                                                     'res4q_out[0][0]']           \n",
      "                                                                                                  \n",
      " res4r_out (Activation)      (None, None, None, 1024)     0         ['add_31[0][0]']              \n",
      "                                                                                                  \n",
      " res4s_branch2a (Conv2D)     (None, None, None, 256)      262400    ['res4r_out[0][0]']           \n",
      "                                                                                                  \n",
      " bn4s_branch2a (BatchNorm)   (None, None, None, 256)      1024      ['res4s_branch2a[0][0]']      \n",
      "                                                                                                  \n",
      " activation_68 (Activation)  (None, None, None, 256)      0         ['bn4s_branch2a[0][0]']       \n",
      "                                                                                                  \n",
      " res4s_branch2b (Conv2D)     (None, None, None, 256)      590080    ['activation_68[0][0]']       \n",
      "                                                                                                  \n",
      " bn4s_branch2b (BatchNorm)   (None, None, None, 256)      1024      ['res4s_branch2b[0][0]']      \n",
      "                                                                                                  \n",
      " activation_69 (Activation)  (None, None, None, 256)      0         ['bn4s_branch2b[0][0]']       \n",
      "                                                                                                  \n",
      " res4s_branch2c (Conv2D)     (None, None, None, 1024)     263168    ['activation_69[0][0]']       \n",
      "                                                                                                  \n",
      " bn4s_branch2c (BatchNorm)   (None, None, None, 1024)     4096      ['res4s_branch2c[0][0]']      \n",
      "                                                                                                  \n",
      " add_32 (Add)                (None, None, None, 1024)     0         ['bn4s_branch2c[0][0]',       \n",
      "                                                                     'res4r_out[0][0]']           \n",
      "                                                                                                  \n",
      " res4s_out (Activation)      (None, None, None, 1024)     0         ['add_32[0][0]']              \n",
      "                                                                                                  \n",
      " res4t_branch2a (Conv2D)     (None, None, None, 256)      262400    ['res4s_out[0][0]']           \n",
      "                                                                                                  \n",
      " bn4t_branch2a (BatchNorm)   (None, None, None, 256)      1024      ['res4t_branch2a[0][0]']      \n",
      "                                                                                                  \n",
      " activation_70 (Activation)  (None, None, None, 256)      0         ['bn4t_branch2a[0][0]']       \n",
      "                                                                                                  \n",
      " res4t_branch2b (Conv2D)     (None, None, None, 256)      590080    ['activation_70[0][0]']       \n",
      "                                                                                                  \n",
      " bn4t_branch2b (BatchNorm)   (None, None, None, 256)      1024      ['res4t_branch2b[0][0]']      \n",
      "                                                                                                  \n",
      " activation_71 (Activation)  (None, None, None, 256)      0         ['bn4t_branch2b[0][0]']       \n",
      "                                                                                                  \n",
      " res4t_branch2c (Conv2D)     (None, None, None, 1024)     263168    ['activation_71[0][0]']       \n",
      "                                                                                                  \n",
      " bn4t_branch2c (BatchNorm)   (None, None, None, 1024)     4096      ['res4t_branch2c[0][0]']      \n",
      "                                                                                                  \n",
      " add_33 (Add)                (None, None, None, 1024)     0         ['bn4t_branch2c[0][0]',       \n",
      "                                                                     'res4s_out[0][0]']           \n",
      "                                                                                                  \n",
      " res4t_out (Activation)      (None, None, None, 1024)     0         ['add_33[0][0]']              \n",
      "                                                                                                  \n",
      " res4u_branch2a (Conv2D)     (None, None, None, 256)      262400    ['res4t_out[0][0]']           \n",
      "                                                                                                  \n",
      " bn4u_branch2a (BatchNorm)   (None, None, None, 256)      1024      ['res4u_branch2a[0][0]']      \n",
      "                                                                                                  \n",
      " activation_72 (Activation)  (None, None, None, 256)      0         ['bn4u_branch2a[0][0]']       \n",
      "                                                                                                  \n",
      " res4u_branch2b (Conv2D)     (None, None, None, 256)      590080    ['activation_72[0][0]']       \n",
      "                                                                                                  \n",
      " bn4u_branch2b (BatchNorm)   (None, None, None, 256)      1024      ['res4u_branch2b[0][0]']      \n",
      "                                                                                                  \n",
      " activation_73 (Activation)  (None, None, None, 256)      0         ['bn4u_branch2b[0][0]']       \n",
      "                                                                                                  \n",
      " res4u_branch2c (Conv2D)     (None, None, None, 1024)     263168    ['activation_73[0][0]']       \n",
      "                                                                                                  \n",
      " bn4u_branch2c (BatchNorm)   (None, None, None, 1024)     4096      ['res4u_branch2c[0][0]']      \n",
      "                                                                                                  \n",
      " add_34 (Add)                (None, None, None, 1024)     0         ['bn4u_branch2c[0][0]',       \n",
      "                                                                     'res4t_out[0][0]']           \n",
      "                                                                                                  \n",
      " res4u_out (Activation)      (None, None, None, 1024)     0         ['add_34[0][0]']              \n",
      "                                                                                                  \n",
      " res4v_branch2a (Conv2D)     (None, None, None, 256)      262400    ['res4u_out[0][0]']           \n",
      "                                                                                                  \n",
      " bn4v_branch2a (BatchNorm)   (None, None, None, 256)      1024      ['res4v_branch2a[0][0]']      \n",
      "                                                                                                  \n",
      " activation_74 (Activation)  (None, None, None, 256)      0         ['bn4v_branch2a[0][0]']       \n",
      "                                                                                                  \n",
      " res4v_branch2b (Conv2D)     (None, None, None, 256)      590080    ['activation_74[0][0]']       \n",
      "                                                                                                  \n",
      " bn4v_branch2b (BatchNorm)   (None, None, None, 256)      1024      ['res4v_branch2b[0][0]']      \n",
      "                                                                                                  \n",
      " activation_75 (Activation)  (None, None, None, 256)      0         ['bn4v_branch2b[0][0]']       \n",
      "                                                                                                  \n",
      " res4v_branch2c (Conv2D)     (None, None, None, 1024)     263168    ['activation_75[0][0]']       \n",
      "                                                                                                  \n",
      " bn4v_branch2c (BatchNorm)   (None, None, None, 1024)     4096      ['res4v_branch2c[0][0]']      \n",
      "                                                                                                  \n",
      " add_35 (Add)                (None, None, None, 1024)     0         ['bn4v_branch2c[0][0]',       \n",
      "                                                                     'res4u_out[0][0]']           \n",
      "                                                                                                  \n",
      " res4v_out (Activation)      (None, None, None, 1024)     0         ['add_35[0][0]']              \n",
      "                                                                                                  \n",
      " res4w_branch2a (Conv2D)     (None, None, None, 256)      262400    ['res4v_out[0][0]']           \n",
      "                                                                                                  \n",
      " bn4w_branch2a (BatchNorm)   (None, None, None, 256)      1024      ['res4w_branch2a[0][0]']      \n",
      "                                                                                                  \n",
      " activation_76 (Activation)  (None, None, None, 256)      0         ['bn4w_branch2a[0][0]']       \n",
      "                                                                                                  \n",
      " res4w_branch2b (Conv2D)     (None, None, None, 256)      590080    ['activation_76[0][0]']       \n",
      "                                                                                                  \n",
      " bn4w_branch2b (BatchNorm)   (None, None, None, 256)      1024      ['res4w_branch2b[0][0]']      \n",
      "                                                                                                  \n",
      " activation_77 (Activation)  (None, None, None, 256)      0         ['bn4w_branch2b[0][0]']       \n",
      "                                                                                                  \n",
      " res4w_branch2c (Conv2D)     (None, None, None, 1024)     263168    ['activation_77[0][0]']       \n",
      "                                                                                                  \n",
      " bn4w_branch2c (BatchNorm)   (None, None, None, 1024)     4096      ['res4w_branch2c[0][0]']      \n",
      "                                                                                                  \n",
      " add_36 (Add)                (None, None, None, 1024)     0         ['bn4w_branch2c[0][0]',       \n",
      "                                                                     'res4v_out[0][0]']           \n",
      "                                                                                                  \n",
      " res4w_out (Activation)      (None, None, None, 1024)     0         ['add_36[0][0]']              \n",
      "                                                                                                  \n",
      " res5a_branch2a (Conv2D)     (None, None, None, 512)      524800    ['res4w_out[0][0]']           \n",
      "                                                                                                  \n",
      " bn5a_branch2a (BatchNorm)   (None, None, None, 512)      2048      ['res5a_branch2a[0][0]']      \n",
      "                                                                                                  \n",
      " activation_78 (Activation)  (None, None, None, 512)      0         ['bn5a_branch2a[0][0]']       \n",
      "                                                                                                  \n",
      " res5a_branch2b (Conv2D)     (None, None, None, 512)      2359808   ['activation_78[0][0]']       \n",
      "                                                                                                  \n",
      " bn5a_branch2b (BatchNorm)   (None, None, None, 512)      2048      ['res5a_branch2b[0][0]']      \n",
      "                                                                                                  \n",
      " activation_79 (Activation)  (None, None, None, 512)      0         ['bn5a_branch2b[0][0]']       \n",
      "                                                                                                  \n",
      " res5a_branch2c (Conv2D)     (None, None, None, 2048)     1050624   ['activation_79[0][0]']       \n",
      "                                                                                                  \n",
      " res5a_branch1 (Conv2D)      (None, None, None, 2048)     2099200   ['res4w_out[0][0]']           \n",
      "                                                                                                  \n",
      " bn5a_branch2c (BatchNorm)   (None, None, None, 2048)     8192      ['res5a_branch2c[0][0]']      \n",
      "                                                                                                  \n",
      " bn5a_branch1 (BatchNorm)    (None, None, None, 2048)     8192      ['res5a_branch1[0][0]']       \n",
      "                                                                                                  \n",
      " add_37 (Add)                (None, None, None, 2048)     0         ['bn5a_branch2c[0][0]',       \n",
      "                                                                     'bn5a_branch1[0][0]']        \n",
      "                                                                                                  \n",
      " res5a_out (Activation)      (None, None, None, 2048)     0         ['add_37[0][0]']              \n",
      "                                                                                                  \n",
      " res5b_branch2a (Conv2D)     (None, None, None, 512)      1049088   ['res5a_out[0][0]']           \n",
      "                                                                                                  \n",
      " bn5b_branch2a (BatchNorm)   (None, None, None, 512)      2048      ['res5b_branch2a[0][0]']      \n",
      "                                                                                                  \n",
      " activation_80 (Activation)  (None, None, None, 512)      0         ['bn5b_branch2a[0][0]']       \n",
      "                                                                                                  \n",
      " res5b_branch2b (Conv2D)     (None, None, None, 512)      2359808   ['activation_80[0][0]']       \n",
      "                                                                                                  \n",
      " bn5b_branch2b (BatchNorm)   (None, None, None, 512)      2048      ['res5b_branch2b[0][0]']      \n",
      "                                                                                                  \n",
      " activation_81 (Activation)  (None, None, None, 512)      0         ['bn5b_branch2b[0][0]']       \n",
      "                                                                                                  \n",
      " res5b_branch2c (Conv2D)     (None, None, None, 2048)     1050624   ['activation_81[0][0]']       \n",
      "                                                                                                  \n",
      " bn5b_branch2c (BatchNorm)   (None, None, None, 2048)     8192      ['res5b_branch2c[0][0]']      \n",
      "                                                                                                  \n",
      " add_38 (Add)                (None, None, None, 2048)     0         ['bn5b_branch2c[0][0]',       \n",
      "                                                                     'res5a_out[0][0]']           \n",
      "                                                                                                  \n",
      " res5b_out (Activation)      (None, None, None, 2048)     0         ['add_38[0][0]']              \n",
      "                                                                                                  \n",
      " res5c_branch2a (Conv2D)     (None, None, None, 512)      1049088   ['res5b_out[0][0]']           \n",
      "                                                                                                  \n",
      " bn5c_branch2a (BatchNorm)   (None, None, None, 512)      2048      ['res5c_branch2a[0][0]']      \n",
      "                                                                                                  \n",
      " activation_82 (Activation)  (None, None, None, 512)      0         ['bn5c_branch2a[0][0]']       \n",
      "                                                                                                  \n",
      " res5c_branch2b (Conv2D)     (None, None, None, 512)      2359808   ['activation_82[0][0]']       \n",
      "                                                                                                  \n",
      " bn5c_branch2b (BatchNorm)   (None, None, None, 512)      2048      ['res5c_branch2b[0][0]']      \n",
      "                                                                                                  \n",
      " activation_83 (Activation)  (None, None, None, 512)      0         ['bn5c_branch2b[0][0]']       \n",
      "                                                                                                  \n",
      " res5c_branch2c (Conv2D)     (None, None, None, 2048)     1050624   ['activation_83[0][0]']       \n",
      "                                                                                                  \n",
      " bn5c_branch2c (BatchNorm)   (None, None, None, 2048)     8192      ['res5c_branch2c[0][0]']      \n",
      "                                                                                                  \n",
      " add_39 (Add)                (None, None, None, 2048)     0         ['bn5c_branch2c[0][0]',       \n",
      "                                                                     'res5b_out[0][0]']           \n",
      "                                                                                                  \n",
      " res5c_out (Activation)      (None, None, None, 2048)     0         ['add_39[0][0]']              \n",
      "                                                                                                  \n",
      " fpn_c5p5 (Conv2D)           (None, None, None, 256)      524544    ['res5c_out[0][0]']           \n",
      "                                                                                                  \n",
      " fpn_p5upsampled (UpSamplin  (None, None, None, 256)      0         ['fpn_c5p5[0][0]']            \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " fpn_c4p4 (Conv2D)           (None, None, None, 256)      262400    ['res4w_out[0][0]']           \n",
      "                                                                                                  \n",
      " fpn_p4add (Add)             (None, None, None, 256)      0         ['fpn_p5upsampled[0][0]',     \n",
      "                                                                     'fpn_c4p4[0][0]']            \n",
      "                                                                                                  \n",
      " fpn_p4upsampled (UpSamplin  (None, None, None, 256)      0         ['fpn_p4add[0][0]']           \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " fpn_c3p3 (Conv2D)           (None, None, None, 256)      131328    ['res3d_out[0][0]']           \n",
      "                                                                                                  \n",
      " fpn_p3add (Add)             (None, None, None, 256)      0         ['fpn_p4upsampled[0][0]',     \n",
      "                                                                     'fpn_c3p3[0][0]']            \n",
      "                                                                                                  \n",
      " fpn_p3upsampled (UpSamplin  (None, None, None, 256)      0         ['fpn_p3add[0][0]']           \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " fpn_c2p2 (Conv2D)           (None, None, None, 256)      65792     ['res2c_out[0][0]']           \n",
      "                                                                                                  \n",
      " fpn_p2add (Add)             (None, None, None, 256)      0         ['fpn_p3upsampled[0][0]',     \n",
      "                                                                     'fpn_c2p2[0][0]']            \n",
      "                                                                                                  \n",
      " fpn_p5 (Conv2D)             (None, None, None, 256)      590080    ['fpn_c5p5[0][0]']            \n",
      "                                                                                                  \n",
      " fpn_p2 (Conv2D)             (None, None, None, 256)      590080    ['fpn_p2add[0][0]']           \n",
      "                                                                                                  \n",
      " fpn_p3 (Conv2D)             (None, None, None, 256)      590080    ['fpn_p3add[0][0]']           \n",
      "                                                                                                  \n",
      " fpn_p4 (Conv2D)             (None, None, None, 256)      590080    ['fpn_p4add[0][0]']           \n",
      "                                                                                                  \n",
      " fpn_p6 (MaxPooling2D)       (None, None, None, 256)      0         ['fpn_p5[0][0]']              \n",
      "                                                                                                  \n",
      " rpn_model (Functional)      [(None, None, 2),            1189394   ['fpn_p2[0][0]',              \n",
      "                              (None, None, 2),                       'fpn_p3[0][0]',              \n",
      "                              (None, None, 4)]                       'fpn_p4[0][0]',              \n",
      "                                                                     'fpn_p5[0][0]',              \n",
      "                                                                     'fpn_p6[0][0]']              \n",
      "                                                                                                  \n",
      " rpn_bbox (Concatenate)      (None, None, 4)              0         ['rpn_model[0][2]',           \n",
      "                                                                     'rpn_model[1][2]',           \n",
      "                                                                     'rpn_model[2][2]',           \n",
      "                                                                     'rpn_model[3][2]',           \n",
      "                                                                     'rpn_model[4][2]']           \n",
      "                                                                                                  \n",
      " rpn_class (Concatenate)     (None, None, 2)              0         ['rpn_model[0][1]',           \n",
      "                                                                     'rpn_model[1][1]',           \n",
      "                                                                     'rpn_model[2][1]',           \n",
      "                                                                     'rpn_model[3][1]',           \n",
      "                                                                     'rpn_model[4][1]']           \n",
      "                                                                                                  \n",
      " anchors (ConstLayer)        (4, 65472, 4)                1047552   ['input_image[0][0]']         \n",
      "                                                                                                  \n",
      " input_gt_boxes (InputLayer  [(None, None, 4)]            0         []                            \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " ROI (ProposalLayer)         (4, 2000, 4)                 0         ['rpn_class[0][0]',           \n",
      "                                                                     'rpn_bbox[0][0]',            \n",
      "                                                                     'anchors[0][0]']             \n",
      "                                                                                                  \n",
      " input_gt_class_ids (InputL  [(None, None)]               0         []                            \n",
      " ayer)                                                                                            \n",
      "                                                                                                  \n",
      " lambda_1 (Lambda)           (None, None, 4)              0         ['input_gt_boxes[0][0]',      \n",
      "                                                                     'input_image[0][0]']         \n",
      "                                                                                                  \n",
      " input_gt_masks (InputLayer  [(None, 512, 512, None)]     0         []                            \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " proposal_targets (Detectio  [(4, None, 4),               0         ['ROI[0][0]',                 \n",
      " nTargetLayer)                (4, None),                             'input_gt_class_ids[0][0]',  \n",
      "                              (4, None, 4),                          'lambda_1[0][0]',            \n",
      "                              (4, None, 28, 28)]                     'input_gt_masks[0][0]']      \n",
      "                                                                                                  \n",
      " input_image_meta (InputLay  [(None, 16)]                 0         []                            \n",
      " er)                                                                                              \n",
      "                                                                                                  \n",
      " roi_align_mask (PyramidROI  (4, None, 14, 14, 256)       0         ['proposal_targets[0][0]',    \n",
      " Align)                                                              'input_image_meta[0][0]',    \n",
      "                                                                     'fpn_p2[0][0]',              \n",
      "                                                                     'fpn_p3[0][0]',              \n",
      "                                                                     'fpn_p4[0][0]',              \n",
      "                                                                     'fpn_p5[0][0]']              \n",
      "                                                                                                  \n",
      " mrcnn_mask_conv1 (TimeDist  (4, None, 14, 14, 256)       590080    ['roi_align_mask[0][0]']      \n",
      " ributed)                                                                                         \n",
      "                                                                                                  \n",
      " mrcnn_mask_bn1 (TimeDistri  (4, None, 14, 14, 256)       1024      ['mrcnn_mask_conv1[0][0]']    \n",
      " buted)                                                                                           \n",
      "                                                                                                  \n",
      " activation_87 (Activation)  (4, None, 14, 14, 256)       0         ['mrcnn_mask_bn1[0][0]']      \n",
      "                                                                                                  \n",
      " mrcnn_mask_conv2 (TimeDist  (4, None, 14, 14, 256)       590080    ['activation_87[0][0]']       \n",
      " ributed)                                                                                         \n",
      "                                                                                                  \n",
      " roi_align_classifier (Pyra  (4, None, 7, 7, 256)         0         ['proposal_targets[0][0]',    \n",
      " midROIAlign)                                                        'input_image_meta[0][0]',    \n",
      "                                                                     'fpn_p2[0][0]',              \n",
      "                                                                     'fpn_p3[0][0]',              \n",
      "                                                                     'fpn_p4[0][0]',              \n",
      "                                                                     'fpn_p5[0][0]']              \n",
      "                                                                                                  \n",
      " mrcnn_mask_bn2 (TimeDistri  (4, None, 14, 14, 256)       1024      ['mrcnn_mask_conv2[0][0]']    \n",
      " buted)                                                                                           \n",
      "                                                                                                  \n",
      " mrcnn_class_conv1 (TimeDis  (4, None, 1, 1, 1024)        1284608   ['roi_align_classifier[0][0]']\n",
      " tributed)                                                0                                       \n",
      "                                                                                                  \n",
      " activation_88 (Activation)  (4, None, 14, 14, 256)       0         ['mrcnn_mask_bn2[0][0]']      \n",
      "                                                                                                  \n",
      " mrcnn_class_bn1 (TimeDistr  (4, None, 1, 1, 1024)        4096      ['mrcnn_class_conv1[0][0]']   \n",
      " ibuted)                                                                                          \n",
      "                                                                                                  \n",
      " mrcnn_mask_conv3 (TimeDist  (4, None, 14, 14, 256)       590080    ['activation_88[0][0]']       \n",
      " ributed)                                                                                         \n",
      "                                                                                                  \n",
      " activation_84 (Activation)  (4, None, 1, 1, 1024)        0         ['mrcnn_class_bn1[0][0]']     \n",
      "                                                                                                  \n",
      " mrcnn_mask_bn3 (TimeDistri  (4, None, 14, 14, 256)       1024      ['mrcnn_mask_conv3[0][0]']    \n",
      " buted)                                                                                           \n",
      "                                                                                                  \n",
      " mrcnn_class_conv2 (TimeDis  (4, None, 1, 1, 1024)        1049600   ['activation_84[0][0]']       \n",
      " tributed)                                                                                        \n",
      "                                                                                                  \n",
      " activation_89 (Activation)  (4, None, 14, 14, 256)       0         ['mrcnn_mask_bn3[0][0]']      \n",
      "                                                                                                  \n",
      " mrcnn_class_bn2 (TimeDistr  (4, None, 1, 1, 1024)        4096      ['mrcnn_class_conv2[0][0]']   \n",
      " ibuted)                                                                                          \n",
      "                                                                                                  \n",
      " mrcnn_mask_conv4 (TimeDist  (4, None, 14, 14, 256)       590080    ['activation_89[0][0]']       \n",
      " ributed)                                                                                         \n",
      "                                                                                                  \n",
      " activation_85 (Activation)  (4, None, 1, 1, 1024)        0         ['mrcnn_class_bn2[0][0]']     \n",
      "                                                                                                  \n",
      " mrcnn_mask_bn4 (TimeDistri  (4, None, 14, 14, 256)       1024      ['mrcnn_mask_conv4[0][0]']    \n",
      " buted)                                                                                           \n",
      "                                                                                                  \n",
      " pool_squeeze (Lambda)       (4, None, 1024)              0         ['activation_85[0][0]']       \n",
      "                                                                                                  \n",
      " activation_90 (Activation)  (4, None, 14, 14, 256)       0         ['mrcnn_mask_bn4[0][0]']      \n",
      "                                                                                                  \n",
      " mrcnn_bbox_fc (TimeDistrib  (4, None, 16)                16400     ['pool_squeeze[0][0]']        \n",
      " uted)                                                                                            \n",
      "                                                                                                  \n",
      " mrcnn_mask_deconv (TimeDis  (4, None, 28, 28, 256)       262400    ['activation_90[0][0]']       \n",
      " tributed)                                                                                        \n",
      "                                                                                                  \n",
      " input_rpn_match (InputLaye  [(None, None, 1)]            0         []                            \n",
      " r)                                                                                               \n",
      "                                                                                                  \n",
      " input_rpn_bbox (InputLayer  [(None, None, 4)]            0         []                            \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " rpn_class_logits (Concaten  (None, None, 2)              0         ['rpn_model[0][0]',           \n",
      " ate)                                                                'rpn_model[1][0]',           \n",
      "                                                                     'rpn_model[2][0]',           \n",
      "                                                                     'rpn_model[3][0]',           \n",
      "                                                                     'rpn_model[4][0]']           \n",
      "                                                                                                  \n",
      " mrcnn_class_logits (TimeDi  (4, None, 4)                 4100      ['pool_squeeze[0][0]']        \n",
      " stributed)                                                                                       \n",
      "                                                                                                  \n",
      " mrcnn_bbox (Reshape)        (4, None, 4, 4)              0         ['mrcnn_bbox_fc[0][0]']       \n",
      "                                                                                                  \n",
      " mrcnn_mask (TimeDistribute  (4, None, 28, 28, 4)         1028      ['mrcnn_mask_deconv[0][0]']   \n",
      " d)                                                                                               \n",
      "                                                                                                  \n",
      " lambda_4 (Lambda)           (None, 4)                    0         ['input_image_meta[0][0]']    \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 64791722 (247.16 MB)\n",
      "Trainable params: 0 (0.00 Byte)\n",
      "Non-trainable params: 64791722 (247.16 MB)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.compile(layers=\"head\")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting at epoch 0.\n",
      "\n",
      "Checkpoint Path: /mnt/c/Users/ChangGeng/Desktop/FAU/Semester 07/Bachelorarbeit/02_Vision_Transformers/logs/60_shapes_resnet20241210T2123/mask_rcnn_60_shapes_resnet_{epoch:04d}.h5\n",
      "n workers used: 32\n",
      "Epoch 1: Learning rate is 0.000100 (warmup phase).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "W0000 00:00:1733862198.315141     953 op_level_cost_estimator.cc:699] Error in PredictCost() for the op: op: \"CropAndResize\" attr { key: \"T\" value { type: DT_FLOAT } } attr { key: \"extrapolation_value\" value { f: 0 } } attr { key: \"method\" value { s: \"bilinear\" } } inputs { dtype: DT_FLOAT shape { dim { size: -638 } dim { size: -121 } dim { size: -122 } dim { size: 1 } } } inputs { dtype: DT_FLOAT shape { dim { size: -24 } dim { size: 4 } } } inputs { dtype: DT_INT32 shape { dim { size: -24 } } } inputs { dtype: DT_INT32 shape { dim { size: 2 } } value { dtype: DT_INT32 tensor_shape { dim { size: 2 } } int_val: 28 } } device { type: \"GPU\" vendor: \"NVIDIA\" model: \"NVIDIA GeForce RTX 4090\" frequency: 2520 num_cores: 128 environment { key: \"architecture\" value: \"8.9\" } environment { key: \"cuda\" value: \"12000\" } environment { key: \"cudnn\" value: \"8800\" } num_registers: 65536 l1_cache_size: 24576 l2_cache_size: 75497472 shared_memory_size_per_multiprocessor: 102400 memory_size: 22500343808 bandwidth: 1008096000 } outputs { dtype: DT_FLOAT shape { dim { size: -24 } dim { size: 28 } dim { size: 28 } dim { size: 1 } } }\n",
      "W0000 00:00:1733862198.315303     953 op_level_cost_estimator.cc:699] Error in PredictCost() for the op: op: \"CropAndResize\" attr { key: \"T\" value { type: DT_FLOAT } } attr { key: \"extrapolation_value\" value { f: 0 } } attr { key: \"method\" value { s: \"bilinear\" } } inputs { dtype: DT_FLOAT shape { dim { size: -696 } dim { size: -130 } dim { size: -131 } dim { size: 1 } } } inputs { dtype: DT_FLOAT shape { dim { size: -42 } dim { size: 4 } } } inputs { dtype: DT_INT32 shape { dim { size: -42 } } } inputs { dtype: DT_INT32 shape { dim { size: 2 } } value { dtype: DT_INT32 tensor_shape { dim { size: 2 } } int_val: 28 } } device { type: \"GPU\" vendor: \"NVIDIA\" model: \"NVIDIA GeForce RTX 4090\" frequency: 2520 num_cores: 128 environment { key: \"architecture\" value: \"8.9\" } environment { key: \"cuda\" value: \"12000\" } environment { key: \"cudnn\" value: \"8800\" } num_registers: 65536 l1_cache_size: 24576 l2_cache_size: 75497472 shared_memory_size_per_multiprocessor: 102400 memory_size: 22500343808 bandwidth: 1008096000 } outputs { dtype: DT_FLOAT shape { dim { size: -42 } dim { size: 28 } dim { size: 28 } dim { size: 1 } } }\n",
      "W0000 00:00:1733862198.315356     953 op_level_cost_estimator.cc:699] Error in PredictCost() for the op: op: \"CropAndResize\" attr { key: \"T\" value { type: DT_FLOAT } } attr { key: \"extrapolation_value\" value { f: 0 } } attr { key: \"method\" value { s: \"bilinear\" } } inputs { dtype: DT_FLOAT shape { dim { size: -660 } dim { size: -124 } dim { size: -125 } dim { size: 1 } } } inputs { dtype: DT_FLOAT shape { dim { size: -30 } dim { size: 4 } } } inputs { dtype: DT_INT32 shape { dim { size: -30 } } } inputs { dtype: DT_INT32 shape { dim { size: 2 } } value { dtype: DT_INT32 tensor_shape { dim { size: 2 } } int_val: 28 } } device { type: \"GPU\" vendor: \"NVIDIA\" model: \"NVIDIA GeForce RTX 4090\" frequency: 2520 num_cores: 128 environment { key: \"architecture\" value: \"8.9\" } environment { key: \"cuda\" value: \"12000\" } environment { key: \"cudnn\" value: \"8800\" } num_registers: 65536 l1_cache_size: 24576 l2_cache_size: 75497472 shared_memory_size_per_multiprocessor: 102400 memory_size: 22500343808 bandwidth: 1008096000 } outputs { dtype: DT_FLOAT shape { dim { size: -30 } dim { size: 28 } dim { size: 28 } dim { size: 1 } } }\n",
      "W0000 00:00:1733862198.315401     953 op_level_cost_estimator.cc:699] Error in PredictCost() for the op: op: \"CropAndResize\" attr { key: \"T\" value { type: DT_FLOAT } } attr { key: \"extrapolation_value\" value { f: 0 } } attr { key: \"method\" value { s: \"bilinear\" } } inputs { dtype: DT_FLOAT shape { dim { size: -681 } dim { size: -127 } dim { size: -128 } dim { size: 1 } } } inputs { dtype: DT_FLOAT shape { dim { size: -36 } dim { size: 4 } } } inputs { dtype: DT_INT32 shape { dim { size: -36 } } } inputs { dtype: DT_INT32 shape { dim { size: 2 } } value { dtype: DT_INT32 tensor_shape { dim { size: 2 } } int_val: 28 } } device { type: \"GPU\" vendor: \"NVIDIA\" model: \"NVIDIA GeForce RTX 4090\" frequency: 2520 num_cores: 128 environment { key: \"architecture\" value: \"8.9\" } environment { key: \"cuda\" value: \"12000\" } environment { key: \"cudnn\" value: \"8800\" } num_registers: 65536 l1_cache_size: 24576 l2_cache_size: 75497472 shared_memory_size_per_multiprocessor: 102400 memory_size: 22500343808 bandwidth: 1008096000 } outputs { dtype: DT_FLOAT shape { dim { size: -36 } dim { size: 28 } dim { size: 28 } dim { size: 1 } } }\n",
      "W0000 00:00:1733862198.316920     953 op_level_cost_estimator.cc:699] Error in PredictCost() for the op: op: \"CropAndResize\" attr { key: \"T\" value { type: DT_FLOAT } } attr { key: \"extrapolation_value\" value { f: 0 } } attr { key: \"method\" value { s: \"bilinear\" } } inputs { dtype: DT_FLOAT shape { dim { size: -96 } dim { size: -440 } dim { size: -441 } dim { size: 256 } } } inputs { dtype: DT_FLOAT shape { dim { size: -81 } dim { size: 4 } } } inputs { dtype: DT_INT32 shape { dim { size: -81 } } } inputs { dtype: DT_INT32 shape { dim { size: 2 } } value { dtype: DT_INT32 tensor_shape { dim { size: 2 } } int_val: 7 } } device { type: \"GPU\" vendor: \"NVIDIA\" model: \"NVIDIA GeForce RTX 4090\" frequency: 2520 num_cores: 128 environment { key: \"architecture\" value: \"8.9\" } environment { key: \"cuda\" value: \"12000\" } environment { key: \"cudnn\" value: \"8800\" } num_registers: 65536 l1_cache_size: 24576 l2_cache_size: 75497472 shared_memory_size_per_multiprocessor: 102400 memory_size: 22500343808 bandwidth: 1008096000 } outputs { dtype: DT_FLOAT shape { dim { size: -81 } dim { size: 7 } dim { size: 7 } dim { size: 256 } } }\n",
      "W0000 00:00:1733862198.316967     953 op_level_cost_estimator.cc:699] Error in PredictCost() for the op: op: \"CropAndResize\" attr { key: \"T\" value { type: DT_FLOAT } } attr { key: \"extrapolation_value\" value { f: 0 } } attr { key: \"method\" value { s: \"bilinear\" } } inputs { dtype: DT_FLOAT shape { dim { size: -96 } dim { size: -440 } dim { size: -441 } dim { size: 256 } } } inputs { dtype: DT_FLOAT shape { dim { size: -81 } dim { size: 4 } } } inputs { dtype: DT_INT32 shape { dim { size: -81 } } } inputs { dtype: DT_INT32 shape { dim { size: 2 } } value { dtype: DT_INT32 tensor_shape { dim { size: 2 } } int_val: 14 } } device { type: \"GPU\" vendor: \"NVIDIA\" model: \"NVIDIA GeForce RTX 4090\" frequency: 2520 num_cores: 128 environment { key: \"architecture\" value: \"8.9\" } environment { key: \"cuda\" value: \"12000\" } environment { key: \"cudnn\" value: \"8800\" } num_registers: 65536 l1_cache_size: 24576 l2_cache_size: 75497472 shared_memory_size_per_multiprocessor: 102400 memory_size: 22500343808 bandwidth: 1008096000 } outputs { dtype: DT_FLOAT shape { dim { size: -81 } dim { size: 14 } dim { size: 14 } dim { size: 256 } } }\n",
      "W0000 00:00:1733862198.317001     953 op_level_cost_estimator.cc:699] Error in PredictCost() for the op: op: \"CropAndResize\" attr { key: \"T\" value { type: DT_FLOAT } } attr { key: \"extrapolation_value\" value { f: 0 } } attr { key: \"method\" value { s: \"bilinear\" } } inputs { dtype: DT_FLOAT shape { dim { size: -96 } dim { size: -430 } dim { size: -431 } dim { size: 256 } } } inputs { dtype: DT_FLOAT shape { dim { size: -83 } dim { size: 4 } } } inputs { dtype: DT_INT32 shape { dim { size: -83 } } } inputs { dtype: DT_INT32 shape { dim { size: 2 } } value { dtype: DT_INT32 tensor_shape { dim { size: 2 } } int_val: 7 } } device { type: \"GPU\" vendor: \"NVIDIA\" model: \"NVIDIA GeForce RTX 4090\" frequency: 2520 num_cores: 128 environment { key: \"architecture\" value: \"8.9\" } environment { key: \"cuda\" value: \"12000\" } environment { key: \"cudnn\" value: \"8800\" } num_registers: 65536 l1_cache_size: 24576 l2_cache_size: 75497472 shared_memory_size_per_multiprocessor: 102400 memory_size: 22500343808 bandwidth: 1008096000 } outputs { dtype: DT_FLOAT shape { dim { size: -83 } dim { size: 7 } dim { size: 7 } dim { size: 256 } } }\n",
      "W0000 00:00:1733862198.317034     953 op_level_cost_estimator.cc:699] Error in PredictCost() for the op: op: \"CropAndResize\" attr { key: \"T\" value { type: DT_FLOAT } } attr { key: \"extrapolation_value\" value { f: 0 } } attr { key: \"method\" value { s: \"bilinear\" } } inputs { dtype: DT_FLOAT shape { dim { size: -96 } dim { size: -430 } dim { size: -431 } dim { size: 256 } } } inputs { dtype: DT_FLOAT shape { dim { size: -83 } dim { size: 4 } } } inputs { dtype: DT_INT32 shape { dim { size: -83 } } } inputs { dtype: DT_INT32 shape { dim { size: 2 } } value { dtype: DT_INT32 tensor_shape { dim { size: 2 } } int_val: 14 } } device { type: \"GPU\" vendor: \"NVIDIA\" model: \"NVIDIA GeForce RTX 4090\" frequency: 2520 num_cores: 128 environment { key: \"architecture\" value: \"8.9\" } environment { key: \"cuda\" value: \"12000\" } environment { key: \"cudnn\" value: \"8800\" } num_registers: 65536 l1_cache_size: 24576 l2_cache_size: 75497472 shared_memory_size_per_multiprocessor: 102400 memory_size: 22500343808 bandwidth: 1008096000 } outputs { dtype: DT_FLOAT shape { dim { size: -83 } dim { size: 14 } dim { size: 14 } dim { size: 256 } } }\n",
      "W0000 00:00:1733862198.317066     953 op_level_cost_estimator.cc:699] Error in PredictCost() for the op: op: \"CropAndResize\" attr { key: \"T\" value { type: DT_FLOAT } } attr { key: \"extrapolation_value\" value { f: 0 } } attr { key: \"method\" value { s: \"bilinear\" } } inputs { dtype: DT_FLOAT shape { dim { size: -96 } dim { size: -418 } dim { size: -419 } dim { size: 256 } } } inputs { dtype: DT_FLOAT shape { dim { size: -85 } dim { size: 4 } } } inputs { dtype: DT_INT32 shape { dim { size: -85 } } } inputs { dtype: DT_INT32 shape { dim { size: 2 } } value { dtype: DT_INT32 tensor_shape { dim { size: 2 } } int_val: 7 } } device { type: \"GPU\" vendor: \"NVIDIA\" model: \"NVIDIA GeForce RTX 4090\" frequency: 2520 num_cores: 128 environment { key: \"architecture\" value: \"8.9\" } environment { key: \"cuda\" value: \"12000\" } environment { key: \"cudnn\" value: \"8800\" } num_registers: 65536 l1_cache_size: 24576 l2_cache_size: 75497472 shared_memory_size_per_multiprocessor: 102400 memory_size: 22500343808 bandwidth: 1008096000 } outputs { dtype: DT_FLOAT shape { dim { size: -85 } dim { size: 7 } dim { size: 7 } dim { size: 256 } } }\n",
      "W0000 00:00:1733862198.317100     953 op_level_cost_estimator.cc:699] Error in PredictCost() for the op: op: \"CropAndResize\" attr { key: \"T\" value { type: DT_FLOAT } } attr { key: \"extrapolation_value\" value { f: 0 } } attr { key: \"method\" value { s: \"bilinear\" } } inputs { dtype: DT_FLOAT shape { dim { size: -96 } dim { size: -418 } dim { size: -419 } dim { size: 256 } } } inputs { dtype: DT_FLOAT shape { dim { size: -85 } dim { size: 4 } } } inputs { dtype: DT_INT32 shape { dim { size: -85 } } } inputs { dtype: DT_INT32 shape { dim { size: 2 } } value { dtype: DT_INT32 tensor_shape { dim { size: 2 } } int_val: 14 } } device { type: \"GPU\" vendor: \"NVIDIA\" model: \"NVIDIA GeForce RTX 4090\" frequency: 2520 num_cores: 128 environment { key: \"architecture\" value: \"8.9\" } environment { key: \"cuda\" value: \"12000\" } environment { key: \"cudnn\" value: \"8800\" } num_registers: 65536 l1_cache_size: 24576 l2_cache_size: 75497472 shared_memory_size_per_multiprocessor: 102400 memory_size: 22500343808 bandwidth: 1008096000 } outputs { dtype: DT_FLOAT shape { dim { size: -85 } dim { size: 14 } dim { size: 14 } dim { size: 256 } } }\n",
      "W0000 00:00:1733862198.317140     953 op_level_cost_estimator.cc:699] Error in PredictCost() for the op: op: \"CropAndResize\" attr { key: \"T\" value { type: DT_FLOAT } } attr { key: \"extrapolation_value\" value { f: 0 } } attr { key: \"method\" value { s: \"bilinear\" } } inputs { dtype: DT_FLOAT shape { dim { size: -96 } dim { size: -404 } dim { size: -405 } dim { size: 256 } } } inputs { dtype: DT_FLOAT shape { dim { size: -87 } dim { size: 4 } } } inputs { dtype: DT_INT32 shape { dim { size: -87 } } } inputs { dtype: DT_INT32 shape { dim { size: 2 } } value { dtype: DT_INT32 tensor_shape { dim { size: 2 } } int_val: 7 } } device { type: \"GPU\" vendor: \"NVIDIA\" model: \"NVIDIA GeForce RTX 4090\" frequency: 2520 num_cores: 128 environment { key: \"architecture\" value: \"8.9\" } environment { key: \"cuda\" value: \"12000\" } environment { key: \"cudnn\" value: \"8800\" } num_registers: 65536 l1_cache_size: 24576 l2_cache_size: 75497472 shared_memory_size_per_multiprocessor: 102400 memory_size: 22500343808 bandwidth: 1008096000 } outputs { dtype: DT_FLOAT shape { dim { size: -87 } dim { size: 7 } dim { size: 7 } dim { size: 256 } } }\n",
      "W0000 00:00:1733862198.317171     953 op_level_cost_estimator.cc:699] Error in PredictCost() for the op: op: \"CropAndResize\" attr { key: \"T\" value { type: DT_FLOAT } } attr { key: \"extrapolation_value\" value { f: 0 } } attr { key: \"method\" value { s: \"bilinear\" } } inputs { dtype: DT_FLOAT shape { dim { size: -96 } dim { size: -404 } dim { size: -405 } dim { size: 256 } } } inputs { dtype: DT_FLOAT shape { dim { size: -87 } dim { size: 4 } } } inputs { dtype: DT_INT32 shape { dim { size: -87 } } } inputs { dtype: DT_INT32 shape { dim { size: 2 } } value { dtype: DT_INT32 tensor_shape { dim { size: 2 } } int_val: 14 } } device { type: \"GPU\" vendor: \"NVIDIA\" model: \"NVIDIA GeForce RTX 4090\" frequency: 2520 num_cores: 128 environment { key: \"architecture\" value: \"8.9\" } environment { key: \"cuda\" value: \"12000\" } environment { key: \"cudnn\" value: \"8800\" } num_registers: 65536 l1_cache_size: 24576 l2_cache_size: 75497472 shared_memory_size_per_multiprocessor: 102400 memory_size: 22500343808 bandwidth: 1008096000 } outputs { dtype: DT_FLOAT shape { dim { size: -87 } dim { size: 14 } dim { size: 14 } dim { size: 256 } } }\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250/250 [==============================] - ETA: 0s - loss: 24.5044 - rpn_class_loss: 10.9030 - rpn_bbox_loss: 12.9161 - mrcnn_class_loss: 0.0207 - mrcnn_bbox_loss: 0.5421 - mrcnn_mask_loss: 0.2220"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1733862222.973442     953 op_level_cost_estimator.cc:699] Error in PredictCost() for the op: op: \"CropAndResize\" attr { key: \"T\" value { type: DT_FLOAT } } attr { key: \"extrapolation_value\" value { f: 0 } } attr { key: \"method\" value { s: \"bilinear\" } } inputs { dtype: DT_FLOAT shape { dim { size: -638 } dim { size: -121 } dim { size: -122 } dim { size: 1 } } } inputs { dtype: DT_FLOAT shape { dim { size: -24 } dim { size: 4 } } } inputs { dtype: DT_INT32 shape { dim { size: -24 } } } inputs { dtype: DT_INT32 shape { dim { size: 2 } } value { dtype: DT_INT32 tensor_shape { dim { size: 2 } } int_val: 28 } } device { type: \"GPU\" vendor: \"NVIDIA\" model: \"NVIDIA GeForce RTX 4090\" frequency: 2520 num_cores: 128 environment { key: \"architecture\" value: \"8.9\" } environment { key: \"cuda\" value: \"12000\" } environment { key: \"cudnn\" value: \"8800\" } num_registers: 65536 l1_cache_size: 24576 l2_cache_size: 75497472 shared_memory_size_per_multiprocessor: 102400 memory_size: 22500343808 bandwidth: 1008096000 } outputs { dtype: DT_FLOAT shape { dim { size: -24 } dim { size: 28 } dim { size: 28 } dim { size: 1 } } }\n",
      "W0000 00:00:1733862222.973569     953 op_level_cost_estimator.cc:699] Error in PredictCost() for the op: op: \"CropAndResize\" attr { key: \"T\" value { type: DT_FLOAT } } attr { key: \"extrapolation_value\" value { f: 0 } } attr { key: \"method\" value { s: \"bilinear\" } } inputs { dtype: DT_FLOAT shape { dim { size: -696 } dim { size: -130 } dim { size: -131 } dim { size: 1 } } } inputs { dtype: DT_FLOAT shape { dim { size: -42 } dim { size: 4 } } } inputs { dtype: DT_INT32 shape { dim { size: -42 } } } inputs { dtype: DT_INT32 shape { dim { size: 2 } } value { dtype: DT_INT32 tensor_shape { dim { size: 2 } } int_val: 28 } } device { type: \"GPU\" vendor: \"NVIDIA\" model: \"NVIDIA GeForce RTX 4090\" frequency: 2520 num_cores: 128 environment { key: \"architecture\" value: \"8.9\" } environment { key: \"cuda\" value: \"12000\" } environment { key: \"cudnn\" value: \"8800\" } num_registers: 65536 l1_cache_size: 24576 l2_cache_size: 75497472 shared_memory_size_per_multiprocessor: 102400 memory_size: 22500343808 bandwidth: 1008096000 } outputs { dtype: DT_FLOAT shape { dim { size: -42 } dim { size: 28 } dim { size: 28 } dim { size: 1 } } }\n",
      "W0000 00:00:1733862222.973632     953 op_level_cost_estimator.cc:699] Error in PredictCost() for the op: op: \"CropAndResize\" attr { key: \"T\" value { type: DT_FLOAT } } attr { key: \"extrapolation_value\" value { f: 0 } } attr { key: \"method\" value { s: \"bilinear\" } } inputs { dtype: DT_FLOAT shape { dim { size: -660 } dim { size: -124 } dim { size: -125 } dim { size: 1 } } } inputs { dtype: DT_FLOAT shape { dim { size: -30 } dim { size: 4 } } } inputs { dtype: DT_INT32 shape { dim { size: -30 } } } inputs { dtype: DT_INT32 shape { dim { size: 2 } } value { dtype: DT_INT32 tensor_shape { dim { size: 2 } } int_val: 28 } } device { type: \"GPU\" vendor: \"NVIDIA\" model: \"NVIDIA GeForce RTX 4090\" frequency: 2520 num_cores: 128 environment { key: \"architecture\" value: \"8.9\" } environment { key: \"cuda\" value: \"12000\" } environment { key: \"cudnn\" value: \"8800\" } num_registers: 65536 l1_cache_size: 24576 l2_cache_size: 75497472 shared_memory_size_per_multiprocessor: 102400 memory_size: 22500343808 bandwidth: 1008096000 } outputs { dtype: DT_FLOAT shape { dim { size: -30 } dim { size: 28 } dim { size: 28 } dim { size: 1 } } }\n",
      "W0000 00:00:1733862222.973678     953 op_level_cost_estimator.cc:699] Error in PredictCost() for the op: op: \"CropAndResize\" attr { key: \"T\" value { type: DT_FLOAT } } attr { key: \"extrapolation_value\" value { f: 0 } } attr { key: \"method\" value { s: \"bilinear\" } } inputs { dtype: DT_FLOAT shape { dim { size: -681 } dim { size: -127 } dim { size: -128 } dim { size: 1 } } } inputs { dtype: DT_FLOAT shape { dim { size: -36 } dim { size: 4 } } } inputs { dtype: DT_INT32 shape { dim { size: -36 } } } inputs { dtype: DT_INT32 shape { dim { size: 2 } } value { dtype: DT_INT32 tensor_shape { dim { size: 2 } } int_val: 28 } } device { type: \"GPU\" vendor: \"NVIDIA\" model: \"NVIDIA GeForce RTX 4090\" frequency: 2520 num_cores: 128 environment { key: \"architecture\" value: \"8.9\" } environment { key: \"cuda\" value: \"12000\" } environment { key: \"cudnn\" value: \"8800\" } num_registers: 65536 l1_cache_size: 24576 l2_cache_size: 75497472 shared_memory_size_per_multiprocessor: 102400 memory_size: 22500343808 bandwidth: 1008096000 } outputs { dtype: DT_FLOAT shape { dim { size: -36 } dim { size: 28 } dim { size: 28 } dim { size: 1 } } }\n",
      "W0000 00:00:1733862222.974993     953 op_level_cost_estimator.cc:699] Error in PredictCost() for the op: op: \"CropAndResize\" attr { key: \"T\" value { type: DT_FLOAT } } attr { key: \"extrapolation_value\" value { f: 0 } } attr { key: \"method\" value { s: \"bilinear\" } } inputs { dtype: DT_FLOAT shape { dim { size: -96 } dim { size: -440 } dim { size: -441 } dim { size: 256 } } } inputs { dtype: DT_FLOAT shape { dim { size: -81 } dim { size: 4 } } } inputs { dtype: DT_INT32 shape { dim { size: -81 } } } inputs { dtype: DT_INT32 shape { dim { size: 2 } } value { dtype: DT_INT32 tensor_shape { dim { size: 2 } } int_val: 7 } } device { type: \"GPU\" vendor: \"NVIDIA\" model: \"NVIDIA GeForce RTX 4090\" frequency: 2520 num_cores: 128 environment { key: \"architecture\" value: \"8.9\" } environment { key: \"cuda\" value: \"12000\" } environment { key: \"cudnn\" value: \"8800\" } num_registers: 65536 l1_cache_size: 24576 l2_cache_size: 75497472 shared_memory_size_per_multiprocessor: 102400 memory_size: 22500343808 bandwidth: 1008096000 } outputs { dtype: DT_FLOAT shape { dim { size: -81 } dim { size: 7 } dim { size: 7 } dim { size: 256 } } }\n",
      "W0000 00:00:1733862222.975037     953 op_level_cost_estimator.cc:699] Error in PredictCost() for the op: op: \"CropAndResize\" attr { key: \"T\" value { type: DT_FLOAT } } attr { key: \"extrapolation_value\" value { f: 0 } } attr { key: \"method\" value { s: \"bilinear\" } } inputs { dtype: DT_FLOAT shape { dim { size: -96 } dim { size: -440 } dim { size: -441 } dim { size: 256 } } } inputs { dtype: DT_FLOAT shape { dim { size: -81 } dim { size: 4 } } } inputs { dtype: DT_INT32 shape { dim { size: -81 } } } inputs { dtype: DT_INT32 shape { dim { size: 2 } } value { dtype: DT_INT32 tensor_shape { dim { size: 2 } } int_val: 14 } } device { type: \"GPU\" vendor: \"NVIDIA\" model: \"NVIDIA GeForce RTX 4090\" frequency: 2520 num_cores: 128 environment { key: \"architecture\" value: \"8.9\" } environment { key: \"cuda\" value: \"12000\" } environment { key: \"cudnn\" value: \"8800\" } num_registers: 65536 l1_cache_size: 24576 l2_cache_size: 75497472 shared_memory_size_per_multiprocessor: 102400 memory_size: 22500343808 bandwidth: 1008096000 } outputs { dtype: DT_FLOAT shape { dim { size: -81 } dim { size: 14 } dim { size: 14 } dim { size: 256 } } }\n",
      "W0000 00:00:1733862222.975071     953 op_level_cost_estimator.cc:699] Error in PredictCost() for the op: op: \"CropAndResize\" attr { key: \"T\" value { type: DT_FLOAT } } attr { key: \"extrapolation_value\" value { f: 0 } } attr { key: \"method\" value { s: \"bilinear\" } } inputs { dtype: DT_FLOAT shape { dim { size: -96 } dim { size: -430 } dim { size: -431 } dim { size: 256 } } } inputs { dtype: DT_FLOAT shape { dim { size: -83 } dim { size: 4 } } } inputs { dtype: DT_INT32 shape { dim { size: -83 } } } inputs { dtype: DT_INT32 shape { dim { size: 2 } } value { dtype: DT_INT32 tensor_shape { dim { size: 2 } } int_val: 7 } } device { type: \"GPU\" vendor: \"NVIDIA\" model: \"NVIDIA GeForce RTX 4090\" frequency: 2520 num_cores: 128 environment { key: \"architecture\" value: \"8.9\" } environment { key: \"cuda\" value: \"12000\" } environment { key: \"cudnn\" value: \"8800\" } num_registers: 65536 l1_cache_size: 24576 l2_cache_size: 75497472 shared_memory_size_per_multiprocessor: 102400 memory_size: 22500343808 bandwidth: 1008096000 } outputs { dtype: DT_FLOAT shape { dim { size: -83 } dim { size: 7 } dim { size: 7 } dim { size: 256 } } }\n",
      "W0000 00:00:1733862222.975102     953 op_level_cost_estimator.cc:699] Error in PredictCost() for the op: op: \"CropAndResize\" attr { key: \"T\" value { type: DT_FLOAT } } attr { key: \"extrapolation_value\" value { f: 0 } } attr { key: \"method\" value { s: \"bilinear\" } } inputs { dtype: DT_FLOAT shape { dim { size: -96 } dim { size: -430 } dim { size: -431 } dim { size: 256 } } } inputs { dtype: DT_FLOAT shape { dim { size: -83 } dim { size: 4 } } } inputs { dtype: DT_INT32 shape { dim { size: -83 } } } inputs { dtype: DT_INT32 shape { dim { size: 2 } } value { dtype: DT_INT32 tensor_shape { dim { size: 2 } } int_val: 14 } } device { type: \"GPU\" vendor: \"NVIDIA\" model: \"NVIDIA GeForce RTX 4090\" frequency: 2520 num_cores: 128 environment { key: \"architecture\" value: \"8.9\" } environment { key: \"cuda\" value: \"12000\" } environment { key: \"cudnn\" value: \"8800\" } num_registers: 65536 l1_cache_size: 24576 l2_cache_size: 75497472 shared_memory_size_per_multiprocessor: 102400 memory_size: 22500343808 bandwidth: 1008096000 } outputs { dtype: DT_FLOAT shape { dim { size: -83 } dim { size: 14 } dim { size: 14 } dim { size: 256 } } }\n",
      "W0000 00:00:1733862222.975133     953 op_level_cost_estimator.cc:699] Error in PredictCost() for the op: op: \"CropAndResize\" attr { key: \"T\" value { type: DT_FLOAT } } attr { key: \"extrapolation_value\" value { f: 0 } } attr { key: \"method\" value { s: \"bilinear\" } } inputs { dtype: DT_FLOAT shape { dim { size: -96 } dim { size: -418 } dim { size: -419 } dim { size: 256 } } } inputs { dtype: DT_FLOAT shape { dim { size: -85 } dim { size: 4 } } } inputs { dtype: DT_INT32 shape { dim { size: -85 } } } inputs { dtype: DT_INT32 shape { dim { size: 2 } } value { dtype: DT_INT32 tensor_shape { dim { size: 2 } } int_val: 7 } } device { type: \"GPU\" vendor: \"NVIDIA\" model: \"NVIDIA GeForce RTX 4090\" frequency: 2520 num_cores: 128 environment { key: \"architecture\" value: \"8.9\" } environment { key: \"cuda\" value: \"12000\" } environment { key: \"cudnn\" value: \"8800\" } num_registers: 65536 l1_cache_size: 24576 l2_cache_size: 75497472 shared_memory_size_per_multiprocessor: 102400 memory_size: 22500343808 bandwidth: 1008096000 } outputs { dtype: DT_FLOAT shape { dim { size: -85 } dim { size: 7 } dim { size: 7 } dim { size: 256 } } }\n",
      "W0000 00:00:1733862222.975163     953 op_level_cost_estimator.cc:699] Error in PredictCost() for the op: op: \"CropAndResize\" attr { key: \"T\" value { type: DT_FLOAT } } attr { key: \"extrapolation_value\" value { f: 0 } } attr { key: \"method\" value { s: \"bilinear\" } } inputs { dtype: DT_FLOAT shape { dim { size: -96 } dim { size: -418 } dim { size: -419 } dim { size: 256 } } } inputs { dtype: DT_FLOAT shape { dim { size: -85 } dim { size: 4 } } } inputs { dtype: DT_INT32 shape { dim { size: -85 } } } inputs { dtype: DT_INT32 shape { dim { size: 2 } } value { dtype: DT_INT32 tensor_shape { dim { size: 2 } } int_val: 14 } } device { type: \"GPU\" vendor: \"NVIDIA\" model: \"NVIDIA GeForce RTX 4090\" frequency: 2520 num_cores: 128 environment { key: \"architecture\" value: \"8.9\" } environment { key: \"cuda\" value: \"12000\" } environment { key: \"cudnn\" value: \"8800\" } num_registers: 65536 l1_cache_size: 24576 l2_cache_size: 75497472 shared_memory_size_per_multiprocessor: 102400 memory_size: 22500343808 bandwidth: 1008096000 } outputs { dtype: DT_FLOAT shape { dim { size: -85 } dim { size: 14 } dim { size: 14 } dim { size: 256 } } }\n",
      "W0000 00:00:1733862222.975202     953 op_level_cost_estimator.cc:699] Error in PredictCost() for the op: op: \"CropAndResize\" attr { key: \"T\" value { type: DT_FLOAT } } attr { key: \"extrapolation_value\" value { f: 0 } } attr { key: \"method\" value { s: \"bilinear\" } } inputs { dtype: DT_FLOAT shape { dim { size: -96 } dim { size: -404 } dim { size: -405 } dim { size: 256 } } } inputs { dtype: DT_FLOAT shape { dim { size: -87 } dim { size: 4 } } } inputs { dtype: DT_INT32 shape { dim { size: -87 } } } inputs { dtype: DT_INT32 shape { dim { size: 2 } } value { dtype: DT_INT32 tensor_shape { dim { size: 2 } } int_val: 7 } } device { type: \"GPU\" vendor: \"NVIDIA\" model: \"NVIDIA GeForce RTX 4090\" frequency: 2520 num_cores: 128 environment { key: \"architecture\" value: \"8.9\" } environment { key: \"cuda\" value: \"12000\" } environment { key: \"cudnn\" value: \"8800\" } num_registers: 65536 l1_cache_size: 24576 l2_cache_size: 75497472 shared_memory_size_per_multiprocessor: 102400 memory_size: 22500343808 bandwidth: 1008096000 } outputs { dtype: DT_FLOAT shape { dim { size: -87 } dim { size: 7 } dim { size: 7 } dim { size: 256 } } }\n",
      "W0000 00:00:1733862222.975233     953 op_level_cost_estimator.cc:699] Error in PredictCost() for the op: op: \"CropAndResize\" attr { key: \"T\" value { type: DT_FLOAT } } attr { key: \"extrapolation_value\" value { f: 0 } } attr { key: \"method\" value { s: \"bilinear\" } } inputs { dtype: DT_FLOAT shape { dim { size: -96 } dim { size: -404 } dim { size: -405 } dim { size: 256 } } } inputs { dtype: DT_FLOAT shape { dim { size: -87 } dim { size: 4 } } } inputs { dtype: DT_INT32 shape { dim { size: -87 } } } inputs { dtype: DT_INT32 shape { dim { size: 2 } } value { dtype: DT_INT32 tensor_shape { dim { size: 2 } } int_val: 14 } } device { type: \"GPU\" vendor: \"NVIDIA\" model: \"NVIDIA GeForce RTX 4090\" frequency: 2520 num_cores: 128 environment { key: \"architecture\" value: \"8.9\" } environment { key: \"cuda\" value: \"12000\" } environment { key: \"cudnn\" value: \"8800\" } num_registers: 65536 l1_cache_size: 24576 l2_cache_size: 75497472 shared_memory_size_per_multiprocessor: 102400 memory_size: 22500343808 bandwidth: 1008096000 } outputs { dtype: DT_FLOAT shape { dim { size: -87 } dim { size: 14 } dim { size: 14 } dim { size: 256 } } }\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250/250 [==============================] - 31s 96ms/step - loss: 24.5044 - rpn_class_loss: 10.9030 - rpn_bbox_loss: 12.9161 - mrcnn_class_loss: 0.0207 - mrcnn_bbox_loss: 0.5419 - mrcnn_mask_loss: 0.2218 - val_loss: 24.8072 - val_rpn_class_loss: 11.5093 - val_rpn_bbox_loss: 13.0021 - val_mrcnn_class_loss: 0.0154 - val_mrcnn_bbox_loss: 0.2166 - val_mrcnn_mask_loss: 0.0638\n"
     ]
    }
   ],
   "source": [
    "model.train(dataset_train, dataset_train, \n",
    "            epochs=EPOCHS[0], \n",
    "            augmentations=None, #augmentation, \n",
    "            custom_callbacks=[stop_early, warmup_with_reduce_lr_callback, csv_logger_head])\n",
    "history = model.keras_model.history.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selecting layers to train\n",
      "conv1                  (Conv2D)\n",
      "bn_conv1               (BatchNorm)\n",
      "res2a_branch2a         (Conv2D)\n",
      "bn2a_branch2a          (BatchNorm)\n",
      "res2a_branch2b         (Conv2D)\n",
      "bn2a_branch2b          (BatchNorm)\n",
      "res2a_branch2c         (Conv2D)\n",
      "res2a_branch1          (Conv2D)\n",
      "bn2a_branch2c          (BatchNorm)\n",
      "bn2a_branch1           (BatchNorm)\n",
      "res2b_branch2a         (Conv2D)\n",
      "bn2b_branch2a          (BatchNorm)\n",
      "res2b_branch2b         (Conv2D)\n",
      "bn2b_branch2b          (BatchNorm)\n",
      "res2b_branch2c         (Conv2D)\n",
      "bn2b_branch2c          (BatchNorm)\n",
      "res2c_branch2a         (Conv2D)\n",
      "bn2c_branch2a          (BatchNorm)\n",
      "res2c_branch2b         (Conv2D)\n",
      "bn2c_branch2b          (BatchNorm)\n",
      "res2c_branch2c         (Conv2D)\n",
      "bn2c_branch2c          (BatchNorm)\n",
      "res3a_branch2a         (Conv2D)\n",
      "bn3a_branch2a          (BatchNorm)\n",
      "res3a_branch2b         (Conv2D)\n",
      "bn3a_branch2b          (BatchNorm)\n",
      "res3a_branch2c         (Conv2D)\n",
      "res3a_branch1          (Conv2D)\n",
      "bn3a_branch2c          (BatchNorm)\n",
      "bn3a_branch1           (BatchNorm)\n",
      "res3b_branch2a         (Conv2D)\n",
      "bn3b_branch2a          (BatchNorm)\n",
      "res3b_branch2b         (Conv2D)\n",
      "bn3b_branch2b          (BatchNorm)\n",
      "res3b_branch2c         (Conv2D)\n",
      "bn3b_branch2c          (BatchNorm)\n",
      "res3c_branch2a         (Conv2D)\n",
      "bn3c_branch2a          (BatchNorm)\n",
      "res3c_branch2b         (Conv2D)\n",
      "bn3c_branch2b          (BatchNorm)\n",
      "res3c_branch2c         (Conv2D)\n",
      "bn3c_branch2c          (BatchNorm)\n",
      "res3d_branch2a         (Conv2D)\n",
      "bn3d_branch2a          (BatchNorm)\n",
      "res3d_branch2b         (Conv2D)\n",
      "bn3d_branch2b          (BatchNorm)\n",
      "res3d_branch2c         (Conv2D)\n",
      "bn3d_branch2c          (BatchNorm)\n",
      "res4a_branch2a         (Conv2D)\n",
      "bn4a_branch2a          (BatchNorm)\n",
      "res4a_branch2b         (Conv2D)\n",
      "bn4a_branch2b          (BatchNorm)\n",
      "res4a_branch2c         (Conv2D)\n",
      "res4a_branch1          (Conv2D)\n",
      "bn4a_branch2c          (BatchNorm)\n",
      "bn4a_branch1           (BatchNorm)\n",
      "res4b_branch2a         (Conv2D)\n",
      "bn4b_branch2a          (BatchNorm)\n",
      "res4b_branch2b         (Conv2D)\n",
      "bn4b_branch2b          (BatchNorm)\n",
      "res4b_branch2c         (Conv2D)\n",
      "bn4b_branch2c          (BatchNorm)\n",
      "res4c_branch2a         (Conv2D)\n",
      "bn4c_branch2a          (BatchNorm)\n",
      "res4c_branch2b         (Conv2D)\n",
      "bn4c_branch2b          (BatchNorm)\n",
      "res4c_branch2c         (Conv2D)\n",
      "bn4c_branch2c          (BatchNorm)\n",
      "res4d_branch2a         (Conv2D)\n",
      "bn4d_branch2a          (BatchNorm)\n",
      "res4d_branch2b         (Conv2D)\n",
      "bn4d_branch2b          (BatchNorm)\n",
      "res4d_branch2c         (Conv2D)\n",
      "bn4d_branch2c          (BatchNorm)\n",
      "res4e_branch2a         (Conv2D)\n",
      "bn4e_branch2a          (BatchNorm)\n",
      "res4e_branch2b         (Conv2D)\n",
      "bn4e_branch2b          (BatchNorm)\n",
      "res4e_branch2c         (Conv2D)\n",
      "bn4e_branch2c          (BatchNorm)\n",
      "res4f_branch2a         (Conv2D)\n",
      "bn4f_branch2a          (BatchNorm)\n",
      "res4f_branch2b         (Conv2D)\n",
      "bn4f_branch2b          (BatchNorm)\n",
      "res4f_branch2c         (Conv2D)\n",
      "bn4f_branch2c          (BatchNorm)\n",
      "res4g_branch2a         (Conv2D)\n",
      "bn4g_branch2a          (BatchNorm)\n",
      "res4g_branch2b         (Conv2D)\n",
      "bn4g_branch2b          (BatchNorm)\n",
      "res4g_branch2c         (Conv2D)\n",
      "bn4g_branch2c          (BatchNorm)\n",
      "res4h_branch2a         (Conv2D)\n",
      "bn4h_branch2a          (BatchNorm)\n",
      "res4h_branch2b         (Conv2D)\n",
      "bn4h_branch2b          (BatchNorm)\n",
      "res4h_branch2c         (Conv2D)\n",
      "bn4h_branch2c          (BatchNorm)\n",
      "res4i_branch2a         (Conv2D)\n",
      "bn4i_branch2a          (BatchNorm)\n",
      "res4i_branch2b         (Conv2D)\n",
      "bn4i_branch2b          (BatchNorm)\n",
      "res4i_branch2c         (Conv2D)\n",
      "bn4i_branch2c          (BatchNorm)\n",
      "res4j_branch2a         (Conv2D)\n",
      "bn4j_branch2a          (BatchNorm)\n",
      "res4j_branch2b         (Conv2D)\n",
      "bn4j_branch2b          (BatchNorm)\n",
      "res4j_branch2c         (Conv2D)\n",
      "bn4j_branch2c          (BatchNorm)\n",
      "res4k_branch2a         (Conv2D)\n",
      "bn4k_branch2a          (BatchNorm)\n",
      "res4k_branch2b         (Conv2D)\n",
      "bn4k_branch2b          (BatchNorm)\n",
      "res4k_branch2c         (Conv2D)\n",
      "bn4k_branch2c          (BatchNorm)\n",
      "res4l_branch2a         (Conv2D)\n",
      "bn4l_branch2a          (BatchNorm)\n",
      "res4l_branch2b         (Conv2D)\n",
      "bn4l_branch2b          (BatchNorm)\n",
      "res4l_branch2c         (Conv2D)\n",
      "bn4l_branch2c          (BatchNorm)\n",
      "res4m_branch2a         (Conv2D)\n",
      "bn4m_branch2a          (BatchNorm)\n",
      "res4m_branch2b         (Conv2D)\n",
      "bn4m_branch2b          (BatchNorm)\n",
      "res4m_branch2c         (Conv2D)\n",
      "bn4m_branch2c          (BatchNorm)\n",
      "res4n_branch2a         (Conv2D)\n",
      "bn4n_branch2a          (BatchNorm)\n",
      "res4n_branch2b         (Conv2D)\n",
      "bn4n_branch2b          (BatchNorm)\n",
      "res4n_branch2c         (Conv2D)\n",
      "bn4n_branch2c          (BatchNorm)\n",
      "res4o_branch2a         (Conv2D)\n",
      "bn4o_branch2a          (BatchNorm)\n",
      "res4o_branch2b         (Conv2D)\n",
      "bn4o_branch2b          (BatchNorm)\n",
      "res4o_branch2c         (Conv2D)\n",
      "bn4o_branch2c          (BatchNorm)\n",
      "res4p_branch2a         (Conv2D)\n",
      "bn4p_branch2a          (BatchNorm)\n",
      "res4p_branch2b         (Conv2D)\n",
      "bn4p_branch2b          (BatchNorm)\n",
      "res4p_branch2c         (Conv2D)\n",
      "bn4p_branch2c          (BatchNorm)\n",
      "res4q_branch2a         (Conv2D)\n",
      "bn4q_branch2a          (BatchNorm)\n",
      "res4q_branch2b         (Conv2D)\n",
      "bn4q_branch2b          (BatchNorm)\n",
      "res4q_branch2c         (Conv2D)\n",
      "bn4q_branch2c          (BatchNorm)\n",
      "res4r_branch2a         (Conv2D)\n",
      "bn4r_branch2a          (BatchNorm)\n",
      "res4r_branch2b         (Conv2D)\n",
      "bn4r_branch2b          (BatchNorm)\n",
      "res4r_branch2c         (Conv2D)\n",
      "bn4r_branch2c          (BatchNorm)\n",
      "res4s_branch2a         (Conv2D)\n",
      "bn4s_branch2a          (BatchNorm)\n",
      "res4s_branch2b         (Conv2D)\n",
      "bn4s_branch2b          (BatchNorm)\n",
      "res4s_branch2c         (Conv2D)\n",
      "bn4s_branch2c          (BatchNorm)\n",
      "res4t_branch2a         (Conv2D)\n",
      "bn4t_branch2a          (BatchNorm)\n",
      "res4t_branch2b         (Conv2D)\n",
      "bn4t_branch2b          (BatchNorm)\n",
      "res4t_branch2c         (Conv2D)\n",
      "bn4t_branch2c          (BatchNorm)\n",
      "res4u_branch2a         (Conv2D)\n",
      "bn4u_branch2a          (BatchNorm)\n",
      "res4u_branch2b         (Conv2D)\n",
      "bn4u_branch2b          (BatchNorm)\n",
      "res4u_branch2c         (Conv2D)\n",
      "bn4u_branch2c          (BatchNorm)\n",
      "res4v_branch2a         (Conv2D)\n",
      "bn4v_branch2a          (BatchNorm)\n",
      "res4v_branch2b         (Conv2D)\n",
      "bn4v_branch2b          (BatchNorm)\n",
      "res4v_branch2c         (Conv2D)\n",
      "bn4v_branch2c          (BatchNorm)\n",
      "res4w_branch2a         (Conv2D)\n",
      "bn4w_branch2a          (BatchNorm)\n",
      "res4w_branch2b         (Conv2D)\n",
      "bn4w_branch2b          (BatchNorm)\n",
      "res4w_branch2c         (Conv2D)\n",
      "bn4w_branch2c          (BatchNorm)\n",
      "res5a_branch2a         (Conv2D)\n",
      "bn5a_branch2a          (BatchNorm)\n",
      "res5a_branch2b         (Conv2D)\n",
      "bn5a_branch2b          (BatchNorm)\n",
      "res5a_branch2c         (Conv2D)\n",
      "res5a_branch1          (Conv2D)\n",
      "bn5a_branch2c          (BatchNorm)\n",
      "bn5a_branch1           (BatchNorm)\n",
      "res5b_branch2a         (Conv2D)\n",
      "bn5b_branch2a          (BatchNorm)\n",
      "res5b_branch2b         (Conv2D)\n",
      "bn5b_branch2b          (BatchNorm)\n",
      "res5b_branch2c         (Conv2D)\n",
      "bn5b_branch2c          (BatchNorm)\n",
      "res5c_branch2a         (Conv2D)\n",
      "bn5c_branch2a          (BatchNorm)\n",
      "res5c_branch2b         (Conv2D)\n",
      "bn5c_branch2b          (BatchNorm)\n",
      "res5c_branch2c         (Conv2D)\n",
      "bn5c_branch2c          (BatchNorm)\n",
      "fpn_c5p5               (Conv2D)\n",
      "fpn_c4p4               (Conv2D)\n",
      "fpn_c3p3               (Conv2D)\n",
      "fpn_c2p2               (Conv2D)\n",
      "fpn_p5                 (Conv2D)\n",
      "fpn_p2                 (Conv2D)\n",
      "fpn_p3                 (Conv2D)\n",
      "fpn_p4                 (Conv2D)\n",
      "rpn_model              (Functional)\n",
      "anchors                (ConstLayer)\n",
      "mrcnn_mask_conv1       (TimeDistributed)\n",
      "mrcnn_mask_bn1         (TimeDistributed)\n",
      "mrcnn_mask_conv2       (TimeDistributed)\n",
      "mrcnn_mask_bn2         (TimeDistributed)\n",
      "mrcnn_class_conv1      (TimeDistributed)\n",
      "mrcnn_class_bn1        (TimeDistributed)\n",
      "mrcnn_mask_conv3       (TimeDistributed)\n",
      "mrcnn_mask_bn3         (TimeDistributed)\n",
      "mrcnn_class_conv2      (TimeDistributed)\n",
      "mrcnn_class_bn2        (TimeDistributed)\n",
      "mrcnn_mask_conv4       (TimeDistributed)\n",
      "mrcnn_mask_bn4         (TimeDistributed)\n",
      "mrcnn_bbox_fc          (TimeDistributed)\n",
      "mrcnn_mask_deconv      (TimeDistributed)\n",
      "mrcnn_class_logits     (TimeDistributed)\n",
      "mrcnn_mask             (TimeDistributed)\n",
      "Model: \"mask_rcnn\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_image (InputLayer)    [(None, None, None, 3)]      0         []                            \n",
      "                                                                                                  \n",
      " zero_padding2d_1 (ZeroPadd  (None, None, None, 3)        0         ['input_image[0][0]']         \n",
      " ing2D)                                                                                           \n",
      "                                                                                                  \n",
      " conv1 (Conv2D)              (None, None, None, 64)       9472      ['zero_padding2d_1[0][0]']    \n",
      "                                                                                                  \n",
      " bn_conv1 (BatchNorm)        (None, None, None, 64)       256       ['conv1[0][0]']               \n",
      "                                                                                                  \n",
      " activation_17 (Activation)  (None, None, None, 64)       0         ['bn_conv1[0][0]']            \n",
      "                                                                                                  \n",
      " max_pooling2d_1 (MaxPoolin  (None, None, None, 64)       0         ['activation_17[0][0]']       \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " res2a_branch2a (Conv2D)     (None, None, None, 64)       4160      ['max_pooling2d_1[0][0]']     \n",
      "                                                                                                  \n",
      " bn2a_branch2a (BatchNorm)   (None, None, None, 64)       256       ['res2a_branch2a[0][0]']      \n",
      "                                                                                                  \n",
      " activation_18 (Activation)  (None, None, None, 64)       0         ['bn2a_branch2a[0][0]']       \n",
      "                                                                                                  \n",
      " res2a_branch2b (Conv2D)     (None, None, None, 64)       36928     ['activation_18[0][0]']       \n",
      "                                                                                                  \n",
      " bn2a_branch2b (BatchNorm)   (None, None, None, 64)       256       ['res2a_branch2b[0][0]']      \n",
      "                                                                                                  \n",
      " activation_19 (Activation)  (None, None, None, 64)       0         ['bn2a_branch2b[0][0]']       \n",
      "                                                                                                  \n",
      " res2a_branch2c (Conv2D)     (None, None, None, 256)      16640     ['activation_19[0][0]']       \n",
      "                                                                                                  \n",
      " res2a_branch1 (Conv2D)      (None, None, None, 256)      16640     ['max_pooling2d_1[0][0]']     \n",
      "                                                                                                  \n",
      " bn2a_branch2c (BatchNorm)   (None, None, None, 256)      1024      ['res2a_branch2c[0][0]']      \n",
      "                                                                                                  \n",
      " bn2a_branch1 (BatchNorm)    (None, None, None, 256)      1024      ['res2a_branch1[0][0]']       \n",
      "                                                                                                  \n",
      " add_7 (Add)                 (None, None, None, 256)      0         ['bn2a_branch2c[0][0]',       \n",
      "                                                                     'bn2a_branch1[0][0]']        \n",
      "                                                                                                  \n",
      " res2a_out (Activation)      (None, None, None, 256)      0         ['add_7[0][0]']               \n",
      "                                                                                                  \n",
      " res2b_branch2a (Conv2D)     (None, None, None, 64)       16448     ['res2a_out[0][0]']           \n",
      "                                                                                                  \n",
      " bn2b_branch2a (BatchNorm)   (None, None, None, 64)       256       ['res2b_branch2a[0][0]']      \n",
      "                                                                                                  \n",
      " activation_20 (Activation)  (None, None, None, 64)       0         ['bn2b_branch2a[0][0]']       \n",
      "                                                                                                  \n",
      " res2b_branch2b (Conv2D)     (None, None, None, 64)       36928     ['activation_20[0][0]']       \n",
      "                                                                                                  \n",
      " bn2b_branch2b (BatchNorm)   (None, None, None, 64)       256       ['res2b_branch2b[0][0]']      \n",
      "                                                                                                  \n",
      " activation_21 (Activation)  (None, None, None, 64)       0         ['bn2b_branch2b[0][0]']       \n",
      "                                                                                                  \n",
      " res2b_branch2c (Conv2D)     (None, None, None, 256)      16640     ['activation_21[0][0]']       \n",
      "                                                                                                  \n",
      " bn2b_branch2c (BatchNorm)   (None, None, None, 256)      1024      ['res2b_branch2c[0][0]']      \n",
      "                                                                                                  \n",
      " add_8 (Add)                 (None, None, None, 256)      0         ['bn2b_branch2c[0][0]',       \n",
      "                                                                     'res2a_out[0][0]']           \n",
      "                                                                                                  \n",
      " res2b_out (Activation)      (None, None, None, 256)      0         ['add_8[0][0]']               \n",
      "                                                                                                  \n",
      " res2c_branch2a (Conv2D)     (None, None, None, 64)       16448     ['res2b_out[0][0]']           \n",
      "                                                                                                  \n",
      " bn2c_branch2a (BatchNorm)   (None, None, None, 64)       256       ['res2c_branch2a[0][0]']      \n",
      "                                                                                                  \n",
      " activation_22 (Activation)  (None, None, None, 64)       0         ['bn2c_branch2a[0][0]']       \n",
      "                                                                                                  \n",
      " res2c_branch2b (Conv2D)     (None, None, None, 64)       36928     ['activation_22[0][0]']       \n",
      "                                                                                                  \n",
      " bn2c_branch2b (BatchNorm)   (None, None, None, 64)       256       ['res2c_branch2b[0][0]']      \n",
      "                                                                                                  \n",
      " activation_23 (Activation)  (None, None, None, 64)       0         ['bn2c_branch2b[0][0]']       \n",
      "                                                                                                  \n",
      " res2c_branch2c (Conv2D)     (None, None, None, 256)      16640     ['activation_23[0][0]']       \n",
      "                                                                                                  \n",
      " bn2c_branch2c (BatchNorm)   (None, None, None, 256)      1024      ['res2c_branch2c[0][0]']      \n",
      "                                                                                                  \n",
      " add_9 (Add)                 (None, None, None, 256)      0         ['bn2c_branch2c[0][0]',       \n",
      "                                                                     'res2b_out[0][0]']           \n",
      "                                                                                                  \n",
      " res2c_out (Activation)      (None, None, None, 256)      0         ['add_9[0][0]']               \n",
      "                                                                                                  \n",
      " res3a_branch2a (Conv2D)     (None, None, None, 128)      32896     ['res2c_out[0][0]']           \n",
      "                                                                                                  \n",
      " bn3a_branch2a (BatchNorm)   (None, None, None, 128)      512       ['res3a_branch2a[0][0]']      \n",
      "                                                                                                  \n",
      " activation_24 (Activation)  (None, None, None, 128)      0         ['bn3a_branch2a[0][0]']       \n",
      "                                                                                                  \n",
      " res3a_branch2b (Conv2D)     (None, None, None, 128)      147584    ['activation_24[0][0]']       \n",
      "                                                                                                  \n",
      " bn3a_branch2b (BatchNorm)   (None, None, None, 128)      512       ['res3a_branch2b[0][0]']      \n",
      "                                                                                                  \n",
      " activation_25 (Activation)  (None, None, None, 128)      0         ['bn3a_branch2b[0][0]']       \n",
      "                                                                                                  \n",
      " res3a_branch2c (Conv2D)     (None, None, None, 512)      66048     ['activation_25[0][0]']       \n",
      "                                                                                                  \n",
      " res3a_branch1 (Conv2D)      (None, None, None, 512)      131584    ['res2c_out[0][0]']           \n",
      "                                                                                                  \n",
      " bn3a_branch2c (BatchNorm)   (None, None, None, 512)      2048      ['res3a_branch2c[0][0]']      \n",
      "                                                                                                  \n",
      " bn3a_branch1 (BatchNorm)    (None, None, None, 512)      2048      ['res3a_branch1[0][0]']       \n",
      "                                                                                                  \n",
      " add_10 (Add)                (None, None, None, 512)      0         ['bn3a_branch2c[0][0]',       \n",
      "                                                                     'bn3a_branch1[0][0]']        \n",
      "                                                                                                  \n",
      " res3a_out (Activation)      (None, None, None, 512)      0         ['add_10[0][0]']              \n",
      "                                                                                                  \n",
      " res3b_branch2a (Conv2D)     (None, None, None, 128)      65664     ['res3a_out[0][0]']           \n",
      "                                                                                                  \n",
      " bn3b_branch2a (BatchNorm)   (None, None, None, 128)      512       ['res3b_branch2a[0][0]']      \n",
      "                                                                                                  \n",
      " activation_26 (Activation)  (None, None, None, 128)      0         ['bn3b_branch2a[0][0]']       \n",
      "                                                                                                  \n",
      " res3b_branch2b (Conv2D)     (None, None, None, 128)      147584    ['activation_26[0][0]']       \n",
      "                                                                                                  \n",
      " bn3b_branch2b (BatchNorm)   (None, None, None, 128)      512       ['res3b_branch2b[0][0]']      \n",
      "                                                                                                  \n",
      " activation_27 (Activation)  (None, None, None, 128)      0         ['bn3b_branch2b[0][0]']       \n",
      "                                                                                                  \n",
      " res3b_branch2c (Conv2D)     (None, None, None, 512)      66048     ['activation_27[0][0]']       \n",
      "                                                                                                  \n",
      " bn3b_branch2c (BatchNorm)   (None, None, None, 512)      2048      ['res3b_branch2c[0][0]']      \n",
      "                                                                                                  \n",
      " add_11 (Add)                (None, None, None, 512)      0         ['bn3b_branch2c[0][0]',       \n",
      "                                                                     'res3a_out[0][0]']           \n",
      "                                                                                                  \n",
      " res3b_out (Activation)      (None, None, None, 512)      0         ['add_11[0][0]']              \n",
      "                                                                                                  \n",
      " res3c_branch2a (Conv2D)     (None, None, None, 128)      65664     ['res3b_out[0][0]']           \n",
      "                                                                                                  \n",
      " bn3c_branch2a (BatchNorm)   (None, None, None, 128)      512       ['res3c_branch2a[0][0]']      \n",
      "                                                                                                  \n",
      " activation_28 (Activation)  (None, None, None, 128)      0         ['bn3c_branch2a[0][0]']       \n",
      "                                                                                                  \n",
      " res3c_branch2b (Conv2D)     (None, None, None, 128)      147584    ['activation_28[0][0]']       \n",
      "                                                                                                  \n",
      " bn3c_branch2b (BatchNorm)   (None, None, None, 128)      512       ['res3c_branch2b[0][0]']      \n",
      "                                                                                                  \n",
      " activation_29 (Activation)  (None, None, None, 128)      0         ['bn3c_branch2b[0][0]']       \n",
      "                                                                                                  \n",
      " res3c_branch2c (Conv2D)     (None, None, None, 512)      66048     ['activation_29[0][0]']       \n",
      "                                                                                                  \n",
      " bn3c_branch2c (BatchNorm)   (None, None, None, 512)      2048      ['res3c_branch2c[0][0]']      \n",
      "                                                                                                  \n",
      " add_12 (Add)                (None, None, None, 512)      0         ['bn3c_branch2c[0][0]',       \n",
      "                                                                     'res3b_out[0][0]']           \n",
      "                                                                                                  \n",
      " res3c_out (Activation)      (None, None, None, 512)      0         ['add_12[0][0]']              \n",
      "                                                                                                  \n",
      " res3d_branch2a (Conv2D)     (None, None, None, 128)      65664     ['res3c_out[0][0]']           \n",
      "                                                                                                  \n",
      " bn3d_branch2a (BatchNorm)   (None, None, None, 128)      512       ['res3d_branch2a[0][0]']      \n",
      "                                                                                                  \n",
      " activation_30 (Activation)  (None, None, None, 128)      0         ['bn3d_branch2a[0][0]']       \n",
      "                                                                                                  \n",
      " res3d_branch2b (Conv2D)     (None, None, None, 128)      147584    ['activation_30[0][0]']       \n",
      "                                                                                                  \n",
      " bn3d_branch2b (BatchNorm)   (None, None, None, 128)      512       ['res3d_branch2b[0][0]']      \n",
      "                                                                                                  \n",
      " activation_31 (Activation)  (None, None, None, 128)      0         ['bn3d_branch2b[0][0]']       \n",
      "                                                                                                  \n",
      " res3d_branch2c (Conv2D)     (None, None, None, 512)      66048     ['activation_31[0][0]']       \n",
      "                                                                                                  \n",
      " bn3d_branch2c (BatchNorm)   (None, None, None, 512)      2048      ['res3d_branch2c[0][0]']      \n",
      "                                                                                                  \n",
      " add_13 (Add)                (None, None, None, 512)      0         ['bn3d_branch2c[0][0]',       \n",
      "                                                                     'res3c_out[0][0]']           \n",
      "                                                                                                  \n",
      " res3d_out (Activation)      (None, None, None, 512)      0         ['add_13[0][0]']              \n",
      "                                                                                                  \n",
      " res4a_branch2a (Conv2D)     (None, None, None, 256)      131328    ['res3d_out[0][0]']           \n",
      "                                                                                                  \n",
      " bn4a_branch2a (BatchNorm)   (None, None, None, 256)      1024      ['res4a_branch2a[0][0]']      \n",
      "                                                                                                  \n",
      " activation_32 (Activation)  (None, None, None, 256)      0         ['bn4a_branch2a[0][0]']       \n",
      "                                                                                                  \n",
      " res4a_branch2b (Conv2D)     (None, None, None, 256)      590080    ['activation_32[0][0]']       \n",
      "                                                                                                  \n",
      " bn4a_branch2b (BatchNorm)   (None, None, None, 256)      1024      ['res4a_branch2b[0][0]']      \n",
      "                                                                                                  \n",
      " activation_33 (Activation)  (None, None, None, 256)      0         ['bn4a_branch2b[0][0]']       \n",
      "                                                                                                  \n",
      " res4a_branch2c (Conv2D)     (None, None, None, 1024)     263168    ['activation_33[0][0]']       \n",
      "                                                                                                  \n",
      " res4a_branch1 (Conv2D)      (None, None, None, 1024)     525312    ['res3d_out[0][0]']           \n",
      "                                                                                                  \n",
      " bn4a_branch2c (BatchNorm)   (None, None, None, 1024)     4096      ['res4a_branch2c[0][0]']      \n",
      "                                                                                                  \n",
      " bn4a_branch1 (BatchNorm)    (None, None, None, 1024)     4096      ['res4a_branch1[0][0]']       \n",
      "                                                                                                  \n",
      " add_14 (Add)                (None, None, None, 1024)     0         ['bn4a_branch2c[0][0]',       \n",
      "                                                                     'bn4a_branch1[0][0]']        \n",
      "                                                                                                  \n",
      " res4a_out (Activation)      (None, None, None, 1024)     0         ['add_14[0][0]']              \n",
      "                                                                                                  \n",
      " res4b_branch2a (Conv2D)     (None, None, None, 256)      262400    ['res4a_out[0][0]']           \n",
      "                                                                                                  \n",
      " bn4b_branch2a (BatchNorm)   (None, None, None, 256)      1024      ['res4b_branch2a[0][0]']      \n",
      "                                                                                                  \n",
      " activation_34 (Activation)  (None, None, None, 256)      0         ['bn4b_branch2a[0][0]']       \n",
      "                                                                                                  \n",
      " res4b_branch2b (Conv2D)     (None, None, None, 256)      590080    ['activation_34[0][0]']       \n",
      "                                                                                                  \n",
      " bn4b_branch2b (BatchNorm)   (None, None, None, 256)      1024      ['res4b_branch2b[0][0]']      \n",
      "                                                                                                  \n",
      " activation_35 (Activation)  (None, None, None, 256)      0         ['bn4b_branch2b[0][0]']       \n",
      "                                                                                                  \n",
      " res4b_branch2c (Conv2D)     (None, None, None, 1024)     263168    ['activation_35[0][0]']       \n",
      "                                                                                                  \n",
      " bn4b_branch2c (BatchNorm)   (None, None, None, 1024)     4096      ['res4b_branch2c[0][0]']      \n",
      "                                                                                                  \n",
      " add_15 (Add)                (None, None, None, 1024)     0         ['bn4b_branch2c[0][0]',       \n",
      "                                                                     'res4a_out[0][0]']           \n",
      "                                                                                                  \n",
      " res4b_out (Activation)      (None, None, None, 1024)     0         ['add_15[0][0]']              \n",
      "                                                                                                  \n",
      " res4c_branch2a (Conv2D)     (None, None, None, 256)      262400    ['res4b_out[0][0]']           \n",
      "                                                                                                  \n",
      " bn4c_branch2a (BatchNorm)   (None, None, None, 256)      1024      ['res4c_branch2a[0][0]']      \n",
      "                                                                                                  \n",
      " activation_36 (Activation)  (None, None, None, 256)      0         ['bn4c_branch2a[0][0]']       \n",
      "                                                                                                  \n",
      " res4c_branch2b (Conv2D)     (None, None, None, 256)      590080    ['activation_36[0][0]']       \n",
      "                                                                                                  \n",
      " bn4c_branch2b (BatchNorm)   (None, None, None, 256)      1024      ['res4c_branch2b[0][0]']      \n",
      "                                                                                                  \n",
      " activation_37 (Activation)  (None, None, None, 256)      0         ['bn4c_branch2b[0][0]']       \n",
      "                                                                                                  \n",
      " res4c_branch2c (Conv2D)     (None, None, None, 1024)     263168    ['activation_37[0][0]']       \n",
      "                                                                                                  \n",
      " bn4c_branch2c (BatchNorm)   (None, None, None, 1024)     4096      ['res4c_branch2c[0][0]']      \n",
      "                                                                                                  \n",
      " add_16 (Add)                (None, None, None, 1024)     0         ['bn4c_branch2c[0][0]',       \n",
      "                                                                     'res4b_out[0][0]']           \n",
      "                                                                                                  \n",
      " res4c_out (Activation)      (None, None, None, 1024)     0         ['add_16[0][0]']              \n",
      "                                                                                                  \n",
      " res4d_branch2a (Conv2D)     (None, None, None, 256)      262400    ['res4c_out[0][0]']           \n",
      "                                                                                                  \n",
      " bn4d_branch2a (BatchNorm)   (None, None, None, 256)      1024      ['res4d_branch2a[0][0]']      \n",
      "                                                                                                  \n",
      " activation_38 (Activation)  (None, None, None, 256)      0         ['bn4d_branch2a[0][0]']       \n",
      "                                                                                                  \n",
      " res4d_branch2b (Conv2D)     (None, None, None, 256)      590080    ['activation_38[0][0]']       \n",
      "                                                                                                  \n",
      " bn4d_branch2b (BatchNorm)   (None, None, None, 256)      1024      ['res4d_branch2b[0][0]']      \n",
      "                                                                                                  \n",
      " activation_39 (Activation)  (None, None, None, 256)      0         ['bn4d_branch2b[0][0]']       \n",
      "                                                                                                  \n",
      " res4d_branch2c (Conv2D)     (None, None, None, 1024)     263168    ['activation_39[0][0]']       \n",
      "                                                                                                  \n",
      " bn4d_branch2c (BatchNorm)   (None, None, None, 1024)     4096      ['res4d_branch2c[0][0]']      \n",
      "                                                                                                  \n",
      " add_17 (Add)                (None, None, None, 1024)     0         ['bn4d_branch2c[0][0]',       \n",
      "                                                                     'res4c_out[0][0]']           \n",
      "                                                                                                  \n",
      " res4d_out (Activation)      (None, None, None, 1024)     0         ['add_17[0][0]']              \n",
      "                                                                                                  \n",
      " res4e_branch2a (Conv2D)     (None, None, None, 256)      262400    ['res4d_out[0][0]']           \n",
      "                                                                                                  \n",
      " bn4e_branch2a (BatchNorm)   (None, None, None, 256)      1024      ['res4e_branch2a[0][0]']      \n",
      "                                                                                                  \n",
      " activation_40 (Activation)  (None, None, None, 256)      0         ['bn4e_branch2a[0][0]']       \n",
      "                                                                                                  \n",
      " res4e_branch2b (Conv2D)     (None, None, None, 256)      590080    ['activation_40[0][0]']       \n",
      "                                                                                                  \n",
      " bn4e_branch2b (BatchNorm)   (None, None, None, 256)      1024      ['res4e_branch2b[0][0]']      \n",
      "                                                                                                  \n",
      " activation_41 (Activation)  (None, None, None, 256)      0         ['bn4e_branch2b[0][0]']       \n",
      "                                                                                                  \n",
      " res4e_branch2c (Conv2D)     (None, None, None, 1024)     263168    ['activation_41[0][0]']       \n",
      "                                                                                                  \n",
      " bn4e_branch2c (BatchNorm)   (None, None, None, 1024)     4096      ['res4e_branch2c[0][0]']      \n",
      "                                                                                                  \n",
      " add_18 (Add)                (None, None, None, 1024)     0         ['bn4e_branch2c[0][0]',       \n",
      "                                                                     'res4d_out[0][0]']           \n",
      "                                                                                                  \n",
      " res4e_out (Activation)      (None, None, None, 1024)     0         ['add_18[0][0]']              \n",
      "                                                                                                  \n",
      " res4f_branch2a (Conv2D)     (None, None, None, 256)      262400    ['res4e_out[0][0]']           \n",
      "                                                                                                  \n",
      " bn4f_branch2a (BatchNorm)   (None, None, None, 256)      1024      ['res4f_branch2a[0][0]']      \n",
      "                                                                                                  \n",
      " activation_42 (Activation)  (None, None, None, 256)      0         ['bn4f_branch2a[0][0]']       \n",
      "                                                                                                  \n",
      " res4f_branch2b (Conv2D)     (None, None, None, 256)      590080    ['activation_42[0][0]']       \n",
      "                                                                                                  \n",
      " bn4f_branch2b (BatchNorm)   (None, None, None, 256)      1024      ['res4f_branch2b[0][0]']      \n",
      "                                                                                                  \n",
      " activation_43 (Activation)  (None, None, None, 256)      0         ['bn4f_branch2b[0][0]']       \n",
      "                                                                                                  \n",
      " res4f_branch2c (Conv2D)     (None, None, None, 1024)     263168    ['activation_43[0][0]']       \n",
      "                                                                                                  \n",
      " bn4f_branch2c (BatchNorm)   (None, None, None, 1024)     4096      ['res4f_branch2c[0][0]']      \n",
      "                                                                                                  \n",
      " add_19 (Add)                (None, None, None, 1024)     0         ['bn4f_branch2c[0][0]',       \n",
      "                                                                     'res4e_out[0][0]']           \n",
      "                                                                                                  \n",
      " res4f_out (Activation)      (None, None, None, 1024)     0         ['add_19[0][0]']              \n",
      "                                                                                                  \n",
      " res4g_branch2a (Conv2D)     (None, None, None, 256)      262400    ['res4f_out[0][0]']           \n",
      "                                                                                                  \n",
      " bn4g_branch2a (BatchNorm)   (None, None, None, 256)      1024      ['res4g_branch2a[0][0]']      \n",
      "                                                                                                  \n",
      " activation_44 (Activation)  (None, None, None, 256)      0         ['bn4g_branch2a[0][0]']       \n",
      "                                                                                                  \n",
      " res4g_branch2b (Conv2D)     (None, None, None, 256)      590080    ['activation_44[0][0]']       \n",
      "                                                                                                  \n",
      " bn4g_branch2b (BatchNorm)   (None, None, None, 256)      1024      ['res4g_branch2b[0][0]']      \n",
      "                                                                                                  \n",
      " activation_45 (Activation)  (None, None, None, 256)      0         ['bn4g_branch2b[0][0]']       \n",
      "                                                                                                  \n",
      " res4g_branch2c (Conv2D)     (None, None, None, 1024)     263168    ['activation_45[0][0]']       \n",
      "                                                                                                  \n",
      " bn4g_branch2c (BatchNorm)   (None, None, None, 1024)     4096      ['res4g_branch2c[0][0]']      \n",
      "                                                                                                  \n",
      " add_20 (Add)                (None, None, None, 1024)     0         ['bn4g_branch2c[0][0]',       \n",
      "                                                                     'res4f_out[0][0]']           \n",
      "                                                                                                  \n",
      " res4g_out (Activation)      (None, None, None, 1024)     0         ['add_20[0][0]']              \n",
      "                                                                                                  \n",
      " res4h_branch2a (Conv2D)     (None, None, None, 256)      262400    ['res4g_out[0][0]']           \n",
      "                                                                                                  \n",
      " bn4h_branch2a (BatchNorm)   (None, None, None, 256)      1024      ['res4h_branch2a[0][0]']      \n",
      "                                                                                                  \n",
      " activation_46 (Activation)  (None, None, None, 256)      0         ['bn4h_branch2a[0][0]']       \n",
      "                                                                                                  \n",
      " res4h_branch2b (Conv2D)     (None, None, None, 256)      590080    ['activation_46[0][0]']       \n",
      "                                                                                                  \n",
      " bn4h_branch2b (BatchNorm)   (None, None, None, 256)      1024      ['res4h_branch2b[0][0]']      \n",
      "                                                                                                  \n",
      " activation_47 (Activation)  (None, None, None, 256)      0         ['bn4h_branch2b[0][0]']       \n",
      "                                                                                                  \n",
      " res4h_branch2c (Conv2D)     (None, None, None, 1024)     263168    ['activation_47[0][0]']       \n",
      "                                                                                                  \n",
      " bn4h_branch2c (BatchNorm)   (None, None, None, 1024)     4096      ['res4h_branch2c[0][0]']      \n",
      "                                                                                                  \n",
      " add_21 (Add)                (None, None, None, 1024)     0         ['bn4h_branch2c[0][0]',       \n",
      "                                                                     'res4g_out[0][0]']           \n",
      "                                                                                                  \n",
      " res4h_out (Activation)      (None, None, None, 1024)     0         ['add_21[0][0]']              \n",
      "                                                                                                  \n",
      " res4i_branch2a (Conv2D)     (None, None, None, 256)      262400    ['res4h_out[0][0]']           \n",
      "                                                                                                  \n",
      " bn4i_branch2a (BatchNorm)   (None, None, None, 256)      1024      ['res4i_branch2a[0][0]']      \n",
      "                                                                                                  \n",
      " activation_48 (Activation)  (None, None, None, 256)      0         ['bn4i_branch2a[0][0]']       \n",
      "                                                                                                  \n",
      " res4i_branch2b (Conv2D)     (None, None, None, 256)      590080    ['activation_48[0][0]']       \n",
      "                                                                                                  \n",
      " bn4i_branch2b (BatchNorm)   (None, None, None, 256)      1024      ['res4i_branch2b[0][0]']      \n",
      "                                                                                                  \n",
      " activation_49 (Activation)  (None, None, None, 256)      0         ['bn4i_branch2b[0][0]']       \n",
      "                                                                                                  \n",
      " res4i_branch2c (Conv2D)     (None, None, None, 1024)     263168    ['activation_49[0][0]']       \n",
      "                                                                                                  \n",
      " bn4i_branch2c (BatchNorm)   (None, None, None, 1024)     4096      ['res4i_branch2c[0][0]']      \n",
      "                                                                                                  \n",
      " add_22 (Add)                (None, None, None, 1024)     0         ['bn4i_branch2c[0][0]',       \n",
      "                                                                     'res4h_out[0][0]']           \n",
      "                                                                                                  \n",
      " res4i_out (Activation)      (None, None, None, 1024)     0         ['add_22[0][0]']              \n",
      "                                                                                                  \n",
      " res4j_branch2a (Conv2D)     (None, None, None, 256)      262400    ['res4i_out[0][0]']           \n",
      "                                                                                                  \n",
      " bn4j_branch2a (BatchNorm)   (None, None, None, 256)      1024      ['res4j_branch2a[0][0]']      \n",
      "                                                                                                  \n",
      " activation_50 (Activation)  (None, None, None, 256)      0         ['bn4j_branch2a[0][0]']       \n",
      "                                                                                                  \n",
      " res4j_branch2b (Conv2D)     (None, None, None, 256)      590080    ['activation_50[0][0]']       \n",
      "                                                                                                  \n",
      " bn4j_branch2b (BatchNorm)   (None, None, None, 256)      1024      ['res4j_branch2b[0][0]']      \n",
      "                                                                                                  \n",
      " activation_51 (Activation)  (None, None, None, 256)      0         ['bn4j_branch2b[0][0]']       \n",
      "                                                                                                  \n",
      " res4j_branch2c (Conv2D)     (None, None, None, 1024)     263168    ['activation_51[0][0]']       \n",
      "                                                                                                  \n",
      " bn4j_branch2c (BatchNorm)   (None, None, None, 1024)     4096      ['res4j_branch2c[0][0]']      \n",
      "                                                                                                  \n",
      " add_23 (Add)                (None, None, None, 1024)     0         ['bn4j_branch2c[0][0]',       \n",
      "                                                                     'res4i_out[0][0]']           \n",
      "                                                                                                  \n",
      " res4j_out (Activation)      (None, None, None, 1024)     0         ['add_23[0][0]']              \n",
      "                                                                                                  \n",
      " res4k_branch2a (Conv2D)     (None, None, None, 256)      262400    ['res4j_out[0][0]']           \n",
      "                                                                                                  \n",
      " bn4k_branch2a (BatchNorm)   (None, None, None, 256)      1024      ['res4k_branch2a[0][0]']      \n",
      "                                                                                                  \n",
      " activation_52 (Activation)  (None, None, None, 256)      0         ['bn4k_branch2a[0][0]']       \n",
      "                                                                                                  \n",
      " res4k_branch2b (Conv2D)     (None, None, None, 256)      590080    ['activation_52[0][0]']       \n",
      "                                                                                                  \n",
      " bn4k_branch2b (BatchNorm)   (None, None, None, 256)      1024      ['res4k_branch2b[0][0]']      \n",
      "                                                                                                  \n",
      " activation_53 (Activation)  (None, None, None, 256)      0         ['bn4k_branch2b[0][0]']       \n",
      "                                                                                                  \n",
      " res4k_branch2c (Conv2D)     (None, None, None, 1024)     263168    ['activation_53[0][0]']       \n",
      "                                                                                                  \n",
      " bn4k_branch2c (BatchNorm)   (None, None, None, 1024)     4096      ['res4k_branch2c[0][0]']      \n",
      "                                                                                                  \n",
      " add_24 (Add)                (None, None, None, 1024)     0         ['bn4k_branch2c[0][0]',       \n",
      "                                                                     'res4j_out[0][0]']           \n",
      "                                                                                                  \n",
      " res4k_out (Activation)      (None, None, None, 1024)     0         ['add_24[0][0]']              \n",
      "                                                                                                  \n",
      " res4l_branch2a (Conv2D)     (None, None, None, 256)      262400    ['res4k_out[0][0]']           \n",
      "                                                                                                  \n",
      " bn4l_branch2a (BatchNorm)   (None, None, None, 256)      1024      ['res4l_branch2a[0][0]']      \n",
      "                                                                                                  \n",
      " activation_54 (Activation)  (None, None, None, 256)      0         ['bn4l_branch2a[0][0]']       \n",
      "                                                                                                  \n",
      " res4l_branch2b (Conv2D)     (None, None, None, 256)      590080    ['activation_54[0][0]']       \n",
      "                                                                                                  \n",
      " bn4l_branch2b (BatchNorm)   (None, None, None, 256)      1024      ['res4l_branch2b[0][0]']      \n",
      "                                                                                                  \n",
      " activation_55 (Activation)  (None, None, None, 256)      0         ['bn4l_branch2b[0][0]']       \n",
      "                                                                                                  \n",
      " res4l_branch2c (Conv2D)     (None, None, None, 1024)     263168    ['activation_55[0][0]']       \n",
      "                                                                                                  \n",
      " bn4l_branch2c (BatchNorm)   (None, None, None, 1024)     4096      ['res4l_branch2c[0][0]']      \n",
      "                                                                                                  \n",
      " add_25 (Add)                (None, None, None, 1024)     0         ['bn4l_branch2c[0][0]',       \n",
      "                                                                     'res4k_out[0][0]']           \n",
      "                                                                                                  \n",
      " res4l_out (Activation)      (None, None, None, 1024)     0         ['add_25[0][0]']              \n",
      "                                                                                                  \n",
      " res4m_branch2a (Conv2D)     (None, None, None, 256)      262400    ['res4l_out[0][0]']           \n",
      "                                                                                                  \n",
      " bn4m_branch2a (BatchNorm)   (None, None, None, 256)      1024      ['res4m_branch2a[0][0]']      \n",
      "                                                                                                  \n",
      " activation_56 (Activation)  (None, None, None, 256)      0         ['bn4m_branch2a[0][0]']       \n",
      "                                                                                                  \n",
      " res4m_branch2b (Conv2D)     (None, None, None, 256)      590080    ['activation_56[0][0]']       \n",
      "                                                                                                  \n",
      " bn4m_branch2b (BatchNorm)   (None, None, None, 256)      1024      ['res4m_branch2b[0][0]']      \n",
      "                                                                                                  \n",
      " activation_57 (Activation)  (None, None, None, 256)      0         ['bn4m_branch2b[0][0]']       \n",
      "                                                                                                  \n",
      " res4m_branch2c (Conv2D)     (None, None, None, 1024)     263168    ['activation_57[0][0]']       \n",
      "                                                                                                  \n",
      " bn4m_branch2c (BatchNorm)   (None, None, None, 1024)     4096      ['res4m_branch2c[0][0]']      \n",
      "                                                                                                  \n",
      " add_26 (Add)                (None, None, None, 1024)     0         ['bn4m_branch2c[0][0]',       \n",
      "                                                                     'res4l_out[0][0]']           \n",
      "                                                                                                  \n",
      " res4m_out (Activation)      (None, None, None, 1024)     0         ['add_26[0][0]']              \n",
      "                                                                                                  \n",
      " res4n_branch2a (Conv2D)     (None, None, None, 256)      262400    ['res4m_out[0][0]']           \n",
      "                                                                                                  \n",
      " bn4n_branch2a (BatchNorm)   (None, None, None, 256)      1024      ['res4n_branch2a[0][0]']      \n",
      "                                                                                                  \n",
      " activation_58 (Activation)  (None, None, None, 256)      0         ['bn4n_branch2a[0][0]']       \n",
      "                                                                                                  \n",
      " res4n_branch2b (Conv2D)     (None, None, None, 256)      590080    ['activation_58[0][0]']       \n",
      "                                                                                                  \n",
      " bn4n_branch2b (BatchNorm)   (None, None, None, 256)      1024      ['res4n_branch2b[0][0]']      \n",
      "                                                                                                  \n",
      " activation_59 (Activation)  (None, None, None, 256)      0         ['bn4n_branch2b[0][0]']       \n",
      "                                                                                                  \n",
      " res4n_branch2c (Conv2D)     (None, None, None, 1024)     263168    ['activation_59[0][0]']       \n",
      "                                                                                                  \n",
      " bn4n_branch2c (BatchNorm)   (None, None, None, 1024)     4096      ['res4n_branch2c[0][0]']      \n",
      "                                                                                                  \n",
      " add_27 (Add)                (None, None, None, 1024)     0         ['bn4n_branch2c[0][0]',       \n",
      "                                                                     'res4m_out[0][0]']           \n",
      "                                                                                                  \n",
      " res4n_out (Activation)      (None, None, None, 1024)     0         ['add_27[0][0]']              \n",
      "                                                                                                  \n",
      " res4o_branch2a (Conv2D)     (None, None, None, 256)      262400    ['res4n_out[0][0]']           \n",
      "                                                                                                  \n",
      " bn4o_branch2a (BatchNorm)   (None, None, None, 256)      1024      ['res4o_branch2a[0][0]']      \n",
      "                                                                                                  \n",
      " activation_60 (Activation)  (None, None, None, 256)      0         ['bn4o_branch2a[0][0]']       \n",
      "                                                                                                  \n",
      " res4o_branch2b (Conv2D)     (None, None, None, 256)      590080    ['activation_60[0][0]']       \n",
      "                                                                                                  \n",
      " bn4o_branch2b (BatchNorm)   (None, None, None, 256)      1024      ['res4o_branch2b[0][0]']      \n",
      "                                                                                                  \n",
      " activation_61 (Activation)  (None, None, None, 256)      0         ['bn4o_branch2b[0][0]']       \n",
      "                                                                                                  \n",
      " res4o_branch2c (Conv2D)     (None, None, None, 1024)     263168    ['activation_61[0][0]']       \n",
      "                                                                                                  \n",
      " bn4o_branch2c (BatchNorm)   (None, None, None, 1024)     4096      ['res4o_branch2c[0][0]']      \n",
      "                                                                                                  \n",
      " add_28 (Add)                (None, None, None, 1024)     0         ['bn4o_branch2c[0][0]',       \n",
      "                                                                     'res4n_out[0][0]']           \n",
      "                                                                                                  \n",
      " res4o_out (Activation)      (None, None, None, 1024)     0         ['add_28[0][0]']              \n",
      "                                                                                                  \n",
      " res4p_branch2a (Conv2D)     (None, None, None, 256)      262400    ['res4o_out[0][0]']           \n",
      "                                                                                                  \n",
      " bn4p_branch2a (BatchNorm)   (None, None, None, 256)      1024      ['res4p_branch2a[0][0]']      \n",
      "                                                                                                  \n",
      " activation_62 (Activation)  (None, None, None, 256)      0         ['bn4p_branch2a[0][0]']       \n",
      "                                                                                                  \n",
      " res4p_branch2b (Conv2D)     (None, None, None, 256)      590080    ['activation_62[0][0]']       \n",
      "                                                                                                  \n",
      " bn4p_branch2b (BatchNorm)   (None, None, None, 256)      1024      ['res4p_branch2b[0][0]']      \n",
      "                                                                                                  \n",
      " activation_63 (Activation)  (None, None, None, 256)      0         ['bn4p_branch2b[0][0]']       \n",
      "                                                                                                  \n",
      " res4p_branch2c (Conv2D)     (None, None, None, 1024)     263168    ['activation_63[0][0]']       \n",
      "                                                                                                  \n",
      " bn4p_branch2c (BatchNorm)   (None, None, None, 1024)     4096      ['res4p_branch2c[0][0]']      \n",
      "                                                                                                  \n",
      " add_29 (Add)                (None, None, None, 1024)     0         ['bn4p_branch2c[0][0]',       \n",
      "                                                                     'res4o_out[0][0]']           \n",
      "                                                                                                  \n",
      " res4p_out (Activation)      (None, None, None, 1024)     0         ['add_29[0][0]']              \n",
      "                                                                                                  \n",
      " res4q_branch2a (Conv2D)     (None, None, None, 256)      262400    ['res4p_out[0][0]']           \n",
      "                                                                                                  \n",
      " bn4q_branch2a (BatchNorm)   (None, None, None, 256)      1024      ['res4q_branch2a[0][0]']      \n",
      "                                                                                                  \n",
      " activation_64 (Activation)  (None, None, None, 256)      0         ['bn4q_branch2a[0][0]']       \n",
      "                                                                                                  \n",
      " res4q_branch2b (Conv2D)     (None, None, None, 256)      590080    ['activation_64[0][0]']       \n",
      "                                                                                                  \n",
      " bn4q_branch2b (BatchNorm)   (None, None, None, 256)      1024      ['res4q_branch2b[0][0]']      \n",
      "                                                                                                  \n",
      " activation_65 (Activation)  (None, None, None, 256)      0         ['bn4q_branch2b[0][0]']       \n",
      "                                                                                                  \n",
      " res4q_branch2c (Conv2D)     (None, None, None, 1024)     263168    ['activation_65[0][0]']       \n",
      "                                                                                                  \n",
      " bn4q_branch2c (BatchNorm)   (None, None, None, 1024)     4096      ['res4q_branch2c[0][0]']      \n",
      "                                                                                                  \n",
      " add_30 (Add)                (None, None, None, 1024)     0         ['bn4q_branch2c[0][0]',       \n",
      "                                                                     'res4p_out[0][0]']           \n",
      "                                                                                                  \n",
      " res4q_out (Activation)      (None, None, None, 1024)     0         ['add_30[0][0]']              \n",
      "                                                                                                  \n",
      " res4r_branch2a (Conv2D)     (None, None, None, 256)      262400    ['res4q_out[0][0]']           \n",
      "                                                                                                  \n",
      " bn4r_branch2a (BatchNorm)   (None, None, None, 256)      1024      ['res4r_branch2a[0][0]']      \n",
      "                                                                                                  \n",
      " activation_66 (Activation)  (None, None, None, 256)      0         ['bn4r_branch2a[0][0]']       \n",
      "                                                                                                  \n",
      " res4r_branch2b (Conv2D)     (None, None, None, 256)      590080    ['activation_66[0][0]']       \n",
      "                                                                                                  \n",
      " bn4r_branch2b (BatchNorm)   (None, None, None, 256)      1024      ['res4r_branch2b[0][0]']      \n",
      "                                                                                                  \n",
      " activation_67 (Activation)  (None, None, None, 256)      0         ['bn4r_branch2b[0][0]']       \n",
      "                                                                                                  \n",
      " res4r_branch2c (Conv2D)     (None, None, None, 1024)     263168    ['activation_67[0][0]']       \n",
      "                                                                                                  \n",
      " bn4r_branch2c (BatchNorm)   (None, None, None, 1024)     4096      ['res4r_branch2c[0][0]']      \n",
      "                                                                                                  \n",
      " add_31 (Add)                (None, None, None, 1024)     0         ['bn4r_branch2c[0][0]',       \n",
      "                                                                     'res4q_out[0][0]']           \n",
      "                                                                                                  \n",
      " res4r_out (Activation)      (None, None, None, 1024)     0         ['add_31[0][0]']              \n",
      "                                                                                                  \n",
      " res4s_branch2a (Conv2D)     (None, None, None, 256)      262400    ['res4r_out[0][0]']           \n",
      "                                                                                                  \n",
      " bn4s_branch2a (BatchNorm)   (None, None, None, 256)      1024      ['res4s_branch2a[0][0]']      \n",
      "                                                                                                  \n",
      " activation_68 (Activation)  (None, None, None, 256)      0         ['bn4s_branch2a[0][0]']       \n",
      "                                                                                                  \n",
      " res4s_branch2b (Conv2D)     (None, None, None, 256)      590080    ['activation_68[0][0]']       \n",
      "                                                                                                  \n",
      " bn4s_branch2b (BatchNorm)   (None, None, None, 256)      1024      ['res4s_branch2b[0][0]']      \n",
      "                                                                                                  \n",
      " activation_69 (Activation)  (None, None, None, 256)      0         ['bn4s_branch2b[0][0]']       \n",
      "                                                                                                  \n",
      " res4s_branch2c (Conv2D)     (None, None, None, 1024)     263168    ['activation_69[0][0]']       \n",
      "                                                                                                  \n",
      " bn4s_branch2c (BatchNorm)   (None, None, None, 1024)     4096      ['res4s_branch2c[0][0]']      \n",
      "                                                                                                  \n",
      " add_32 (Add)                (None, None, None, 1024)     0         ['bn4s_branch2c[0][0]',       \n",
      "                                                                     'res4r_out[0][0]']           \n",
      "                                                                                                  \n",
      " res4s_out (Activation)      (None, None, None, 1024)     0         ['add_32[0][0]']              \n",
      "                                                                                                  \n",
      " res4t_branch2a (Conv2D)     (None, None, None, 256)      262400    ['res4s_out[0][0]']           \n",
      "                                                                                                  \n",
      " bn4t_branch2a (BatchNorm)   (None, None, None, 256)      1024      ['res4t_branch2a[0][0]']      \n",
      "                                                                                                  \n",
      " activation_70 (Activation)  (None, None, None, 256)      0         ['bn4t_branch2a[0][0]']       \n",
      "                                                                                                  \n",
      " res4t_branch2b (Conv2D)     (None, None, None, 256)      590080    ['activation_70[0][0]']       \n",
      "                                                                                                  \n",
      " bn4t_branch2b (BatchNorm)   (None, None, None, 256)      1024      ['res4t_branch2b[0][0]']      \n",
      "                                                                                                  \n",
      " activation_71 (Activation)  (None, None, None, 256)      0         ['bn4t_branch2b[0][0]']       \n",
      "                                                                                                  \n",
      " res4t_branch2c (Conv2D)     (None, None, None, 1024)     263168    ['activation_71[0][0]']       \n",
      "                                                                                                  \n",
      " bn4t_branch2c (BatchNorm)   (None, None, None, 1024)     4096      ['res4t_branch2c[0][0]']      \n",
      "                                                                                                  \n",
      " add_33 (Add)                (None, None, None, 1024)     0         ['bn4t_branch2c[0][0]',       \n",
      "                                                                     'res4s_out[0][0]']           \n",
      "                                                                                                  \n",
      " res4t_out (Activation)      (None, None, None, 1024)     0         ['add_33[0][0]']              \n",
      "                                                                                                  \n",
      " res4u_branch2a (Conv2D)     (None, None, None, 256)      262400    ['res4t_out[0][0]']           \n",
      "                                                                                                  \n",
      " bn4u_branch2a (BatchNorm)   (None, None, None, 256)      1024      ['res4u_branch2a[0][0]']      \n",
      "                                                                                                  \n",
      " activation_72 (Activation)  (None, None, None, 256)      0         ['bn4u_branch2a[0][0]']       \n",
      "                                                                                                  \n",
      " res4u_branch2b (Conv2D)     (None, None, None, 256)      590080    ['activation_72[0][0]']       \n",
      "                                                                                                  \n",
      " bn4u_branch2b (BatchNorm)   (None, None, None, 256)      1024      ['res4u_branch2b[0][0]']      \n",
      "                                                                                                  \n",
      " activation_73 (Activation)  (None, None, None, 256)      0         ['bn4u_branch2b[0][0]']       \n",
      "                                                                                                  \n",
      " res4u_branch2c (Conv2D)     (None, None, None, 1024)     263168    ['activation_73[0][0]']       \n",
      "                                                                                                  \n",
      " bn4u_branch2c (BatchNorm)   (None, None, None, 1024)     4096      ['res4u_branch2c[0][0]']      \n",
      "                                                                                                  \n",
      " add_34 (Add)                (None, None, None, 1024)     0         ['bn4u_branch2c[0][0]',       \n",
      "                                                                     'res4t_out[0][0]']           \n",
      "                                                                                                  \n",
      " res4u_out (Activation)      (None, None, None, 1024)     0         ['add_34[0][0]']              \n",
      "                                                                                                  \n",
      " res4v_branch2a (Conv2D)     (None, None, None, 256)      262400    ['res4u_out[0][0]']           \n",
      "                                                                                                  \n",
      " bn4v_branch2a (BatchNorm)   (None, None, None, 256)      1024      ['res4v_branch2a[0][0]']      \n",
      "                                                                                                  \n",
      " activation_74 (Activation)  (None, None, None, 256)      0         ['bn4v_branch2a[0][0]']       \n",
      "                                                                                                  \n",
      " res4v_branch2b (Conv2D)     (None, None, None, 256)      590080    ['activation_74[0][0]']       \n",
      "                                                                                                  \n",
      " bn4v_branch2b (BatchNorm)   (None, None, None, 256)      1024      ['res4v_branch2b[0][0]']      \n",
      "                                                                                                  \n",
      " activation_75 (Activation)  (None, None, None, 256)      0         ['bn4v_branch2b[0][0]']       \n",
      "                                                                                                  \n",
      " res4v_branch2c (Conv2D)     (None, None, None, 1024)     263168    ['activation_75[0][0]']       \n",
      "                                                                                                  \n",
      " bn4v_branch2c (BatchNorm)   (None, None, None, 1024)     4096      ['res4v_branch2c[0][0]']      \n",
      "                                                                                                  \n",
      " add_35 (Add)                (None, None, None, 1024)     0         ['bn4v_branch2c[0][0]',       \n",
      "                                                                     'res4u_out[0][0]']           \n",
      "                                                                                                  \n",
      " res4v_out (Activation)      (None, None, None, 1024)     0         ['add_35[0][0]']              \n",
      "                                                                                                  \n",
      " res4w_branch2a (Conv2D)     (None, None, None, 256)      262400    ['res4v_out[0][0]']           \n",
      "                                                                                                  \n",
      " bn4w_branch2a (BatchNorm)   (None, None, None, 256)      1024      ['res4w_branch2a[0][0]']      \n",
      "                                                                                                  \n",
      " activation_76 (Activation)  (None, None, None, 256)      0         ['bn4w_branch2a[0][0]']       \n",
      "                                                                                                  \n",
      " res4w_branch2b (Conv2D)     (None, None, None, 256)      590080    ['activation_76[0][0]']       \n",
      "                                                                                                  \n",
      " bn4w_branch2b (BatchNorm)   (None, None, None, 256)      1024      ['res4w_branch2b[0][0]']      \n",
      "                                                                                                  \n",
      " activation_77 (Activation)  (None, None, None, 256)      0         ['bn4w_branch2b[0][0]']       \n",
      "                                                                                                  \n",
      " res4w_branch2c (Conv2D)     (None, None, None, 1024)     263168    ['activation_77[0][0]']       \n",
      "                                                                                                  \n",
      " bn4w_branch2c (BatchNorm)   (None, None, None, 1024)     4096      ['res4w_branch2c[0][0]']      \n",
      "                                                                                                  \n",
      " add_36 (Add)                (None, None, None, 1024)     0         ['bn4w_branch2c[0][0]',       \n",
      "                                                                     'res4v_out[0][0]']           \n",
      "                                                                                                  \n",
      " res4w_out (Activation)      (None, None, None, 1024)     0         ['add_36[0][0]']              \n",
      "                                                                                                  \n",
      " res5a_branch2a (Conv2D)     (None, None, None, 512)      524800    ['res4w_out[0][0]']           \n",
      "                                                                                                  \n",
      " bn5a_branch2a (BatchNorm)   (None, None, None, 512)      2048      ['res5a_branch2a[0][0]']      \n",
      "                                                                                                  \n",
      " activation_78 (Activation)  (None, None, None, 512)      0         ['bn5a_branch2a[0][0]']       \n",
      "                                                                                                  \n",
      " res5a_branch2b (Conv2D)     (None, None, None, 512)      2359808   ['activation_78[0][0]']       \n",
      "                                                                                                  \n",
      " bn5a_branch2b (BatchNorm)   (None, None, None, 512)      2048      ['res5a_branch2b[0][0]']      \n",
      "                                                                                                  \n",
      " activation_79 (Activation)  (None, None, None, 512)      0         ['bn5a_branch2b[0][0]']       \n",
      "                                                                                                  \n",
      " res5a_branch2c (Conv2D)     (None, None, None, 2048)     1050624   ['activation_79[0][0]']       \n",
      "                                                                                                  \n",
      " res5a_branch1 (Conv2D)      (None, None, None, 2048)     2099200   ['res4w_out[0][0]']           \n",
      "                                                                                                  \n",
      " bn5a_branch2c (BatchNorm)   (None, None, None, 2048)     8192      ['res5a_branch2c[0][0]']      \n",
      "                                                                                                  \n",
      " bn5a_branch1 (BatchNorm)    (None, None, None, 2048)     8192      ['res5a_branch1[0][0]']       \n",
      "                                                                                                  \n",
      " add_37 (Add)                (None, None, None, 2048)     0         ['bn5a_branch2c[0][0]',       \n",
      "                                                                     'bn5a_branch1[0][0]']        \n",
      "                                                                                                  \n",
      " res5a_out (Activation)      (None, None, None, 2048)     0         ['add_37[0][0]']              \n",
      "                                                                                                  \n",
      " res5b_branch2a (Conv2D)     (None, None, None, 512)      1049088   ['res5a_out[0][0]']           \n",
      "                                                                                                  \n",
      " bn5b_branch2a (BatchNorm)   (None, None, None, 512)      2048      ['res5b_branch2a[0][0]']      \n",
      "                                                                                                  \n",
      " activation_80 (Activation)  (None, None, None, 512)      0         ['bn5b_branch2a[0][0]']       \n",
      "                                                                                                  \n",
      " res5b_branch2b (Conv2D)     (None, None, None, 512)      2359808   ['activation_80[0][0]']       \n",
      "                                                                                                  \n",
      " bn5b_branch2b (BatchNorm)   (None, None, None, 512)      2048      ['res5b_branch2b[0][0]']      \n",
      "                                                                                                  \n",
      " activation_81 (Activation)  (None, None, None, 512)      0         ['bn5b_branch2b[0][0]']       \n",
      "                                                                                                  \n",
      " res5b_branch2c (Conv2D)     (None, None, None, 2048)     1050624   ['activation_81[0][0]']       \n",
      "                                                                                                  \n",
      " bn5b_branch2c (BatchNorm)   (None, None, None, 2048)     8192      ['res5b_branch2c[0][0]']      \n",
      "                                                                                                  \n",
      " add_38 (Add)                (None, None, None, 2048)     0         ['bn5b_branch2c[0][0]',       \n",
      "                                                                     'res5a_out[0][0]']           \n",
      "                                                                                                  \n",
      " res5b_out (Activation)      (None, None, None, 2048)     0         ['add_38[0][0]']              \n",
      "                                                                                                  \n",
      " res5c_branch2a (Conv2D)     (None, None, None, 512)      1049088   ['res5b_out[0][0]']           \n",
      "                                                                                                  \n",
      " bn5c_branch2a (BatchNorm)   (None, None, None, 512)      2048      ['res5c_branch2a[0][0]']      \n",
      "                                                                                                  \n",
      " activation_82 (Activation)  (None, None, None, 512)      0         ['bn5c_branch2a[0][0]']       \n",
      "                                                                                                  \n",
      " res5c_branch2b (Conv2D)     (None, None, None, 512)      2359808   ['activation_82[0][0]']       \n",
      "                                                                                                  \n",
      " bn5c_branch2b (BatchNorm)   (None, None, None, 512)      2048      ['res5c_branch2b[0][0]']      \n",
      "                                                                                                  \n",
      " activation_83 (Activation)  (None, None, None, 512)      0         ['bn5c_branch2b[0][0]']       \n",
      "                                                                                                  \n",
      " res5c_branch2c (Conv2D)     (None, None, None, 2048)     1050624   ['activation_83[0][0]']       \n",
      "                                                                                                  \n",
      " bn5c_branch2c (BatchNorm)   (None, None, None, 2048)     8192      ['res5c_branch2c[0][0]']      \n",
      "                                                                                                  \n",
      " add_39 (Add)                (None, None, None, 2048)     0         ['bn5c_branch2c[0][0]',       \n",
      "                                                                     'res5b_out[0][0]']           \n",
      "                                                                                                  \n",
      " res5c_out (Activation)      (None, None, None, 2048)     0         ['add_39[0][0]']              \n",
      "                                                                                                  \n",
      " fpn_c5p5 (Conv2D)           (None, None, None, 256)      524544    ['res5c_out[0][0]']           \n",
      "                                                                                                  \n",
      " fpn_p5upsampled (UpSamplin  (None, None, None, 256)      0         ['fpn_c5p5[0][0]']            \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " fpn_c4p4 (Conv2D)           (None, None, None, 256)      262400    ['res4w_out[0][0]']           \n",
      "                                                                                                  \n",
      " fpn_p4add (Add)             (None, None, None, 256)      0         ['fpn_p5upsampled[0][0]',     \n",
      "                                                                     'fpn_c4p4[0][0]']            \n",
      "                                                                                                  \n",
      " fpn_p4upsampled (UpSamplin  (None, None, None, 256)      0         ['fpn_p4add[0][0]']           \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " fpn_c3p3 (Conv2D)           (None, None, None, 256)      131328    ['res3d_out[0][0]']           \n",
      "                                                                                                  \n",
      " fpn_p3add (Add)             (None, None, None, 256)      0         ['fpn_p4upsampled[0][0]',     \n",
      "                                                                     'fpn_c3p3[0][0]']            \n",
      "                                                                                                  \n",
      " fpn_p3upsampled (UpSamplin  (None, None, None, 256)      0         ['fpn_p3add[0][0]']           \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " fpn_c2p2 (Conv2D)           (None, None, None, 256)      65792     ['res2c_out[0][0]']           \n",
      "                                                                                                  \n",
      " fpn_p2add (Add)             (None, None, None, 256)      0         ['fpn_p3upsampled[0][0]',     \n",
      "                                                                     'fpn_c2p2[0][0]']            \n",
      "                                                                                                  \n",
      " fpn_p5 (Conv2D)             (None, None, None, 256)      590080    ['fpn_c5p5[0][0]']            \n",
      "                                                                                                  \n",
      " fpn_p2 (Conv2D)             (None, None, None, 256)      590080    ['fpn_p2add[0][0]']           \n",
      "                                                                                                  \n",
      " fpn_p3 (Conv2D)             (None, None, None, 256)      590080    ['fpn_p3add[0][0]']           \n",
      "                                                                                                  \n",
      " fpn_p4 (Conv2D)             (None, None, None, 256)      590080    ['fpn_p4add[0][0]']           \n",
      "                                                                                                  \n",
      " fpn_p6 (MaxPooling2D)       (None, None, None, 256)      0         ['fpn_p5[0][0]']              \n",
      "                                                                                                  \n",
      " rpn_model (Functional)      [(None, None, 2),            1189394   ['fpn_p2[0][0]',              \n",
      "                              (None, None, 2),                       'fpn_p3[0][0]',              \n",
      "                              (None, None, 4)]                       'fpn_p4[0][0]',              \n",
      "                                                                     'fpn_p5[0][0]',              \n",
      "                                                                     'fpn_p6[0][0]']              \n",
      "                                                                                                  \n",
      " rpn_bbox (Concatenate)      (None, None, 4)              0         ['rpn_model[0][2]',           \n",
      "                                                                     'rpn_model[1][2]',           \n",
      "                                                                     'rpn_model[2][2]',           \n",
      "                                                                     'rpn_model[3][2]',           \n",
      "                                                                     'rpn_model[4][2]']           \n",
      "                                                                                                  \n",
      " rpn_class (Concatenate)     (None, None, 2)              0         ['rpn_model[0][1]',           \n",
      "                                                                     'rpn_model[1][1]',           \n",
      "                                                                     'rpn_model[2][1]',           \n",
      "                                                                     'rpn_model[3][1]',           \n",
      "                                                                     'rpn_model[4][1]']           \n",
      "                                                                                                  \n",
      " anchors (ConstLayer)        (4, 65472, 4)                1047552   ['input_image[0][0]']         \n",
      "                                                                                                  \n",
      " input_gt_boxes (InputLayer  [(None, None, 4)]            0         []                            \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " ROI (ProposalLayer)         (4, 2000, 4)                 0         ['rpn_class[0][0]',           \n",
      "                                                                     'rpn_bbox[0][0]',            \n",
      "                                                                     'anchors[0][0]']             \n",
      "                                                                                                  \n",
      " input_gt_class_ids (InputL  [(None, None)]               0         []                            \n",
      " ayer)                                                                                            \n",
      "                                                                                                  \n",
      " lambda_1 (Lambda)           (None, None, 4)              0         ['input_gt_boxes[0][0]',      \n",
      "                                                                     'input_image[0][0]']         \n",
      "                                                                                                  \n",
      " input_gt_masks (InputLayer  [(None, 512, 512, None)]     0         []                            \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " proposal_targets (Detectio  [(4, None, 4),               0         ['ROI[0][0]',                 \n",
      " nTargetLayer)                (4, None),                             'input_gt_class_ids[0][0]',  \n",
      "                              (4, None, 4),                          'lambda_1[0][0]',            \n",
      "                              (4, None, 28, 28)]                     'input_gt_masks[0][0]']      \n",
      "                                                                                                  \n",
      " input_image_meta (InputLay  [(None, 16)]                 0         []                            \n",
      " er)                                                                                              \n",
      "                                                                                                  \n",
      " roi_align_mask (PyramidROI  (4, None, 14, 14, 256)       0         ['proposal_targets[0][0]',    \n",
      " Align)                                                              'input_image_meta[0][0]',    \n",
      "                                                                     'fpn_p2[0][0]',              \n",
      "                                                                     'fpn_p3[0][0]',              \n",
      "                                                                     'fpn_p4[0][0]',              \n",
      "                                                                     'fpn_p5[0][0]']              \n",
      "                                                                                                  \n",
      " mrcnn_mask_conv1 (TimeDist  (4, None, 14, 14, 256)       590080    ['roi_align_mask[0][0]']      \n",
      " ributed)                                                                                         \n",
      "                                                                                                  \n",
      " mrcnn_mask_bn1 (TimeDistri  (4, None, 14, 14, 256)       1024      ['mrcnn_mask_conv1[0][0]']    \n",
      " buted)                                                                                           \n",
      "                                                                                                  \n",
      " activation_87 (Activation)  (4, None, 14, 14, 256)       0         ['mrcnn_mask_bn1[0][0]']      \n",
      "                                                                                                  \n",
      " mrcnn_mask_conv2 (TimeDist  (4, None, 14, 14, 256)       590080    ['activation_87[0][0]']       \n",
      " ributed)                                                                                         \n",
      "                                                                                                  \n",
      " roi_align_classifier (Pyra  (4, None, 7, 7, 256)         0         ['proposal_targets[0][0]',    \n",
      " midROIAlign)                                                        'input_image_meta[0][0]',    \n",
      "                                                                     'fpn_p2[0][0]',              \n",
      "                                                                     'fpn_p3[0][0]',              \n",
      "                                                                     'fpn_p4[0][0]',              \n",
      "                                                                     'fpn_p5[0][0]']              \n",
      "                                                                                                  \n",
      " mrcnn_mask_bn2 (TimeDistri  (4, None, 14, 14, 256)       1024      ['mrcnn_mask_conv2[0][0]']    \n",
      " buted)                                                                                           \n",
      "                                                                                                  \n",
      " mrcnn_class_conv1 (TimeDis  (4, None, 1, 1, 1024)        1284608   ['roi_align_classifier[0][0]']\n",
      " tributed)                                                0                                       \n",
      "                                                                                                  \n",
      " activation_88 (Activation)  (4, None, 14, 14, 256)       0         ['mrcnn_mask_bn2[0][0]']      \n",
      "                                                                                                  \n",
      " mrcnn_class_bn1 (TimeDistr  (4, None, 1, 1, 1024)        4096      ['mrcnn_class_conv1[0][0]']   \n",
      " ibuted)                                                                                          \n",
      "                                                                                                  \n",
      " mrcnn_mask_conv3 (TimeDist  (4, None, 14, 14, 256)       590080    ['activation_88[0][0]']       \n",
      " ributed)                                                                                         \n",
      "                                                                                                  \n",
      " activation_84 (Activation)  (4, None, 1, 1, 1024)        0         ['mrcnn_class_bn1[0][0]']     \n",
      "                                                                                                  \n",
      " mrcnn_mask_bn3 (TimeDistri  (4, None, 14, 14, 256)       1024      ['mrcnn_mask_conv3[0][0]']    \n",
      " buted)                                                                                           \n",
      "                                                                                                  \n",
      " mrcnn_class_conv2 (TimeDis  (4, None, 1, 1, 1024)        1049600   ['activation_84[0][0]']       \n",
      " tributed)                                                                                        \n",
      "                                                                                                  \n",
      " activation_89 (Activation)  (4, None, 14, 14, 256)       0         ['mrcnn_mask_bn3[0][0]']      \n",
      "                                                                                                  \n",
      " mrcnn_class_bn2 (TimeDistr  (4, None, 1, 1, 1024)        4096      ['mrcnn_class_conv2[0][0]']   \n",
      " ibuted)                                                                                          \n",
      "                                                                                                  \n",
      " mrcnn_mask_conv4 (TimeDist  (4, None, 14, 14, 256)       590080    ['activation_89[0][0]']       \n",
      " ributed)                                                                                         \n",
      "                                                                                                  \n",
      " activation_85 (Activation)  (4, None, 1, 1, 1024)        0         ['mrcnn_class_bn2[0][0]']     \n",
      "                                                                                                  \n",
      " mrcnn_mask_bn4 (TimeDistri  (4, None, 14, 14, 256)       1024      ['mrcnn_mask_conv4[0][0]']    \n",
      " buted)                                                                                           \n",
      "                                                                                                  \n",
      " pool_squeeze (Lambda)       (4, None, 1024)              0         ['activation_85[0][0]']       \n",
      "                                                                                                  \n",
      " activation_90 (Activation)  (4, None, 14, 14, 256)       0         ['mrcnn_mask_bn4[0][0]']      \n",
      "                                                                                                  \n",
      " mrcnn_bbox_fc (TimeDistrib  (4, None, 16)                16400     ['pool_squeeze[0][0]']        \n",
      " uted)                                                                                            \n",
      "                                                                                                  \n",
      " mrcnn_mask_deconv (TimeDis  (4, None, 28, 28, 256)       262400    ['activation_90[0][0]']       \n",
      " tributed)                                                                                        \n",
      "                                                                                                  \n",
      " input_rpn_match (InputLaye  [(None, None, 1)]            0         []                            \n",
      " r)                                                                                               \n",
      "                                                                                                  \n",
      " input_rpn_bbox (InputLayer  [(None, None, 4)]            0         []                            \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " rpn_class_logits (Concaten  (None, None, 2)              0         ['rpn_model[0][0]',           \n",
      " ate)                                                                'rpn_model[1][0]',           \n",
      "                                                                     'rpn_model[2][0]',           \n",
      "                                                                     'rpn_model[3][0]',           \n",
      "                                                                     'rpn_model[4][0]']           \n",
      "                                                                                                  \n",
      " mrcnn_class_logits (TimeDi  (4, None, 4)                 4100      ['pool_squeeze[0][0]']        \n",
      " stributed)                                                                                       \n",
      "                                                                                                  \n",
      " mrcnn_bbox (Reshape)        (4, None, 4, 4)              0         ['mrcnn_bbox_fc[0][0]']       \n",
      "                                                                                                  \n",
      " mrcnn_mask (TimeDistribute  (4, None, 28, 28, 4)         1028      ['mrcnn_mask_deconv[0][0]']   \n",
      " d)                                                                                               \n",
      "                                                                                                  \n",
      " lambda_4 (Lambda)           (None, 4)                    0         ['input_image_meta[0][0]']    \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 64791722 (247.16 MB)\n",
      "Trainable params: 63632682 (242.74 MB)\n",
      "Non-trainable params: 1159040 (4.42 MB)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.compile(layers=\"all\")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting at epoch 1.\n",
      "\n",
      "Checkpoint Path: /mnt/c/Users/ChangGeng/Desktop/FAU/Semester 07/Bachelorarbeit/02_Vision_Transformers/logs/60_shapes_resnet20241210T2123/mask_rcnn_60_shapes_resnet_{epoch:04d}.h5\n",
      "n workers used: 32\n",
      "Epoch 2: Learning rate is 0.000200 (warmup phase).\n",
      "Epoch 2/500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1733862246.839124     953 op_level_cost_estimator.cc:699] Error in PredictCost() for the op: op: \"CropAndResize\" attr { key: \"T\" value { type: DT_FLOAT } } attr { key: \"extrapolation_value\" value { f: 0 } } attr { key: \"method\" value { s: \"bilinear\" } } inputs { dtype: DT_FLOAT shape { dim { size: -1086 } dim { size: -613 } dim { size: -614 } dim { size: 1 } } } inputs { dtype: DT_FLOAT shape { dim { size: -38 } dim { size: 4 } } } inputs { dtype: DT_INT32 shape { dim { size: -38 } } } inputs { dtype: DT_INT32 shape { dim { size: 2 } } value { dtype: DT_INT32 tensor_shape { dim { size: 2 } } int_val: 28 } } device { type: \"GPU\" vendor: \"NVIDIA\" model: \"NVIDIA GeForce RTX 4090\" frequency: 2520 num_cores: 128 environment { key: \"architecture\" value: \"8.9\" } environment { key: \"cuda\" value: \"12000\" } environment { key: \"cudnn\" value: \"8800\" } num_registers: 65536 l1_cache_size: 24576 l2_cache_size: 75497472 shared_memory_size_per_multiprocessor: 102400 memory_size: 22500343808 bandwidth: 1008096000 } outputs { dtype: DT_FLOAT shape { dim { size: -38 } dim { size: 28 } dim { size: 28 } dim { size: 1 } } }\n",
      "W0000 00:00:1733862246.839319     953 op_level_cost_estimator.cc:699] Error in PredictCost() for the op: op: \"CropAndResize\" attr { key: \"T\" value { type: DT_FLOAT } } attr { key: \"extrapolation_value\" value { f: 0 } } attr { key: \"method\" value { s: \"bilinear\" } } inputs { dtype: DT_FLOAT shape { dim { size: -1202 } dim { size: -622 } dim { size: -623 } dim { size: 1 } } } inputs { dtype: DT_FLOAT shape { dim { size: -56 } dim { size: 4 } } } inputs { dtype: DT_INT32 shape { dim { size: -56 } } } inputs { dtype: DT_INT32 shape { dim { size: 2 } } value { dtype: DT_INT32 tensor_shape { dim { size: 2 } } int_val: 28 } } device { type: \"GPU\" vendor: \"NVIDIA\" model: \"NVIDIA GeForce RTX 4090\" frequency: 2520 num_cores: 128 environment { key: \"architecture\" value: \"8.9\" } environment { key: \"cuda\" value: \"12000\" } environment { key: \"cudnn\" value: \"8800\" } num_registers: 65536 l1_cache_size: 24576 l2_cache_size: 75497472 shared_memory_size_per_multiprocessor: 102400 memory_size: 22500343808 bandwidth: 1008096000 } outputs { dtype: DT_FLOAT shape { dim { size: -56 } dim { size: 28 } dim { size: 28 } dim { size: 1 } } }\n",
      "W0000 00:00:1733862246.839405     953 op_level_cost_estimator.cc:699] Error in PredictCost() for the op: op: \"CropAndResize\" attr { key: \"T\" value { type: DT_FLOAT } } attr { key: \"extrapolation_value\" value { f: 0 } } attr { key: \"method\" value { s: \"bilinear\" } } inputs { dtype: DT_FLOAT shape { dim { size: -1116 } dim { size: -616 } dim { size: -617 } dim { size: 1 } } } inputs { dtype: DT_FLOAT shape { dim { size: -44 } dim { size: 4 } } } inputs { dtype: DT_INT32 shape { dim { size: -44 } } } inputs { dtype: DT_INT32 shape { dim { size: 2 } } value { dtype: DT_INT32 tensor_shape { dim { size: 2 } } int_val: 28 } } device { type: \"GPU\" vendor: \"NVIDIA\" model: \"NVIDIA GeForce RTX 4090\" frequency: 2520 num_cores: 128 environment { key: \"architecture\" value: \"8.9\" } environment { key: \"cuda\" value: \"12000\" } environment { key: \"cudnn\" value: \"8800\" } num_registers: 65536 l1_cache_size: 24576 l2_cache_size: 75497472 shared_memory_size_per_multiprocessor: 102400 memory_size: 22500343808 bandwidth: 1008096000 } outputs { dtype: DT_FLOAT shape { dim { size: -44 } dim { size: 28 } dim { size: 28 } dim { size: 1 } } }\n",
      "W0000 00:00:1733862246.839481     953 op_level_cost_estimator.cc:699] Error in PredictCost() for the op: op: \"CropAndResize\" attr { key: \"T\" value { type: DT_FLOAT } } attr { key: \"extrapolation_value\" value { f: 0 } } attr { key: \"method\" value { s: \"bilinear\" } } inputs { dtype: DT_FLOAT shape { dim { size: -1163 } dim { size: -619 } dim { size: -620 } dim { size: 1 } } } inputs { dtype: DT_FLOAT shape { dim { size: -50 } dim { size: 4 } } } inputs { dtype: DT_INT32 shape { dim { size: -50 } } } inputs { dtype: DT_INT32 shape { dim { size: 2 } } value { dtype: DT_INT32 tensor_shape { dim { size: 2 } } int_val: 28 } } device { type: \"GPU\" vendor: \"NVIDIA\" model: \"NVIDIA GeForce RTX 4090\" frequency: 2520 num_cores: 128 environment { key: \"architecture\" value: \"8.9\" } environment { key: \"cuda\" value: \"12000\" } environment { key: \"cudnn\" value: \"8800\" } num_registers: 65536 l1_cache_size: 24576 l2_cache_size: 75497472 shared_memory_size_per_multiprocessor: 102400 memory_size: 22500343808 bandwidth: 1008096000 } outputs { dtype: DT_FLOAT shape { dim { size: -50 } dim { size: 28 } dim { size: 28 } dim { size: 1 } } }\n",
      "W0000 00:00:1733862246.841084     953 op_level_cost_estimator.cc:699] Error in PredictCost() for the op: op: \"CropAndResize\" attr { key: \"T\" value { type: DT_FLOAT } } attr { key: \"extrapolation_value\" value { f: 0 } } attr { key: \"method\" value { s: \"bilinear\" } } inputs { dtype: DT_FLOAT shape { dim { size: -18 } dim { size: -231 } dim { size: -232 } dim { size: 256 } } } inputs { dtype: DT_FLOAT shape { dim { size: -95 } dim { size: 4 } } } inputs { dtype: DT_INT32 shape { dim { size: -95 } } } inputs { dtype: DT_INT32 shape { dim { size: 2 } } value { dtype: DT_INT32 tensor_shape { dim { size: 2 } } int_val: 7 } } device { type: \"GPU\" vendor: \"NVIDIA\" model: \"NVIDIA GeForce RTX 4090\" frequency: 2520 num_cores: 128 environment { key: \"architecture\" value: \"8.9\" } environment { key: \"cuda\" value: \"12000\" } environment { key: \"cudnn\" value: \"8800\" } num_registers: 65536 l1_cache_size: 24576 l2_cache_size: 75497472 shared_memory_size_per_multiprocessor: 102400 memory_size: 22500343808 bandwidth: 1008096000 } outputs { dtype: DT_FLOAT shape { dim { size: -95 } dim { size: 7 } dim { size: 7 } dim { size: 256 } } }\n",
      "W0000 00:00:1733862246.841126     953 op_level_cost_estimator.cc:699] Error in PredictCost() for the op: op: \"CropAndResize\" attr { key: \"T\" value { type: DT_FLOAT } } attr { key: \"extrapolation_value\" value { f: 0 } } attr { key: \"method\" value { s: \"bilinear\" } } inputs { dtype: DT_FLOAT shape { dim { size: -18 } dim { size: -231 } dim { size: -232 } dim { size: 256 } } } inputs { dtype: DT_FLOAT shape { dim { size: -95 } dim { size: 4 } } } inputs { dtype: DT_INT32 shape { dim { size: -95 } } } inputs { dtype: DT_INT32 shape { dim { size: 2 } } value { dtype: DT_INT32 tensor_shape { dim { size: 2 } } int_val: 14 } } device { type: \"GPU\" vendor: \"NVIDIA\" model: \"NVIDIA GeForce RTX 4090\" frequency: 2520 num_cores: 128 environment { key: \"architecture\" value: \"8.9\" } environment { key: \"cuda\" value: \"12000\" } environment { key: \"cudnn\" value: \"8800\" } num_registers: 65536 l1_cache_size: 24576 l2_cache_size: 75497472 shared_memory_size_per_multiprocessor: 102400 memory_size: 22500343808 bandwidth: 1008096000 } outputs { dtype: DT_FLOAT shape { dim { size: -95 } dim { size: 14 } dim { size: 14 } dim { size: 256 } } }\n",
      "W0000 00:00:1733862246.841151     953 op_level_cost_estimator.cc:699] Error in PredictCost() for the op: op: \"CropAndResize\" attr { key: \"T\" value { type: DT_FLOAT } } attr { key: \"extrapolation_value\" value { f: 0 } } attr { key: \"method\" value { s: \"bilinear\" } } inputs { dtype: DT_FLOAT shape { dim { size: -18 } dim { size: -239 } dim { size: -240 } dim { size: 256 } } } inputs { dtype: DT_FLOAT shape { dim { size: -97 } dim { size: 4 } } } inputs { dtype: DT_INT32 shape { dim { size: -97 } } } inputs { dtype: DT_INT32 shape { dim { size: 2 } } value { dtype: DT_INT32 tensor_shape { dim { size: 2 } } int_val: 7 } } device { type: \"GPU\" vendor: \"NVIDIA\" model: \"NVIDIA GeForce RTX 4090\" frequency: 2520 num_cores: 128 environment { key: \"architecture\" value: \"8.9\" } environment { key: \"cuda\" value: \"12000\" } environment { key: \"cudnn\" value: \"8800\" } num_registers: 65536 l1_cache_size: 24576 l2_cache_size: 75497472 shared_memory_size_per_multiprocessor: 102400 memory_size: 22500343808 bandwidth: 1008096000 } outputs { dtype: DT_FLOAT shape { dim { size: -97 } dim { size: 7 } dim { size: 7 } dim { size: 256 } } }\n",
      "W0000 00:00:1733862246.841173     953 op_level_cost_estimator.cc:699] Error in PredictCost() for the op: op: \"CropAndResize\" attr { key: \"T\" value { type: DT_FLOAT } } attr { key: \"extrapolation_value\" value { f: 0 } } attr { key: \"method\" value { s: \"bilinear\" } } inputs { dtype: DT_FLOAT shape { dim { size: -18 } dim { size: -239 } dim { size: -240 } dim { size: 256 } } } inputs { dtype: DT_FLOAT shape { dim { size: -97 } dim { size: 4 } } } inputs { dtype: DT_INT32 shape { dim { size: -97 } } } inputs { dtype: DT_INT32 shape { dim { size: 2 } } value { dtype: DT_INT32 tensor_shape { dim { size: 2 } } int_val: 14 } } device { type: \"GPU\" vendor: \"NVIDIA\" model: \"NVIDIA GeForce RTX 4090\" frequency: 2520 num_cores: 128 environment { key: \"architecture\" value: \"8.9\" } environment { key: \"cuda\" value: \"12000\" } environment { key: \"cudnn\" value: \"8800\" } num_registers: 65536 l1_cache_size: 24576 l2_cache_size: 75497472 shared_memory_size_per_multiprocessor: 102400 memory_size: 22500343808 bandwidth: 1008096000 } outputs { dtype: DT_FLOAT shape { dim { size: -97 } dim { size: 14 } dim { size: 14 } dim { size: 256 } } }\n",
      "W0000 00:00:1733862246.841205     953 op_level_cost_estimator.cc:699] Error in PredictCost() for the op: op: \"CropAndResize\" attr { key: \"T\" value { type: DT_FLOAT } } attr { key: \"extrapolation_value\" value { f: 0 } } attr { key: \"method\" value { s: \"bilinear\" } } inputs { dtype: DT_FLOAT shape { dim { size: -18 } dim { size: -247 } dim { size: -248 } dim { size: 256 } } } inputs { dtype: DT_FLOAT shape { dim { size: -99 } dim { size: 4 } } } inputs { dtype: DT_INT32 shape { dim { size: -99 } } } inputs { dtype: DT_INT32 shape { dim { size: 2 } } value { dtype: DT_INT32 tensor_shape { dim { size: 2 } } int_val: 7 } } device { type: \"GPU\" vendor: \"NVIDIA\" model: \"NVIDIA GeForce RTX 4090\" frequency: 2520 num_cores: 128 environment { key: \"architecture\" value: \"8.9\" } environment { key: \"cuda\" value: \"12000\" } environment { key: \"cudnn\" value: \"8800\" } num_registers: 65536 l1_cache_size: 24576 l2_cache_size: 75497472 shared_memory_size_per_multiprocessor: 102400 memory_size: 22500343808 bandwidth: 1008096000 } outputs { dtype: DT_FLOAT shape { dim { size: -99 } dim { size: 7 } dim { size: 7 } dim { size: 256 } } }\n",
      "W0000 00:00:1733862246.841240     953 op_level_cost_estimator.cc:699] Error in PredictCost() for the op: op: \"CropAndResize\" attr { key: \"T\" value { type: DT_FLOAT } } attr { key: \"extrapolation_value\" value { f: 0 } } attr { key: \"method\" value { s: \"bilinear\" } } inputs { dtype: DT_FLOAT shape { dim { size: -18 } dim { size: -247 } dim { size: -248 } dim { size: 256 } } } inputs { dtype: DT_FLOAT shape { dim { size: -99 } dim { size: 4 } } } inputs { dtype: DT_INT32 shape { dim { size: -99 } } } inputs { dtype: DT_INT32 shape { dim { size: 2 } } value { dtype: DT_INT32 tensor_shape { dim { size: 2 } } int_val: 14 } } device { type: \"GPU\" vendor: \"NVIDIA\" model: \"NVIDIA GeForce RTX 4090\" frequency: 2520 num_cores: 128 environment { key: \"architecture\" value: \"8.9\" } environment { key: \"cuda\" value: \"12000\" } environment { key: \"cudnn\" value: \"8800\" } num_registers: 65536 l1_cache_size: 24576 l2_cache_size: 75497472 shared_memory_size_per_multiprocessor: 102400 memory_size: 22500343808 bandwidth: 1008096000 } outputs { dtype: DT_FLOAT shape { dim { size: -99 } dim { size: 14 } dim { size: 14 } dim { size: 256 } } }\n",
      "W0000 00:00:1733862246.841284     953 op_level_cost_estimator.cc:699] Error in PredictCost() for the op: op: \"CropAndResize\" attr { key: \"T\" value { type: DT_FLOAT } } attr { key: \"extrapolation_value\" value { f: 0 } } attr { key: \"method\" value { s: \"bilinear\" } } inputs { dtype: DT_FLOAT shape { dim { size: -18 } dim { size: -223 } dim { size: -224 } dim { size: 256 } } } inputs { dtype: DT_FLOAT shape { dim { size: -101 } dim { size: 4 } } } inputs { dtype: DT_INT32 shape { dim { size: -101 } } } inputs { dtype: DT_INT32 shape { dim { size: 2 } } value { dtype: DT_INT32 tensor_shape { dim { size: 2 } } int_val: 7 } } device { type: \"GPU\" vendor: \"NVIDIA\" model: \"NVIDIA GeForce RTX 4090\" frequency: 2520 num_cores: 128 environment { key: \"architecture\" value: \"8.9\" } environment { key: \"cuda\" value: \"12000\" } environment { key: \"cudnn\" value: \"8800\" } num_registers: 65536 l1_cache_size: 24576 l2_cache_size: 75497472 shared_memory_size_per_multiprocessor: 102400 memory_size: 22500343808 bandwidth: 1008096000 } outputs { dtype: DT_FLOAT shape { dim { size: -101 } dim { size: 7 } dim { size: 7 } dim { size: 256 } } }\n",
      "W0000 00:00:1733862246.841319     953 op_level_cost_estimator.cc:699] Error in PredictCost() for the op: op: \"CropAndResize\" attr { key: \"T\" value { type: DT_FLOAT } } attr { key: \"extrapolation_value\" value { f: 0 } } attr { key: \"method\" value { s: \"bilinear\" } } inputs { dtype: DT_FLOAT shape { dim { size: -18 } dim { size: -223 } dim { size: -224 } dim { size: 256 } } } inputs { dtype: DT_FLOAT shape { dim { size: -101 } dim { size: 4 } } } inputs { dtype: DT_INT32 shape { dim { size: -101 } } } inputs { dtype: DT_INT32 shape { dim { size: 2 } } value { dtype: DT_INT32 tensor_shape { dim { size: 2 } } int_val: 14 } } device { type: \"GPU\" vendor: \"NVIDIA\" model: \"NVIDIA GeForce RTX 4090\" frequency: 2520 num_cores: 128 environment { key: \"architecture\" value: \"8.9\" } environment { key: \"cuda\" value: \"12000\" } environment { key: \"cudnn\" value: \"8800\" } num_registers: 65536 l1_cache_size: 24576 l2_cache_size: 75497472 shared_memory_size_per_multiprocessor: 102400 memory_size: 22500343808 bandwidth: 1008096000 } outputs { dtype: DT_FLOAT shape { dim { size: -101 } dim { size: 14 } dim { size: 14 } dim { size: 256 } } }\n",
      "I0000 00:00:1733862250.292033    1592 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250/250 [==============================] - ETA: 0s - loss: 3.1689 - rpn_class_loss: 0.1137 - rpn_bbox_loss: 1.3042 - mrcnn_class_loss: 0.2548 - mrcnn_bbox_loss: 1.4731 - mrcnn_mask_loss: 0.7143"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1733862315.611600     953 op_level_cost_estimator.cc:699] Error in PredictCost() for the op: op: \"CropAndResize\" attr { key: \"T\" value { type: DT_FLOAT } } attr { key: \"extrapolation_value\" value { f: 0 } } attr { key: \"method\" value { s: \"bilinear\" } } inputs { dtype: DT_FLOAT shape { dim { size: -638 } dim { size: -121 } dim { size: -122 } dim { size: 1 } } } inputs { dtype: DT_FLOAT shape { dim { size: -24 } dim { size: 4 } } } inputs { dtype: DT_INT32 shape { dim { size: -24 } } } inputs { dtype: DT_INT32 shape { dim { size: 2 } } value { dtype: DT_INT32 tensor_shape { dim { size: 2 } } int_val: 28 } } device { type: \"GPU\" vendor: \"NVIDIA\" model: \"NVIDIA GeForce RTX 4090\" frequency: 2520 num_cores: 128 environment { key: \"architecture\" value: \"8.9\" } environment { key: \"cuda\" value: \"12000\" } environment { key: \"cudnn\" value: \"8800\" } num_registers: 65536 l1_cache_size: 24576 l2_cache_size: 75497472 shared_memory_size_per_multiprocessor: 102400 memory_size: 22500343808 bandwidth: 1008096000 } outputs { dtype: DT_FLOAT shape { dim { size: -24 } dim { size: 28 } dim { size: 28 } dim { size: 1 } } }\n",
      "W0000 00:00:1733862315.611720     953 op_level_cost_estimator.cc:699] Error in PredictCost() for the op: op: \"CropAndResize\" attr { key: \"T\" value { type: DT_FLOAT } } attr { key: \"extrapolation_value\" value { f: 0 } } attr { key: \"method\" value { s: \"bilinear\" } } inputs { dtype: DT_FLOAT shape { dim { size: -696 } dim { size: -130 } dim { size: -131 } dim { size: 1 } } } inputs { dtype: DT_FLOAT shape { dim { size: -42 } dim { size: 4 } } } inputs { dtype: DT_INT32 shape { dim { size: -42 } } } inputs { dtype: DT_INT32 shape { dim { size: 2 } } value { dtype: DT_INT32 tensor_shape { dim { size: 2 } } int_val: 28 } } device { type: \"GPU\" vendor: \"NVIDIA\" model: \"NVIDIA GeForce RTX 4090\" frequency: 2520 num_cores: 128 environment { key: \"architecture\" value: \"8.9\" } environment { key: \"cuda\" value: \"12000\" } environment { key: \"cudnn\" value: \"8800\" } num_registers: 65536 l1_cache_size: 24576 l2_cache_size: 75497472 shared_memory_size_per_multiprocessor: 102400 memory_size: 22500343808 bandwidth: 1008096000 } outputs { dtype: DT_FLOAT shape { dim { size: -42 } dim { size: 28 } dim { size: 28 } dim { size: 1 } } }\n",
      "W0000 00:00:1733862315.611766     953 op_level_cost_estimator.cc:699] Error in PredictCost() for the op: op: \"CropAndResize\" attr { key: \"T\" value { type: DT_FLOAT } } attr { key: \"extrapolation_value\" value { f: 0 } } attr { key: \"method\" value { s: \"bilinear\" } } inputs { dtype: DT_FLOAT shape { dim { size: -660 } dim { size: -124 } dim { size: -125 } dim { size: 1 } } } inputs { dtype: DT_FLOAT shape { dim { size: -30 } dim { size: 4 } } } inputs { dtype: DT_INT32 shape { dim { size: -30 } } } inputs { dtype: DT_INT32 shape { dim { size: 2 } } value { dtype: DT_INT32 tensor_shape { dim { size: 2 } } int_val: 28 } } device { type: \"GPU\" vendor: \"NVIDIA\" model: \"NVIDIA GeForce RTX 4090\" frequency: 2520 num_cores: 128 environment { key: \"architecture\" value: \"8.9\" } environment { key: \"cuda\" value: \"12000\" } environment { key: \"cudnn\" value: \"8800\" } num_registers: 65536 l1_cache_size: 24576 l2_cache_size: 75497472 shared_memory_size_per_multiprocessor: 102400 memory_size: 22500343808 bandwidth: 1008096000 } outputs { dtype: DT_FLOAT shape { dim { size: -30 } dim { size: 28 } dim { size: 28 } dim { size: 1 } } }\n",
      "W0000 00:00:1733862315.611808     953 op_level_cost_estimator.cc:699] Error in PredictCost() for the op: op: \"CropAndResize\" attr { key: \"T\" value { type: DT_FLOAT } } attr { key: \"extrapolation_value\" value { f: 0 } } attr { key: \"method\" value { s: \"bilinear\" } } inputs { dtype: DT_FLOAT shape { dim { size: -681 } dim { size: -127 } dim { size: -128 } dim { size: 1 } } } inputs { dtype: DT_FLOAT shape { dim { size: -36 } dim { size: 4 } } } inputs { dtype: DT_INT32 shape { dim { size: -36 } } } inputs { dtype: DT_INT32 shape { dim { size: 2 } } value { dtype: DT_INT32 tensor_shape { dim { size: 2 } } int_val: 28 } } device { type: \"GPU\" vendor: \"NVIDIA\" model: \"NVIDIA GeForce RTX 4090\" frequency: 2520 num_cores: 128 environment { key: \"architecture\" value: \"8.9\" } environment { key: \"cuda\" value: \"12000\" } environment { key: \"cudnn\" value: \"8800\" } num_registers: 65536 l1_cache_size: 24576 l2_cache_size: 75497472 shared_memory_size_per_multiprocessor: 102400 memory_size: 22500343808 bandwidth: 1008096000 } outputs { dtype: DT_FLOAT shape { dim { size: -36 } dim { size: 28 } dim { size: 28 } dim { size: 1 } } }\n",
      "W0000 00:00:1733862315.612831     953 op_level_cost_estimator.cc:699] Error in PredictCost() for the op: op: \"CropAndResize\" attr { key: \"T\" value { type: DT_FLOAT } } attr { key: \"extrapolation_value\" value { f: 0 } } attr { key: \"method\" value { s: \"bilinear\" } } inputs { dtype: DT_FLOAT shape { dim { size: -96 } dim { size: -440 } dim { size: -441 } dim { size: 256 } } } inputs { dtype: DT_FLOAT shape { dim { size: -81 } dim { size: 4 } } } inputs { dtype: DT_INT32 shape { dim { size: -81 } } } inputs { dtype: DT_INT32 shape { dim { size: 2 } } value { dtype: DT_INT32 tensor_shape { dim { size: 2 } } int_val: 7 } } device { type: \"GPU\" vendor: \"NVIDIA\" model: \"NVIDIA GeForce RTX 4090\" frequency: 2520 num_cores: 128 environment { key: \"architecture\" value: \"8.9\" } environment { key: \"cuda\" value: \"12000\" } environment { key: \"cudnn\" value: \"8800\" } num_registers: 65536 l1_cache_size: 24576 l2_cache_size: 75497472 shared_memory_size_per_multiprocessor: 102400 memory_size: 22500343808 bandwidth: 1008096000 } outputs { dtype: DT_FLOAT shape { dim { size: -81 } dim { size: 7 } dim { size: 7 } dim { size: 256 } } }\n",
      "W0000 00:00:1733862315.612867     953 op_level_cost_estimator.cc:699] Error in PredictCost() for the op: op: \"CropAndResize\" attr { key: \"T\" value { type: DT_FLOAT } } attr { key: \"extrapolation_value\" value { f: 0 } } attr { key: \"method\" value { s: \"bilinear\" } } inputs { dtype: DT_FLOAT shape { dim { size: -96 } dim { size: -440 } dim { size: -441 } dim { size: 256 } } } inputs { dtype: DT_FLOAT shape { dim { size: -81 } dim { size: 4 } } } inputs { dtype: DT_INT32 shape { dim { size: -81 } } } inputs { dtype: DT_INT32 shape { dim { size: 2 } } value { dtype: DT_INT32 tensor_shape { dim { size: 2 } } int_val: 14 } } device { type: \"GPU\" vendor: \"NVIDIA\" model: \"NVIDIA GeForce RTX 4090\" frequency: 2520 num_cores: 128 environment { key: \"architecture\" value: \"8.9\" } environment { key: \"cuda\" value: \"12000\" } environment { key: \"cudnn\" value: \"8800\" } num_registers: 65536 l1_cache_size: 24576 l2_cache_size: 75497472 shared_memory_size_per_multiprocessor: 102400 memory_size: 22500343808 bandwidth: 1008096000 } outputs { dtype: DT_FLOAT shape { dim { size: -81 } dim { size: 14 } dim { size: 14 } dim { size: 256 } } }\n",
      "W0000 00:00:1733862315.612898     953 op_level_cost_estimator.cc:699] Error in PredictCost() for the op: op: \"CropAndResize\" attr { key: \"T\" value { type: DT_FLOAT } } attr { key: \"extrapolation_value\" value { f: 0 } } attr { key: \"method\" value { s: \"bilinear\" } } inputs { dtype: DT_FLOAT shape { dim { size: -96 } dim { size: -430 } dim { size: -431 } dim { size: 256 } } } inputs { dtype: DT_FLOAT shape { dim { size: -83 } dim { size: 4 } } } inputs { dtype: DT_INT32 shape { dim { size: -83 } } } inputs { dtype: DT_INT32 shape { dim { size: 2 } } value { dtype: DT_INT32 tensor_shape { dim { size: 2 } } int_val: 7 } } device { type: \"GPU\" vendor: \"NVIDIA\" model: \"NVIDIA GeForce RTX 4090\" frequency: 2520 num_cores: 128 environment { key: \"architecture\" value: \"8.9\" } environment { key: \"cuda\" value: \"12000\" } environment { key: \"cudnn\" value: \"8800\" } num_registers: 65536 l1_cache_size: 24576 l2_cache_size: 75497472 shared_memory_size_per_multiprocessor: 102400 memory_size: 22500343808 bandwidth: 1008096000 } outputs { dtype: DT_FLOAT shape { dim { size: -83 } dim { size: 7 } dim { size: 7 } dim { size: 256 } } }\n",
      "W0000 00:00:1733862315.612919     953 op_level_cost_estimator.cc:699] Error in PredictCost() for the op: op: \"CropAndResize\" attr { key: \"T\" value { type: DT_FLOAT } } attr { key: \"extrapolation_value\" value { f: 0 } } attr { key: \"method\" value { s: \"bilinear\" } } inputs { dtype: DT_FLOAT shape { dim { size: -96 } dim { size: -430 } dim { size: -431 } dim { size: 256 } } } inputs { dtype: DT_FLOAT shape { dim { size: -83 } dim { size: 4 } } } inputs { dtype: DT_INT32 shape { dim { size: -83 } } } inputs { dtype: DT_INT32 shape { dim { size: 2 } } value { dtype: DT_INT32 tensor_shape { dim { size: 2 } } int_val: 14 } } device { type: \"GPU\" vendor: \"NVIDIA\" model: \"NVIDIA GeForce RTX 4090\" frequency: 2520 num_cores: 128 environment { key: \"architecture\" value: \"8.9\" } environment { key: \"cuda\" value: \"12000\" } environment { key: \"cudnn\" value: \"8800\" } num_registers: 65536 l1_cache_size: 24576 l2_cache_size: 75497472 shared_memory_size_per_multiprocessor: 102400 memory_size: 22500343808 bandwidth: 1008096000 } outputs { dtype: DT_FLOAT shape { dim { size: -83 } dim { size: 14 } dim { size: 14 } dim { size: 256 } } }\n",
      "W0000 00:00:1733862315.612946     953 op_level_cost_estimator.cc:699] Error in PredictCost() for the op: op: \"CropAndResize\" attr { key: \"T\" value { type: DT_FLOAT } } attr { key: \"extrapolation_value\" value { f: 0 } } attr { key: \"method\" value { s: \"bilinear\" } } inputs { dtype: DT_FLOAT shape { dim { size: -96 } dim { size: -418 } dim { size: -419 } dim { size: 256 } } } inputs { dtype: DT_FLOAT shape { dim { size: -85 } dim { size: 4 } } } inputs { dtype: DT_INT32 shape { dim { size: -85 } } } inputs { dtype: DT_INT32 shape { dim { size: 2 } } value { dtype: DT_INT32 tensor_shape { dim { size: 2 } } int_val: 7 } } device { type: \"GPU\" vendor: \"NVIDIA\" model: \"NVIDIA GeForce RTX 4090\" frequency: 2520 num_cores: 128 environment { key: \"architecture\" value: \"8.9\" } environment { key: \"cuda\" value: \"12000\" } environment { key: \"cudnn\" value: \"8800\" } num_registers: 65536 l1_cache_size: 24576 l2_cache_size: 75497472 shared_memory_size_per_multiprocessor: 102400 memory_size: 22500343808 bandwidth: 1008096000 } outputs { dtype: DT_FLOAT shape { dim { size: -85 } dim { size: 7 } dim { size: 7 } dim { size: 256 } } }\n",
      "W0000 00:00:1733862315.612976     953 op_level_cost_estimator.cc:699] Error in PredictCost() for the op: op: \"CropAndResize\" attr { key: \"T\" value { type: DT_FLOAT } } attr { key: \"extrapolation_value\" value { f: 0 } } attr { key: \"method\" value { s: \"bilinear\" } } inputs { dtype: DT_FLOAT shape { dim { size: -96 } dim { size: -418 } dim { size: -419 } dim { size: 256 } } } inputs { dtype: DT_FLOAT shape { dim { size: -85 } dim { size: 4 } } } inputs { dtype: DT_INT32 shape { dim { size: -85 } } } inputs { dtype: DT_INT32 shape { dim { size: 2 } } value { dtype: DT_INT32 tensor_shape { dim { size: 2 } } int_val: 14 } } device { type: \"GPU\" vendor: \"NVIDIA\" model: \"NVIDIA GeForce RTX 4090\" frequency: 2520 num_cores: 128 environment { key: \"architecture\" value: \"8.9\" } environment { key: \"cuda\" value: \"12000\" } environment { key: \"cudnn\" value: \"8800\" } num_registers: 65536 l1_cache_size: 24576 l2_cache_size: 75497472 shared_memory_size_per_multiprocessor: 102400 memory_size: 22500343808 bandwidth: 1008096000 } outputs { dtype: DT_FLOAT shape { dim { size: -85 } dim { size: 14 } dim { size: 14 } dim { size: 256 } } }\n",
      "W0000 00:00:1733862315.613013     953 op_level_cost_estimator.cc:699] Error in PredictCost() for the op: op: \"CropAndResize\" attr { key: \"T\" value { type: DT_FLOAT } } attr { key: \"extrapolation_value\" value { f: 0 } } attr { key: \"method\" value { s: \"bilinear\" } } inputs { dtype: DT_FLOAT shape { dim { size: -96 } dim { size: -404 } dim { size: -405 } dim { size: 256 } } } inputs { dtype: DT_FLOAT shape { dim { size: -87 } dim { size: 4 } } } inputs { dtype: DT_INT32 shape { dim { size: -87 } } } inputs { dtype: DT_INT32 shape { dim { size: 2 } } value { dtype: DT_INT32 tensor_shape { dim { size: 2 } } int_val: 7 } } device { type: \"GPU\" vendor: \"NVIDIA\" model: \"NVIDIA GeForce RTX 4090\" frequency: 2520 num_cores: 128 environment { key: \"architecture\" value: \"8.9\" } environment { key: \"cuda\" value: \"12000\" } environment { key: \"cudnn\" value: \"8800\" } num_registers: 65536 l1_cache_size: 24576 l2_cache_size: 75497472 shared_memory_size_per_multiprocessor: 102400 memory_size: 22500343808 bandwidth: 1008096000 } outputs { dtype: DT_FLOAT shape { dim { size: -87 } dim { size: 7 } dim { size: 7 } dim { size: 256 } } }\n",
      "W0000 00:00:1733862315.613043     953 op_level_cost_estimator.cc:699] Error in PredictCost() for the op: op: \"CropAndResize\" attr { key: \"T\" value { type: DT_FLOAT } } attr { key: \"extrapolation_value\" value { f: 0 } } attr { key: \"method\" value { s: \"bilinear\" } } inputs { dtype: DT_FLOAT shape { dim { size: -96 } dim { size: -404 } dim { size: -405 } dim { size: 256 } } } inputs { dtype: DT_FLOAT shape { dim { size: -87 } dim { size: 4 } } } inputs { dtype: DT_INT32 shape { dim { size: -87 } } } inputs { dtype: DT_INT32 shape { dim { size: 2 } } value { dtype: DT_INT32 tensor_shape { dim { size: 2 } } int_val: 14 } } device { type: \"GPU\" vendor: \"NVIDIA\" model: \"NVIDIA GeForce RTX 4090\" frequency: 2520 num_cores: 128 environment { key: \"architecture\" value: \"8.9\" } environment { key: \"cuda\" value: \"12000\" } environment { key: \"cudnn\" value: \"8800\" } num_registers: 65536 l1_cache_size: 24576 l2_cache_size: 75497472 shared_memory_size_per_multiprocessor: 102400 memory_size: 22500343808 bandwidth: 1008096000 } outputs { dtype: DT_FLOAT shape { dim { size: -87 } dim { size: 14 } dim { size: 14 } dim { size: 256 } } }\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250/250 [==============================] - 92s 229ms/step - loss: 3.1689 - rpn_class_loss: 0.1137 - rpn_bbox_loss: 1.3042 - mrcnn_class_loss: 0.2548 - mrcnn_bbox_loss: 1.4706 - mrcnn_mask_loss: 0.7140 - val_loss: 2.2738 - val_rpn_class_loss: 0.0225 - val_rpn_bbox_loss: 0.9038 - val_mrcnn_class_loss: 0.2563 - val_mrcnn_bbox_loss: 0.4985 - val_mrcnn_mask_loss: 0.5926\n",
      "Epoch 3: Learning rate is 0.000300 (warmup phase).\n",
      "Epoch 3/500\n",
      "250/250 [==============================] - 56s 223ms/step - loss: 2.0510 - rpn_class_loss: 0.0249 - rpn_bbox_loss: 0.8135 - mrcnn_class_loss: 0.2207 - mrcnn_bbox_loss: 0.4725 - mrcnn_mask_loss: 0.5867 - val_loss: 1.9167 - val_rpn_class_loss: 0.0213 - val_rpn_bbox_loss: 0.7611 - val_mrcnn_class_loss: 0.1823 - val_mrcnn_bbox_loss: 0.3778 - val_mrcnn_mask_loss: 0.5743\n",
      "Epoch 4: Learning rate is 0.000400 (warmup phase).\n",
      "Epoch 4/500\n",
      "250/250 [==============================] - 56s 225ms/step - loss: 1.7109 - rpn_class_loss: 0.0231 - rpn_bbox_loss: 0.6619 - mrcnn_class_loss: 0.1669 - mrcnn_bbox_loss: 0.3769 - mrcnn_mask_loss: 0.5251 - val_loss: 1.5924 - val_rpn_class_loss: 0.0204 - val_rpn_bbox_loss: 0.5609 - val_mrcnn_class_loss: 0.2043 - val_mrcnn_bbox_loss: 0.3242 - val_mrcnn_mask_loss: 0.4827\n",
      "Epoch 5: Learning rate is 0.000500 (warmup phase).\n",
      "Epoch 5/500\n",
      "250/250 [==============================] - 56s 224ms/step - loss: 1.4281 - rpn_class_loss: 0.0203 - rpn_bbox_loss: 0.5372 - mrcnn_class_loss: 0.1630 - mrcnn_bbox_loss: 0.2982 - mrcnn_mask_loss: 0.4395 - val_loss: 1.2070 - val_rpn_class_loss: 0.0181 - val_rpn_bbox_loss: 0.3859 - val_mrcnn_class_loss: 0.1410 - val_mrcnn_bbox_loss: 0.2673 - val_mrcnn_mask_loss: 0.3947\n",
      "Epoch 6: Learning rate is 0.000600 (warmup phase).\n",
      "Epoch 6/500\n",
      "250/250 [==============================] - 56s 224ms/step - loss: 1.1649 - rpn_class_loss: 0.0167 - rpn_bbox_loss: 0.4259 - mrcnn_class_loss: 0.1496 - mrcnn_bbox_loss: 0.2400 - mrcnn_mask_loss: 0.3573 - val_loss: 1.1090 - val_rpn_class_loss: 0.0153 - val_rpn_bbox_loss: 0.4122 - val_mrcnn_class_loss: 0.1345 - val_mrcnn_bbox_loss: 0.2333 - val_mrcnn_mask_loss: 0.3136\n",
      "Epoch 7: Learning rate is 0.000700 (warmup phase).\n",
      "Epoch 7/500\n",
      "250/250 [==============================] - 57s 226ms/step - loss: 1.0265 - rpn_class_loss: 0.0140 - rpn_bbox_loss: 0.3751 - mrcnn_class_loss: 0.1392 - mrcnn_bbox_loss: 0.2149 - mrcnn_mask_loss: 0.2909 - val_loss: 1.0012 - val_rpn_class_loss: 0.0114 - val_rpn_bbox_loss: 0.3307 - val_mrcnn_class_loss: 0.1634 - val_mrcnn_bbox_loss: 0.2048 - val_mrcnn_mask_loss: 0.2909\n",
      "Epoch 8: Learning rate is 0.000800 (warmup phase).\n",
      "Epoch 8/500\n",
      "250/250 [==============================] - 56s 224ms/step - loss: 0.8848 - rpn_class_loss: 0.0119 - rpn_bbox_loss: 0.3170 - mrcnn_class_loss: 0.1332 - mrcnn_bbox_loss: 0.1859 - mrcnn_mask_loss: 0.2582 - val_loss: 0.8776 - val_rpn_class_loss: 0.0105 - val_rpn_bbox_loss: 0.2870 - val_mrcnn_class_loss: 0.1326 - val_mrcnn_bbox_loss: 0.1863 - val_mrcnn_mask_loss: 0.2612\n",
      "Epoch 9: Learning rate is 0.000900 (warmup phase).\n",
      "Epoch 9/500\n",
      "250/250 [==============================] - 56s 225ms/step - loss: 0.7962 - rpn_class_loss: 0.0102 - rpn_bbox_loss: 0.2794 - mrcnn_class_loss: 0.1159 - mrcnn_bbox_loss: 0.1661 - mrcnn_mask_loss: 0.2389 - val_loss: 0.7518 - val_rpn_class_loss: 0.0091 - val_rpn_bbox_loss: 0.2277 - val_mrcnn_class_loss: 0.1122 - val_mrcnn_bbox_loss: 0.1641 - val_mrcnn_mask_loss: 0.2388\n",
      "Epoch 10: Learning rate is 0.001000 (warmup phase).\n",
      "Epoch 10/500\n",
      "250/250 [==============================] - 55s 220ms/step - loss: 0.7051 - rpn_class_loss: 0.0090 - rpn_bbox_loss: 0.2446 - mrcnn_class_loss: 0.0898 - mrcnn_bbox_loss: 0.1372 - mrcnn_mask_loss: 0.2095 - val_loss: 0.7613 - val_rpn_class_loss: 0.0109 - val_rpn_bbox_loss: 0.1985 - val_mrcnn_class_loss: 0.1277 - val_mrcnn_bbox_loss: 0.1755 - val_mrcnn_mask_loss: 0.2488\n",
      "Epoch 11/500\n",
      "250/250 [==============================] - 57s 227ms/step - loss: 0.6869 - rpn_class_loss: 0.0082 - rpn_bbox_loss: 0.2382 - mrcnn_class_loss: 0.0965 - mrcnn_bbox_loss: 0.1409 - mrcnn_mask_loss: 0.1988 - val_loss: 0.5959 - val_rpn_class_loss: 0.0075 - val_rpn_bbox_loss: 0.1530 - val_mrcnn_class_loss: 0.1068 - val_mrcnn_bbox_loss: 0.1216 - val_mrcnn_mask_loss: 0.2070\n",
      "Epoch 12/500\n",
      "250/250 [==============================] - 56s 224ms/step - loss: 0.5948 - rpn_class_loss: 0.0077 - rpn_bbox_loss: 0.2062 - mrcnn_class_loss: 0.0955 - mrcnn_bbox_loss: 0.1173 - mrcnn_mask_loss: 0.1891 - val_loss: 0.5535 - val_rpn_class_loss: 0.0070 - val_rpn_bbox_loss: 0.1300 - val_mrcnn_class_loss: 0.1076 - val_mrcnn_bbox_loss: 0.1188 - val_mrcnn_mask_loss: 0.1901\n",
      "Epoch 13/500\n",
      "250/250 [==============================] - 56s 225ms/step - loss: 0.5164 - rpn_class_loss: 0.0064 - rpn_bbox_loss: 0.1712 - mrcnn_class_loss: 0.0711 - mrcnn_bbox_loss: 0.0947 - mrcnn_mask_loss: 0.1661 - val_loss: 0.4991 - val_rpn_class_loss: 0.0058 - val_rpn_bbox_loss: 0.1176 - val_mrcnn_class_loss: 0.0898 - val_mrcnn_bbox_loss: 0.1015 - val_mrcnn_mask_loss: 0.1844\n",
      "Epoch 14/500\n",
      "250/250 [==============================] - 57s 226ms/step - loss: 0.4930 - rpn_class_loss: 0.0065 - rpn_bbox_loss: 0.1524 - mrcnn_class_loss: 0.0682 - mrcnn_bbox_loss: 0.0942 - mrcnn_mask_loss: 0.1690 - val_loss: 0.4724 - val_rpn_class_loss: 0.0056 - val_rpn_bbox_loss: 0.1058 - val_mrcnn_class_loss: 0.0714 - val_mrcnn_bbox_loss: 0.0963 - val_mrcnn_mask_loss: 0.1933\n",
      "Epoch 15/500\n",
      "250/250 [==============================] - 57s 227ms/step - loss: 0.4226 - rpn_class_loss: 0.0055 - rpn_bbox_loss: 0.1268 - mrcnn_class_loss: 0.0601 - mrcnn_bbox_loss: 0.0788 - mrcnn_mask_loss: 0.1523 - val_loss: 0.4401 - val_rpn_class_loss: 0.0053 - val_rpn_bbox_loss: 0.1095 - val_mrcnn_class_loss: 0.0706 - val_mrcnn_bbox_loss: 0.0842 - val_mrcnn_mask_loss: 0.1705\n",
      "Epoch 16/500\n",
      "250/250 [==============================] - 57s 226ms/step - loss: 0.3966 - rpn_class_loss: 0.0049 - rpn_bbox_loss: 0.1090 - mrcnn_class_loss: 0.0559 - mrcnn_bbox_loss: 0.0760 - mrcnn_mask_loss: 0.1511 - val_loss: 0.4106 - val_rpn_class_loss: 0.0041 - val_rpn_bbox_loss: 0.0829 - val_mrcnn_class_loss: 0.0628 - val_mrcnn_bbox_loss: 0.0800 - val_mrcnn_mask_loss: 0.1808\n",
      "Epoch 17/500\n",
      "250/250 [==============================] - 57s 227ms/step - loss: 0.3590 - rpn_class_loss: 0.0046 - rpn_bbox_loss: 0.0871 - mrcnn_class_loss: 0.0499 - mrcnn_bbox_loss: 0.0692 - mrcnn_mask_loss: 0.1494 - val_loss: 0.4030 - val_rpn_class_loss: 0.0040 - val_rpn_bbox_loss: 0.0639 - val_mrcnn_class_loss: 0.0561 - val_mrcnn_bbox_loss: 0.0703 - val_mrcnn_mask_loss: 0.2087\n",
      "Epoch 18/500\n",
      "250/250 [==============================] - 56s 222ms/step - loss: 0.3244 - rpn_class_loss: 0.0041 - rpn_bbox_loss: 0.0691 - mrcnn_class_loss: 0.0458 - mrcnn_bbox_loss: 0.0622 - mrcnn_mask_loss: 0.1461 - val_loss: 0.3107 - val_rpn_class_loss: 0.0041 - val_rpn_bbox_loss: 0.0448 - val_mrcnn_class_loss: 0.0524 - val_mrcnn_bbox_loss: 0.0625 - val_mrcnn_mask_loss: 0.1470\n",
      "Epoch 19/500\n",
      "250/250 [==============================] - 55s 219ms/step - loss: 0.3165 - rpn_class_loss: 0.0038 - rpn_bbox_loss: 0.0762 - mrcnn_class_loss: 0.0430 - mrcnn_bbox_loss: 0.0582 - mrcnn_mask_loss: 0.1325 - val_loss: 0.3157 - val_rpn_class_loss: 0.0037 - val_rpn_bbox_loss: 0.0508 - val_mrcnn_class_loss: 0.0504 - val_mrcnn_bbox_loss: 0.0600 - val_mrcnn_mask_loss: 0.1508\n",
      "Epoch 20/500\n",
      "250/250 [==============================] - 56s 224ms/step - loss: 0.2857 - rpn_class_loss: 0.0037 - rpn_bbox_loss: 0.0613 - mrcnn_class_loss: 0.0386 - mrcnn_bbox_loss: 0.0511 - mrcnn_mask_loss: 0.1295 - val_loss: 0.3054 - val_rpn_class_loss: 0.0044 - val_rpn_bbox_loss: 0.0380 - val_mrcnn_class_loss: 0.0475 - val_mrcnn_bbox_loss: 0.0582 - val_mrcnn_mask_loss: 0.1573\n",
      "Epoch 21/500\n",
      "250/250 [==============================] - 56s 222ms/step - loss: 0.2695 - rpn_class_loss: 0.0035 - rpn_bbox_loss: 0.0517 - mrcnn_class_loss: 0.0381 - mrcnn_bbox_loss: 0.0480 - mrcnn_mask_loss: 0.1407 - val_loss: 0.2811 - val_rpn_class_loss: 0.0036 - val_rpn_bbox_loss: 0.0344 - val_mrcnn_class_loss: 0.0471 - val_mrcnn_bbox_loss: 0.0509 - val_mrcnn_mask_loss: 0.1451\n",
      "Epoch 22/500\n",
      "250/250 [==============================] - 55s 220ms/step - loss: 0.2605 - rpn_class_loss: 0.0031 - rpn_bbox_loss: 0.0508 - mrcnn_class_loss: 0.0363 - mrcnn_bbox_loss: 0.0438 - mrcnn_mask_loss: 0.1172 - val_loss: 0.2757 - val_rpn_class_loss: 0.0036 - val_rpn_bbox_loss: 0.0359 - val_mrcnn_class_loss: 0.0438 - val_mrcnn_bbox_loss: 0.0503 - val_mrcnn_mask_loss: 0.1421\n",
      "Epoch 23/500\n",
      "250/250 [==============================] - 56s 222ms/step - loss: 0.2533 - rpn_class_loss: 0.0029 - rpn_bbox_loss: 0.0445 - mrcnn_class_loss: 0.0376 - mrcnn_bbox_loss: 0.0452 - mrcnn_mask_loss: 0.1247 - val_loss: 0.2668 - val_rpn_class_loss: 0.0036 - val_rpn_bbox_loss: 0.0327 - val_mrcnn_class_loss: 0.0430 - val_mrcnn_bbox_loss: 0.0462 - val_mrcnn_mask_loss: 0.1413\n",
      "Epoch 24/500\n",
      "250/250 [==============================] - 55s 221ms/step - loss: 0.2424 - rpn_class_loss: 0.0029 - rpn_bbox_loss: 0.0430 - mrcnn_class_loss: 0.0350 - mrcnn_bbox_loss: 0.0403 - mrcnn_mask_loss: 0.1216 - val_loss: 0.2666 - val_rpn_class_loss: 0.0033 - val_rpn_bbox_loss: 0.0265 - val_mrcnn_class_loss: 0.0461 - val_mrcnn_bbox_loss: 0.0501 - val_mrcnn_mask_loss: 0.1406\n",
      "Epoch 25/500\n",
      "250/250 [==============================] - 55s 221ms/step - loss: 0.2323 - rpn_class_loss: 0.0029 - rpn_bbox_loss: 0.0380 - mrcnn_class_loss: 0.0338 - mrcnn_bbox_loss: 0.0368 - mrcnn_mask_loss: 0.1161 - val_loss: 0.2417 - val_rpn_class_loss: 0.0033 - val_rpn_bbox_loss: 0.0262 - val_mrcnn_class_loss: 0.0421 - val_mrcnn_bbox_loss: 0.0398 - val_mrcnn_mask_loss: 0.1304\n",
      "Epoch 26/500\n",
      "250/250 [==============================] - 55s 218ms/step - loss: 0.2256 - rpn_class_loss: 0.0026 - rpn_bbox_loss: 0.0370 - mrcnn_class_loss: 0.0308 - mrcnn_bbox_loss: 0.0354 - mrcnn_mask_loss: 0.1091 - val_loss: 0.2627 - val_rpn_class_loss: 0.0032 - val_rpn_bbox_loss: 0.0334 - val_mrcnn_class_loss: 0.0446 - val_mrcnn_bbox_loss: 0.0415 - val_mrcnn_mask_loss: 0.1400\n",
      "Epoch 27/500\n",
      "250/250 [==============================] - 56s 223ms/step - loss: 0.2259 - rpn_class_loss: 0.0026 - rpn_bbox_loss: 0.0393 - mrcnn_class_loss: 0.0327 - mrcnn_bbox_loss: 0.0381 - mrcnn_mask_loss: 0.1183 - val_loss: 0.2406 - val_rpn_class_loss: 0.0033 - val_rpn_bbox_loss: 0.0283 - val_mrcnn_class_loss: 0.0368 - val_mrcnn_bbox_loss: 0.0413 - val_mrcnn_mask_loss: 0.1309\n",
      "Epoch 28/500\n",
      "250/250 [==============================] - 56s 225ms/step - loss: 0.2174 - rpn_class_loss: 0.0025 - rpn_bbox_loss: 0.0374 - mrcnn_class_loss: 0.0315 - mrcnn_bbox_loss: 0.0369 - mrcnn_mask_loss: 0.1186 - val_loss: 0.2104 - val_rpn_class_loss: 0.0025 - val_rpn_bbox_loss: 0.0233 - val_mrcnn_class_loss: 0.0332 - val_mrcnn_bbox_loss: 0.0323 - val_mrcnn_mask_loss: 0.1191\n",
      "Epoch 29/500\n",
      "250/250 [==============================] - 54s 217ms/step - loss: 0.2121 - rpn_class_loss: 0.0025 - rpn_bbox_loss: 0.0361 - mrcnn_class_loss: 0.0264 - mrcnn_bbox_loss: 0.0323 - mrcnn_mask_loss: 0.1048 - val_loss: 0.2312 - val_rpn_class_loss: 0.0030 - val_rpn_bbox_loss: 0.0279 - val_mrcnn_class_loss: 0.0334 - val_mrcnn_bbox_loss: 0.0401 - val_mrcnn_mask_loss: 0.1270\n",
      "Epoch 30/500\n",
      "250/250 [==============================] - 54s 217ms/step - loss: 0.1964 - rpn_class_loss: 0.0023 - rpn_bbox_loss: 0.0309 - mrcnn_class_loss: 0.0248 - mrcnn_bbox_loss: 0.0315 - mrcnn_mask_loss: 0.1102 - val_loss: 0.2154 - val_rpn_class_loss: 0.0025 - val_rpn_bbox_loss: 0.0210 - val_mrcnn_class_loss: 0.0311 - val_mrcnn_bbox_loss: 0.0376 - val_mrcnn_mask_loss: 0.1231\n",
      "Epoch 31/500\n",
      "250/250 [==============================] - 55s 221ms/step - loss: 0.1926 - rpn_class_loss: 0.0023 - rpn_bbox_loss: 0.0306 - mrcnn_class_loss: 0.0256 - mrcnn_bbox_loss: 0.0325 - mrcnn_mask_loss: 0.1095 - val_loss: 0.2208 - val_rpn_class_loss: 0.0025 - val_rpn_bbox_loss: 0.0191 - val_mrcnn_class_loss: 0.0327 - val_mrcnn_bbox_loss: 0.0342 - val_mrcnn_mask_loss: 0.1323\n",
      "Epoch 32/500\n",
      "250/250 [==============================] - 55s 221ms/step - loss: 0.1905 - rpn_class_loss: 0.0023 - rpn_bbox_loss: 0.0283 - mrcnn_class_loss: 0.0236 - mrcnn_bbox_loss: 0.0297 - mrcnn_mask_loss: 0.1086 - val_loss: 0.1973 - val_rpn_class_loss: 0.0022 - val_rpn_bbox_loss: 0.0211 - val_mrcnn_class_loss: 0.0268 - val_mrcnn_bbox_loss: 0.0310 - val_mrcnn_mask_loss: 0.1163\n",
      "Epoch 33/500\n",
      "250/250 [==============================] - 54s 217ms/step - loss: 0.1831 - rpn_class_loss: 0.0021 - rpn_bbox_loss: 0.0297 - mrcnn_class_loss: 0.0223 - mrcnn_bbox_loss: 0.0258 - mrcnn_mask_loss: 0.1024 - val_loss: 0.1997 - val_rpn_class_loss: 0.0023 - val_rpn_bbox_loss: 0.0218 - val_mrcnn_class_loss: 0.0203 - val_mrcnn_bbox_loss: 0.0355 - val_mrcnn_mask_loss: 0.1198\n",
      "Epoch 34/500\n",
      "250/250 [==============================] - 55s 221ms/step - loss: 0.1831 - rpn_class_loss: 0.0020 - rpn_bbox_loss: 0.0277 - mrcnn_class_loss: 0.0183 - mrcnn_bbox_loss: 0.0289 - mrcnn_mask_loss: 0.1067 - val_loss: 0.1911 - val_rpn_class_loss: 0.0024 - val_rpn_bbox_loss: 0.0215 - val_mrcnn_class_loss: 0.0281 - val_mrcnn_bbox_loss: 0.0291 - val_mrcnn_mask_loss: 0.1101\n",
      "Epoch 35/500\n",
      "250/250 [==============================] - 55s 221ms/step - loss: 0.1897 - rpn_class_loss: 0.0022 - rpn_bbox_loss: 0.0356 - mrcnn_class_loss: 0.0224 - mrcnn_bbox_loss: 0.0265 - mrcnn_mask_loss: 0.0981 - val_loss: 0.1849 - val_rpn_class_loss: 0.0022 - val_rpn_bbox_loss: 0.0214 - val_mrcnn_class_loss: 0.0304 - val_mrcnn_bbox_loss: 0.0278 - val_mrcnn_mask_loss: 0.1031\n",
      "Epoch 36/500\n",
      "250/250 [==============================] - 55s 221ms/step - loss: 0.1761 - rpn_class_loss: 0.0020 - rpn_bbox_loss: 0.0286 - mrcnn_class_loss: 0.0202 - mrcnn_bbox_loss: 0.0252 - mrcnn_mask_loss: 0.0938 - val_loss: 0.1818 - val_rpn_class_loss: 0.0021 - val_rpn_bbox_loss: 0.0159 - val_mrcnn_class_loss: 0.0277 - val_mrcnn_bbox_loss: 0.0257 - val_mrcnn_mask_loss: 0.1104\n",
      "Epoch 37/500\n",
      "250/250 [==============================] - 54s 217ms/step - loss: 0.1743 - rpn_class_loss: 0.0019 - rpn_bbox_loss: 0.0273 - mrcnn_class_loss: 0.0199 - mrcnn_bbox_loss: 0.0239 - mrcnn_mask_loss: 0.0954 - val_loss: 0.2272 - val_rpn_class_loss: 0.0024 - val_rpn_bbox_loss: 0.0570 - val_mrcnn_class_loss: 0.0255 - val_mrcnn_bbox_loss: 0.0354 - val_mrcnn_mask_loss: 0.1068\n",
      "Epoch 38/500\n",
      "250/250 [==============================] - 54s 217ms/step - loss: 0.1740 - rpn_class_loss: 0.0018 - rpn_bbox_loss: 0.0317 - mrcnn_class_loss: 0.0192 - mrcnn_bbox_loss: 0.0245 - mrcnn_mask_loss: 0.0941 - val_loss: 0.2015 - val_rpn_class_loss: 0.0026 - val_rpn_bbox_loss: 0.0324 - val_mrcnn_class_loss: 0.0251 - val_mrcnn_bbox_loss: 0.0279 - val_mrcnn_mask_loss: 0.1135\n",
      "Epoch 39/500\n",
      "250/250 [==============================] - 55s 221ms/step - loss: 0.1649 - rpn_class_loss: 0.0019 - rpn_bbox_loss: 0.0254 - mrcnn_class_loss: 0.0186 - mrcnn_bbox_loss: 0.0236 - mrcnn_mask_loss: 0.0951 - val_loss: 0.1713 - val_rpn_class_loss: 0.0020 - val_rpn_bbox_loss: 0.0172 - val_mrcnn_class_loss: 0.0216 - val_mrcnn_bbox_loss: 0.0258 - val_mrcnn_mask_loss: 0.1047\n",
      "Epoch 40/500\n",
      "250/250 [==============================] - 55s 220ms/step - loss: 0.1583 - rpn_class_loss: 0.0017 - rpn_bbox_loss: 0.0242 - mrcnn_class_loss: 0.0163 - mrcnn_bbox_loss: 0.0211 - mrcnn_mask_loss: 0.0948 - val_loss: 0.1625 - val_rpn_class_loss: 0.0019 - val_rpn_bbox_loss: 0.0152 - val_mrcnn_class_loss: 0.0206 - val_mrcnn_bbox_loss: 0.0211 - val_mrcnn_mask_loss: 0.1037\n",
      "Epoch 41/500\n",
      "250/250 [==============================] - 55s 221ms/step - loss: 0.1488 - rpn_class_loss: 0.0018 - rpn_bbox_loss: 0.0193 - mrcnn_class_loss: 0.0171 - mrcnn_bbox_loss: 0.0196 - mrcnn_mask_loss: 0.0898 - val_loss: 0.1481 - val_rpn_class_loss: 0.0023 - val_rpn_bbox_loss: 0.0117 - val_mrcnn_class_loss: 0.0184 - val_mrcnn_bbox_loss: 0.0191 - val_mrcnn_mask_loss: 0.0966\n",
      "Epoch 42/500\n",
      "250/250 [==============================] - 54s 216ms/step - loss: 0.1492 - rpn_class_loss: 0.0017 - rpn_bbox_loss: 0.0177 - mrcnn_class_loss: 0.0168 - mrcnn_bbox_loss: 0.0183 - mrcnn_mask_loss: 0.0896 - val_loss: 0.1512 - val_rpn_class_loss: 0.0021 - val_rpn_bbox_loss: 0.0102 - val_mrcnn_class_loss: 0.0170 - val_mrcnn_bbox_loss: 0.0210 - val_mrcnn_mask_loss: 0.1009\n",
      "Epoch 43/500\n",
      "250/250 [==============================] - 54s 217ms/step - loss: 0.1420 - rpn_class_loss: 0.0015 - rpn_bbox_loss: 0.0189 - mrcnn_class_loss: 0.0156 - mrcnn_bbox_loss: 0.0203 - mrcnn_mask_loss: 0.0927 - val_loss: 0.1564 - val_rpn_class_loss: 0.0016 - val_rpn_bbox_loss: 0.0117 - val_mrcnn_class_loss: 0.0186 - val_mrcnn_bbox_loss: 0.0207 - val_mrcnn_mask_loss: 0.1039\n",
      "Epoch 44/500\n",
      "250/250 [==============================] - 55s 220ms/step - loss: 0.1417 - rpn_class_loss: 0.0016 - rpn_bbox_loss: 0.0189 - mrcnn_class_loss: 0.0138 - mrcnn_bbox_loss: 0.0165 - mrcnn_mask_loss: 0.0849 - val_loss: 0.1418 - val_rpn_class_loss: 0.0019 - val_rpn_bbox_loss: 0.0143 - val_mrcnn_class_loss: 0.0147 - val_mrcnn_bbox_loss: 0.0172 - val_mrcnn_mask_loss: 0.0937\n",
      "Epoch 45/500\n",
      "250/250 [==============================] - 54s 216ms/step - loss: 0.1461 - rpn_class_loss: 0.0016 - rpn_bbox_loss: 0.0214 - mrcnn_class_loss: 0.0155 - mrcnn_bbox_loss: 0.0192 - mrcnn_mask_loss: 0.0894 - val_loss: 0.1481 - val_rpn_class_loss: 0.0020 - val_rpn_bbox_loss: 0.0110 - val_mrcnn_class_loss: 0.0164 - val_mrcnn_bbox_loss: 0.0205 - val_mrcnn_mask_loss: 0.0983\n",
      "Epoch 46/500\n",
      "250/250 [==============================] - 54s 216ms/step - loss: 0.1424 - rpn_class_loss: 0.0016 - rpn_bbox_loss: 0.0193 - mrcnn_class_loss: 0.0146 - mrcnn_bbox_loss: 0.0175 - mrcnn_mask_loss: 0.0879 - val_loss: 0.1615 - val_rpn_class_loss: 0.0020 - val_rpn_bbox_loss: 0.0150 - val_mrcnn_class_loss: 0.0180 - val_mrcnn_bbox_loss: 0.0221 - val_mrcnn_mask_loss: 0.1044\n",
      "Epoch 47/500\n",
      "250/250 [==============================] - 54s 217ms/step - loss: 0.1248 - rpn_class_loss: 0.0014 - rpn_bbox_loss: 0.0134 - mrcnn_class_loss: 0.0124 - mrcnn_bbox_loss: 0.0153 - mrcnn_mask_loss: 0.0843 - val_loss: 0.1470 - val_rpn_class_loss: 0.0016 - val_rpn_bbox_loss: 0.0115 - val_mrcnn_class_loss: 0.0178 - val_mrcnn_bbox_loss: 0.0182 - val_mrcnn_mask_loss: 0.0979\n",
      "Epoch 48/500\n",
      "250/250 [==============================] - 54s 217ms/step - loss: 0.1298 - rpn_class_loss: 0.0013 - rpn_bbox_loss: 0.0167 - mrcnn_class_loss: 0.0120 - mrcnn_bbox_loss: 0.0161 - mrcnn_mask_loss: 0.0825 - val_loss: 0.1419 - val_rpn_class_loss: 0.0016 - val_rpn_bbox_loss: 0.0143 - val_mrcnn_class_loss: 0.0149 - val_mrcnn_bbox_loss: 0.0168 - val_mrcnn_mask_loss: 0.0943\n",
      "Epoch 49/500\n",
      "250/250 [==============================] - 55s 221ms/step - loss: 0.1295 - rpn_class_loss: 0.0015 - rpn_bbox_loss: 0.0164 - mrcnn_class_loss: 0.0117 - mrcnn_bbox_loss: 0.0158 - mrcnn_mask_loss: 0.0855 - val_loss: 0.1360 - val_rpn_class_loss: 0.0015 - val_rpn_bbox_loss: 0.0165 - val_mrcnn_class_loss: 0.0120 - val_mrcnn_bbox_loss: 0.0166 - val_mrcnn_mask_loss: 0.0893\n",
      "Epoch 50/500\n",
      "250/250 [==============================] - 54s 217ms/step - loss: 0.1324 - rpn_class_loss: 0.0015 - rpn_bbox_loss: 0.0210 - mrcnn_class_loss: 0.0098 - mrcnn_bbox_loss: 0.0156 - mrcnn_mask_loss: 0.0815 - val_loss: 0.1422 - val_rpn_class_loss: 0.0021 - val_rpn_bbox_loss: 0.0175 - val_mrcnn_class_loss: 0.0154 - val_mrcnn_bbox_loss: 0.0175 - val_mrcnn_mask_loss: 0.0897\n",
      "Epoch 51/500\n",
      "250/250 [==============================] - 55s 221ms/step - loss: 0.1261 - rpn_class_loss: 0.0013 - rpn_bbox_loss: 0.0159 - mrcnn_class_loss: 0.0125 - mrcnn_bbox_loss: 0.0145 - mrcnn_mask_loss: 0.0779 - val_loss: 0.1324 - val_rpn_class_loss: 0.0013 - val_rpn_bbox_loss: 0.0147 - val_mrcnn_class_loss: 0.0130 - val_mrcnn_bbox_loss: 0.0151 - val_mrcnn_mask_loss: 0.0883\n",
      "Epoch 52/500\n",
      "250/250 [==============================] - 54s 217ms/step - loss: 0.1280 - rpn_class_loss: 0.0013 - rpn_bbox_loss: 0.0180 - mrcnn_class_loss: 0.0121 - mrcnn_bbox_loss: 0.0150 - mrcnn_mask_loss: 0.0780 - val_loss: 0.1546 - val_rpn_class_loss: 0.0015 - val_rpn_bbox_loss: 0.0148 - val_mrcnn_class_loss: 0.0162 - val_mrcnn_bbox_loss: 0.0216 - val_mrcnn_mask_loss: 0.1005\n",
      "Epoch 53/500\n",
      "250/250 [==============================] - 55s 221ms/step - loss: 0.1224 - rpn_class_loss: 0.0013 - rpn_bbox_loss: 0.0168 - mrcnn_class_loss: 0.0106 - mrcnn_bbox_loss: 0.0145 - mrcnn_mask_loss: 0.0766 - val_loss: 0.1275 - val_rpn_class_loss: 0.0016 - val_rpn_bbox_loss: 0.0143 - val_mrcnn_class_loss: 0.0127 - val_mrcnn_bbox_loss: 0.0149 - val_mrcnn_mask_loss: 0.0840\n",
      "Epoch 54/500\n",
      "250/250 [==============================] - 55s 221ms/step - loss: 0.1192 - rpn_class_loss: 0.0013 - rpn_bbox_loss: 0.0144 - mrcnn_class_loss: 0.0116 - mrcnn_bbox_loss: 0.0138 - mrcnn_mask_loss: 0.0796 - val_loss: 0.1206 - val_rpn_class_loss: 0.0018 - val_rpn_bbox_loss: 0.0111 - val_mrcnn_class_loss: 0.0129 - val_mrcnn_bbox_loss: 0.0128 - val_mrcnn_mask_loss: 0.0818\n",
      "Epoch 55/500\n",
      "250/250 [==============================] - 55s 221ms/step - loss: 0.1133 - rpn_class_loss: 0.0013 - rpn_bbox_loss: 0.0160 - mrcnn_class_loss: 0.0105 - mrcnn_bbox_loss: 0.0122 - mrcnn_mask_loss: 0.0759 - val_loss: 0.1148 - val_rpn_class_loss: 0.0014 - val_rpn_bbox_loss: 0.0088 - val_mrcnn_class_loss: 0.0101 - val_mrcnn_bbox_loss: 0.0127 - val_mrcnn_mask_loss: 0.0817\n",
      "Epoch 56/500\n",
      "250/250 [==============================] - 54s 217ms/step - loss: 0.1141 - rpn_class_loss: 0.0013 - rpn_bbox_loss: 0.0142 - mrcnn_class_loss: 0.0098 - mrcnn_bbox_loss: 0.0129 - mrcnn_mask_loss: 0.0728 - val_loss: 0.1170 - val_rpn_class_loss: 0.0014 - val_rpn_bbox_loss: 0.0107 - val_mrcnn_class_loss: 0.0109 - val_mrcnn_bbox_loss: 0.0129 - val_mrcnn_mask_loss: 0.0810\n",
      "Epoch 57/500\n",
      "250/250 [==============================] - 54s 217ms/step - loss: 0.1098 - rpn_class_loss: 0.0013 - rpn_bbox_loss: 0.0131 - mrcnn_class_loss: 0.0084 - mrcnn_bbox_loss: 0.0128 - mrcnn_mask_loss: 0.0747 - val_loss: 0.1172 - val_rpn_class_loss: 0.0013 - val_rpn_bbox_loss: 0.0093 - val_mrcnn_class_loss: 0.0137 - val_mrcnn_bbox_loss: 0.0140 - val_mrcnn_mask_loss: 0.0789\n",
      "Epoch 58/500\n",
      "250/250 [==============================] - 54s 217ms/step - loss: 0.1242 - rpn_class_loss: 0.0013 - rpn_bbox_loss: 0.0170 - mrcnn_class_loss: 0.0115 - mrcnn_bbox_loss: 0.0126 - mrcnn_mask_loss: 0.0754 - val_loss: 0.1219 - val_rpn_class_loss: 0.0015 - val_rpn_bbox_loss: 0.0124 - val_mrcnn_class_loss: 0.0127 - val_mrcnn_bbox_loss: 0.0149 - val_mrcnn_mask_loss: 0.0803\n",
      "Epoch 59/500\n",
      "250/250 [==============================] - 54s 217ms/step - loss: 0.1124 - rpn_class_loss: 0.0012 - rpn_bbox_loss: 0.0142 - mrcnn_class_loss: 0.0093 - mrcnn_bbox_loss: 0.0130 - mrcnn_mask_loss: 0.0721 - val_loss: 0.1209 - val_rpn_class_loss: 0.0015 - val_rpn_bbox_loss: 0.0097 - val_mrcnn_class_loss: 0.0119 - val_mrcnn_bbox_loss: 0.0144 - val_mrcnn_mask_loss: 0.0834\n",
      "Epoch 60/500\n",
      "250/250 [==============================] - 56s 223ms/step - loss: 0.1019 - rpn_class_loss: 0.0012 - rpn_bbox_loss: 0.0108 - mrcnn_class_loss: 0.0094 - mrcnn_bbox_loss: 0.0107 - mrcnn_mask_loss: 0.0686 - val_loss: 0.1090 - val_rpn_class_loss: 0.0014 - val_rpn_bbox_loss: 0.0078 - val_mrcnn_class_loss: 0.0120 - val_mrcnn_bbox_loss: 0.0120 - val_mrcnn_mask_loss: 0.0757\n",
      "Epoch 61/500\n",
      "250/250 [==============================] - 54s 217ms/step - loss: 0.1068 - rpn_class_loss: 0.0013 - rpn_bbox_loss: 0.0122 - mrcnn_class_loss: 0.0098 - mrcnn_bbox_loss: 0.0115 - mrcnn_mask_loss: 0.0719 - val_loss: 0.1105 - val_rpn_class_loss: 0.0014 - val_rpn_bbox_loss: 0.0089 - val_mrcnn_class_loss: 0.0119 - val_mrcnn_bbox_loss: 0.0112 - val_mrcnn_mask_loss: 0.0770\n",
      "Epoch 62/500\n",
      "250/250 [==============================] - 54s 217ms/step - loss: 0.1019 - rpn_class_loss: 0.0011 - rpn_bbox_loss: 0.0129 - mrcnn_class_loss: 0.0094 - mrcnn_bbox_loss: 0.0099 - mrcnn_mask_loss: 0.0684 - val_loss: 0.1117 - val_rpn_class_loss: 0.0011 - val_rpn_bbox_loss: 0.0087 - val_mrcnn_class_loss: 0.0112 - val_mrcnn_bbox_loss: 0.0108 - val_mrcnn_mask_loss: 0.0798\n",
      "Epoch 63/500\n",
      "250/250 [==============================] - 54s 217ms/step - loss: 0.1013 - rpn_class_loss: 0.0012 - rpn_bbox_loss: 0.0117 - mrcnn_class_loss: 0.0090 - mrcnn_bbox_loss: 0.0093 - mrcnn_mask_loss: 0.0656 - val_loss: 0.1121 - val_rpn_class_loss: 0.0014 - val_rpn_bbox_loss: 0.0064 - val_mrcnn_class_loss: 0.0123 - val_mrcnn_bbox_loss: 0.0112 - val_mrcnn_mask_loss: 0.0808\n",
      "Epoch 64/500\n",
      "250/250 [==============================] - 54s 217ms/step - loss: 0.1013 - rpn_class_loss: 0.0011 - rpn_bbox_loss: 0.0122 - mrcnn_class_loss: 0.0097 - mrcnn_bbox_loss: 0.0108 - mrcnn_mask_loss: 0.0684 - val_loss: 0.1188 - val_rpn_class_loss: 0.0013 - val_rpn_bbox_loss: 0.0082 - val_mrcnn_class_loss: 0.0098 - val_mrcnn_bbox_loss: 0.0112 - val_mrcnn_mask_loss: 0.0882\n",
      "Epoch 65/500\n",
      "250/250 [==============================] - 55s 221ms/step - loss: 0.0971 - rpn_class_loss: 0.0011 - rpn_bbox_loss: 0.0106 - mrcnn_class_loss: 0.0084 - mrcnn_bbox_loss: 0.0091 - mrcnn_mask_loss: 0.0614 - val_loss: 0.1067 - val_rpn_class_loss: 0.0011 - val_rpn_bbox_loss: 0.0076 - val_mrcnn_class_loss: 0.0102 - val_mrcnn_bbox_loss: 0.0093 - val_mrcnn_mask_loss: 0.0785\n",
      "Epoch 66/500\n",
      "250/250 [==============================] - 54s 217ms/step - loss: 0.0982 - rpn_class_loss: 0.0011 - rpn_bbox_loss: 0.0114 - mrcnn_class_loss: 0.0083 - mrcnn_bbox_loss: 0.0088 - mrcnn_mask_loss: 0.0679 - val_loss: 0.1078 - val_rpn_class_loss: 0.0013 - val_rpn_bbox_loss: 0.0073 - val_mrcnn_class_loss: 0.0128 - val_mrcnn_bbox_loss: 0.0109 - val_mrcnn_mask_loss: 0.0756\n",
      "Epoch 67/500\n",
      "250/250 [==============================] - 55s 221ms/step - loss: 0.0946 - rpn_class_loss: 0.0010 - rpn_bbox_loss: 0.0101 - mrcnn_class_loss: 0.0091 - mrcnn_bbox_loss: 0.0094 - mrcnn_mask_loss: 0.0649 - val_loss: 0.1057 - val_rpn_class_loss: 0.0015 - val_rpn_bbox_loss: 0.0100 - val_mrcnn_class_loss: 0.0121 - val_mrcnn_bbox_loss: 0.0106 - val_mrcnn_mask_loss: 0.0715\n",
      "Epoch 68/500\n",
      "250/250 [==============================] - 55s 221ms/step - loss: 0.0969 - rpn_class_loss: 0.0011 - rpn_bbox_loss: 0.0120 - mrcnn_class_loss: 0.0086 - mrcnn_bbox_loss: 0.0095 - mrcnn_mask_loss: 0.0642 - val_loss: 0.0956 - val_rpn_class_loss: 0.0013 - val_rpn_bbox_loss: 0.0070 - val_mrcnn_class_loss: 0.0091 - val_mrcnn_bbox_loss: 0.0084 - val_mrcnn_mask_loss: 0.0698\n",
      "Epoch 69/500\n",
      "250/250 [==============================] - 54s 217ms/step - loss: 0.0869 - rpn_class_loss: 9.6979e-04 - rpn_bbox_loss: 0.0078 - mrcnn_class_loss: 0.0078 - mrcnn_bbox_loss: 0.0081 - mrcnn_mask_loss: 0.0587 - val_loss: 0.0967 - val_rpn_class_loss: 0.0013 - val_rpn_bbox_loss: 0.0058 - val_mrcnn_class_loss: 0.0097 - val_mrcnn_bbox_loss: 0.0097 - val_mrcnn_mask_loss: 0.0703\n",
      "Epoch 70/500\n",
      "250/250 [==============================] - 54s 217ms/step - loss: 0.0872 - rpn_class_loss: 9.8335e-04 - rpn_bbox_loss: 0.0082 - mrcnn_class_loss: 0.0072 - mrcnn_bbox_loss: 0.0081 - mrcnn_mask_loss: 0.0593 - val_loss: 0.1000 - val_rpn_class_loss: 0.0013 - val_rpn_bbox_loss: 0.0077 - val_mrcnn_class_loss: 0.0108 - val_mrcnn_bbox_loss: 0.0107 - val_mrcnn_mask_loss: 0.0695\n",
      "Epoch 71/500\n",
      "250/250 [==============================] - 54s 217ms/step - loss: 0.0908 - rpn_class_loss: 0.0011 - rpn_bbox_loss: 0.0093 - mrcnn_class_loss: 0.0087 - mrcnn_bbox_loss: 0.0093 - mrcnn_mask_loss: 0.0632 - val_loss: 0.1020 - val_rpn_class_loss: 9.7711e-04 - val_rpn_bbox_loss: 0.0107 - val_mrcnn_class_loss: 0.0096 - val_mrcnn_bbox_loss: 0.0099 - val_mrcnn_mask_loss: 0.0708\n",
      "Epoch 72/500\n",
      "  6/250 [..............................] - ETA: 51s - loss: 0.0696 - rpn_class_loss: 0.0012 - rpn_bbox_loss: 0.0045 - mrcnn_class_loss: 0.0023 - mrcnn_bbox_loss: 0.0063 - mrcnn_mask_loss: 0.0543    "
     ]
    }
   ],
   "source": [
    "model.train(dataset_train, dataset_train, \n",
    "            epochs=EPOCHS[1], \n",
    "            augmentations=None, #augmentation, \n",
    "            custom_callbacks=[stop_early, warmup_with_reduce_lr_callback, csv_logger_all])\n",
    "new_history = model.keras_model.history.history\n",
    "for k in new_history: \n",
    "    history[k] = history[k] + new_history[k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = range(len(list(history[\"loss\"])))\n",
    "epochs = tuple(e + 1 for e in epochs)\n",
    "\n",
    "\n",
    "plt.figure(figsize=(18, 6))\n",
    "\n",
    "plt.subplot(131, title=\"losses\")\n",
    "plt.plot(epochs, history[\"loss\"], label=\"train loss\")\n",
    "plt.plot(epochs, history[\"val_loss\"], label=\"valid loss\")\n",
    "plt.xticks(range(0, epochs[-1]+1, 20))\n",
    "plt.yscale(\"log\")\n",
    "for xpos in (epochs[0], epochs[-1]):\n",
    "    plt.axvline(x=xpos, color=\"gray\", linestyle=\"--\", linewidth=1)\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(132)\n",
    "plt.plot(epochs, history[\"mrcnn_class_loss\"], label=\"train class loss\")\n",
    "plt.plot(epochs, history[\"val_mrcnn_class_loss\"], label=\"valid class loss\")\n",
    "plt.xticks(range(0, epochs[-1]+1, 20))\n",
    "plt.yscale(\"log\")\n",
    "for xpos in (epochs[0], epochs[-1]):\n",
    "    plt.axvline(x=xpos, color=\"gray\", linestyle=\"--\", linewidth=1)\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(133)\n",
    "plt.plot(epochs, history[\"mrcnn_mask_loss\"], label=\"train mask loss\")\n",
    "plt.plot(epochs, history[\"val_mrcnn_mask_loss\"], label=\"valid mask loss\")\n",
    "plt.xticks(range(0, epochs[-1]+1, 20))\n",
    "plt.yscale(\"log\")\n",
    "for xpos in (epochs[0], epochs[-1]):\n",
    "    plt.axvline(x=xpos, color=\"gray\", linestyle=\"--\", linewidth=1)\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InferenceConfig(ShapesConfig):\n",
    "    GPU_COUNT = 1\n",
    "    IMAGES_PER_GPU = 1\n",
    "\n",
    "inference_config = InferenceConfig()\n",
    "\n",
    "# Recreate the model in inference mode\n",
    "model = modellib.MaskRCNN(mode=\"inference\", \n",
    "                          config=inference_config,\n",
    "                          model_dir=dir_model)\n",
    "\n",
    "# Get path to saved weights\n",
    "# Either set a specific path or find last trained weights\n",
    "# model_path = os.path.join(ROOT_DIR, \".h5 file name here\")\n",
    "model_path = model.find_last()\n",
    "\n",
    "# Load trained weights\n",
    "print(\"Loading weights from \", model_path)\n",
    "model.load_weights(model_path, by_name=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread(\"./shape_test_images/shape_test_image_8.png\") # check if image in folder exists - otherwise change name, if necessary\n",
    "\n",
    "# Run detection\n",
    "results = model.detect([image], verbose=1)\n",
    "res = results[0]\n",
    "print(res[\"rois\"])\n",
    "print(res[\"class_ids\"])\n",
    "print(res[\"scores\"])\n",
    "print(dataset_val.class_names)\n",
    "\n",
    "# Visualize results\n",
    "visualize.display_instances(image, res[\"rois\"], res[\"masks\"], res[\"class_ids\"], dataset_val.class_names, res[\"scores\"], figsize=(8, 8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test on a random image\n",
    "image_id = random.choice(dataset_val.image_ids)\n",
    "original_image, image_meta, gt_class_id, gt_bbox, gt_mask =\\\n",
    "    modellib.load_image_gt(dataset_val, inference_config, \n",
    "                           image_id, use_mini_mask=False)\n",
    "\n",
    "log(\"original_image\", original_image)\n",
    "log(\"image_meta\", image_meta)\n",
    "log(\"gt_class_id\", gt_class_id) # ground truth\n",
    "log(\"gt_bbox\", gt_bbox) # ground truth\n",
    "log(\"gt_mask\", gt_mask) # ground truth\n",
    "\n",
    "# visualize.display_instances(original_image, gt_bbox, gt_mask, gt_class_id, \n",
    "#                             dataset_val.class_names, figsize=(8, 8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf215",
   "language": "python",
   "name": "tf215"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
